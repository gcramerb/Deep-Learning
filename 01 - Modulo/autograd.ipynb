{"nbformat":4,"nbformat_minor":0,"metadata":{"display_name":"","name":"","language":"python","colab":{"name":"autograd.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xb8Q262gpaDl","colab_type":"text"},"source":["<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n","<!--- or more contributor license agreements.  See the NOTICE file -->\n","<!--- distributed with this work for additional information -->\n","<!--- regarding copyright ownership.  The ASF licenses this file -->\n","<!--- to you under the Apache License, Version 2.0 (the -->\n","<!--- \"License\"); you may not use this file except in compliance -->\n","<!--- with the License.  You may obtain a copy of the License at -->\n","\n","<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n","\n","<!--- Unless required by applicable law or agreed to in writing, -->\n","<!--- software distributed under the License is distributed on an -->\n","<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n","<!--- KIND, either express or implied.  See the License for the -->\n","<!--- specific language governing permissions and limitations -->\n","<!--- under the License. -->\n","\n","# Automatic differentiation\n","\n","MXNet supports automatic differentiation with the `autograd` package.\n","`autograd` allows you to differentiate a graph of NDArray operations\n","with the chain rule.\n","This is called define-by-run, i.e., the network is defined on-the-fly by\n","running forward computation. You can define exotic network structures\n","and differentiate them, and each iteration can have a totally different\n","network structure."]},{"cell_type":"code","metadata":{"id":"aeoioPPopaDq","colab_type":"code","colab":{}},"source":["import mxnet as mx\n","from mxnet import autograd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JvS0VejGpaD2","colab_type":"text"},"source":["To use `autograd`, we must first mark variables that require gradient and\n","attach gradient buffers to them:"]},{"cell_type":"code","metadata":{"id":"tTwCu4vEpaD4","colab_type":"code","colab":{}},"source":["x = mx.nd.array([[1, 2], [3, 4]])\n","x.attach_grad()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EFsX7AbWpaEA","colab_type":"text"},"source":["Now we can define the network while running forward computation by wrapping\n","it inside a `record` (operations out of `record` does not define\n","a graph and cannot be differentiated):"]},{"cell_type":"code","metadata":{"id":"NH5Z8GXZpaEC","colab_type":"code","colab":{}},"source":["with autograd.record():\n","  y = x * 2\n","  z = y * x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yE2coeQwpaEJ","colab_type":"text"},"source":["Let's backprop with `z.backward()`, which is equivalent to\n","`z.backward(mx.nd.ones_like(z))`. When z has more than one entry, `z.backward()`\n","is equivalent to `mx.nd.sum(z).backward()`:"]},{"cell_type":"code","metadata":{"id":"auGYKnp8paEK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"817b9a17-c08c-4e5c-eb03-7bf0db5d2aa9","executionInfo":{"status":"ok","timestamp":1566332318125,"user_tz":180,"elapsed":567,"user":{"displayName":"Guilherme Cramer","photoUrl":"","userId":"08509545871907917206"}}},"source":["print(type(z))\n","z.backward()\n","print(x.grad)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["<class 'mxnet.ndarray.ndarray.NDArray'>\n","\n","[[ 4.  8.]\n"," [12. 16.]]\n","<NDArray 2x2 @cpu(0)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AC9GGUAEpaES","colab_type":"text"},"source":["\n","Now, let's see if this is the expected output.\n","\n","Here, y = f(x), z = f(y) = f(g(x))\n","which means y = 2 * x and z = 2 * x * x.\n","\n","After, doing backprop with `z.backward()`, we will get gradient dz/dx as follows:\n","\n","dy/dx = 2,\n","dz/dx = 4 * x\n","\n","So, we should get x.grad as an array of [[4, 8],[12, 16]].\n","\n","<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n","\n"]}]}