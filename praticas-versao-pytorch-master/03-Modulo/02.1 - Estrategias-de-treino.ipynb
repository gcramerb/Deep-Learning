{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXlS74cg4Ebl"
   },
   "source": [
    "# Estratégias de treino\n",
    "\n",
    "Até agora no curso, vimos somente uma estratégia de treino para redes neurais: o treinamento do zero.\n",
    "Entretanto, há outras formas de se explorar redes neurais.\n",
    "Nessa aula, vamos rever a estratégia treinamento do zero além de apresentar duas novas formas:\n",
    "\n",
    "1.   rede neural como um extrator de características, e\n",
    "2.   *fine-tuning*.\n",
    "\n",
    "Para cada uma dessas estratégias, vamos apresentar sua definição, vantagens e desvantagens.\n",
    "Antes, vamos instalar o Pytorch, importar alguns pacotes e definir funções para carregar os dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5104,
     "status": "ok",
     "timestamp": 1571003691150,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "0JuWliDd393n",
    "outputId": "de26f222-e8f5-4517-e7cd-56dfaa3310e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDFChpaZ4MiW"
   },
   "outputs": [],
   "source": [
    "import time, os, sys, numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import time, os, sys, numpy as np\n",
    "\n",
    "# Test if GPU is avaliable, if not, use cpu instead\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n = torch.cuda.device_count()\n",
    "devices_ids= list(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uF4QkjwG4RQI"
   },
   "outputs": [],
   "source": [
    "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
    "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
    "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
    "    root = os.path.expanduser(root)\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [torchvision.transforms.Resize(resize)]\n",
    "    transformer += [torchvision.transforms.ToTensor()]\n",
    "    transformer = torchvision.transforms.Compose(transformer)\n",
    "\n",
    "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
    "                                  batch_size, shuffle=True,\n",
    "                                  num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
    "                                 batch_size, shuffle=False,\n",
    "                                 num_workers=num_workers)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "# funções básicas\n",
    "def _get_batch(batch):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.type() != features.type():\n",
    "        labels = labels.type(features.type())\n",
    "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
    "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
    "\n",
    "# Função usada para calcular acurácia\n",
    "def evaluate_accuracy(data_iter, net, loss):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "\n",
    "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for X, y in data_iter:\n",
    "          #y = y.astype('float32')\n",
    "          X, y = X.to(device), y.to(device)\n",
    "          y_hat = net(X)\n",
    "          l += loss(y_hat, y).sum()\n",
    "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "          n += y.size()[0]\n",
    "\n",
    "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
    "  \n",
    "# Função usada no treinamento e validação da rede\n",
    "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
    "                   num_epochs):\n",
    "    print('training on', device)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            trainer.zero_grad()\n",
    "            l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.size()[0]\n",
    "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
    "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
    "              'test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
    "                 test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Xu4l1od4y1N"
   },
   "source": [
    "## Treinamento do zero\n",
    "\n",
    "Como dito anteriormente, essa foi a única estratégia vista até o momento no curso.\n",
    "Nessa estratégia, uma rede neural é proposta, **inicializada com pesos aleatórios** e treinada até convergir.\n",
    "A **vantagem** dessa estratégia é liberdade para definir como quiser a arquitetura da rede e seus hiper-parâmetros\n",
    "Por outro lado, a **desvantagem** é que essa estratégia requer muitos dados para convergir a rede inicializada aleatoriamente.\n",
    "Logo, se tivermos poucos dados, essa não é a estratégia mais recomendada.\n",
    "Abaixo, uma representação visual dessa estratégia.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n",
    "</p>\n",
    "\n",
    "Apesar de já termos visto essa estratégia na prática, vamos vê-la aqui novamente para efeitos de comparação com as outras técnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZAEDlZ-DgGd"
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    r\"\"\"AlexNet model from the `\"One weird trick...\" `_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : int, default 10\n",
    "        Number of classes for the output layer.\n",
    "    \"\"\"\n",
    "    def __init__(self,input_channels, classes=10, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels,kernel_size=11, out_channels=64, stride=4)             # entrada: (b, 3, 227, 227) e saida: (b, 64, 55, 55)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3,stride=2)                                                    # entrada: (b, 64, 55, 55) e saida: (b, 64, 27, 27)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64,out_channels=192, kernel_size=5, padding=2)                        # entrada: (b, 64, 27, 27) e saida: (b, 192, 27, 27)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3,stride=2)                                                    # entrada: (b, 192, 27, 27) e saida: (b, 192, 13, 13)\n",
    "        self.conv3 = nn.Conv2d(in_channels=192,out_channels=384,kernel_size=3,padding=1)                         # entrada: (b, 192, 13, 13) e saida: (b, 384, 13, 13)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,padding=1)                         # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=1)                         # entrada: (b, 256, 13, 13) e saida: (b, 256, 13, 13)\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size=3,stride=2)                                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n",
    "        self.flatten  = nn.Flatten()                                                                             # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n",
    "        self.linear1 = nn.Linear(9216, 4096)                                                                     # entrada: (b, 9216) e saida: (b, 4096)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.linear2 = nn.Linear(4096, 4096)                                                                     # entrada: (b, 4096) e saida: (b, 4096)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(4096, classes)                                                                   # entrada: (b, 4096) e saida: (b, 10)\n",
    "          \n",
    "\n",
    "    def forward(self, x):\n",
    "        output_conv1 = F.relu(self.conv1(x))\n",
    "        output_max_pool1 = self.max_pool1(output_conv1)\n",
    "        output_conv2 = F.relu(self.conv2(output_max_pool1))\n",
    "        output_max_pool2 = self.max_pool2(output_conv2)\n",
    "        output_conv3 = F.relu(self.conv3(output_max_pool2))\n",
    "        output_conv4 = F.relu(self.conv4(output_conv3))\n",
    "        output_conv5 = F.relu(self.conv5(output_conv4))\n",
    "        output_max_pool3 = self.max_pool3(output_conv5)\n",
    "        output_flatten = self.flatten(output_max_pool3)\n",
    "        output_linear1 = F.relu(self.linear1(output_flatten))\n",
    "        output_dropout1 = self.dropout1(output_linear1)\n",
    "        output_linear2 = F.relu(self.linear2(output_dropout1))\n",
    "        output_dropout2 = self.dropout2(output_linear2)\n",
    "        output = self.output(output_dropout2)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2574983,
     "status": "ok",
     "timestamp": 1570991559755,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "9Wr5rH-KMNZo",
    "outputId": "b14c2af5-9dab-4bc0-f1ab-4df210fce5c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "         MaxPool2d-2           [-1, 64, 27, 27]               0\n",
      "            Conv2d-3          [-1, 192, 27, 27]         307,392\n",
      "         MaxPool2d-4          [-1, 192, 13, 13]               0\n",
      "            Conv2d-5          [-1, 384, 13, 13]         663,936\n",
      "            Conv2d-6          [-1, 256, 13, 13]         884,992\n",
      "            Conv2d-7          [-1, 256, 13, 13]         590,080\n",
      "         MaxPool2d-8            [-1, 256, 6, 6]               0\n",
      "           Flatten-9                 [-1, 9216]               0\n",
      "           Linear-10                 [-1, 4096]      37,752,832\n",
      "          Dropout-11                 [-1, 4096]               0\n",
      "           Linear-12                 [-1, 4096]      16,781,312\n",
      "          Dropout-13                 [-1, 4096]               0\n",
      "           Linear-14                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,044,810\n",
      "Trainable params: 57,044,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 4.57\n",
      "Params size (MB): 217.61\n",
      "Estimated Total Size (MB): 222.77\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training on cuda\n",
      "epoch 1, train loss 2.2102, train acc 0.161, test loss 1.9457, test acc 0.280, time 128.4 sec\n",
      "epoch 2, train loss 1.7509, train acc 0.351, test loss 1.6097, test acc 0.421, time 128.3 sec\n",
      "epoch 3, train loss 1.3814, train acc 0.498, test loss 1.2269, test acc 0.558, time 129.3 sec\n",
      "epoch 4, train loss 1.1166, train acc 0.604, test loss 1.1047, test acc 0.609, time 129.1 sec\n",
      "epoch 5, train loss 0.8981, train acc 0.685, test loss 0.8339, test acc 0.715, time 128.5 sec\n",
      "epoch 6, train loss 0.7299, train acc 0.744, test loss 0.7781, test acc 0.737, time 128.5 sec\n",
      "epoch 7, train loss 0.6121, train acc 0.787, test loss 0.6994, test acc 0.764, time 128.7 sec\n",
      "epoch 8, train loss 0.5004, train acc 0.827, test loss 0.6572, test acc 0.782, time 128.3 sec\n",
      "epoch 9, train loss 0.4075, train acc 0.860, test loss 0.6668, test acc 0.785, time 128.6 sec\n",
      "epoch 10, train loss 0.3267, train acc 0.888, test loss 0.7464, test acc 0.769, time 129.1 sec\n",
      "epoch 11, train loss 0.2576, train acc 0.910, test loss 0.7472, test acc 0.788, time 128.5 sec\n",
      "epoch 12, train loss 0.2041, train acc 0.930, test loss 0.8997, test acc 0.770, time 128.2 sec\n",
      "epoch 13, train loss 0.1728, train acc 0.939, test loss 0.8014, test acc 0.788, time 128.3 sec\n",
      "epoch 14, train loss 0.1416, train acc 0.952, test loss 0.8084, test acc 0.793, time 128.4 sec\n",
      "epoch 15, train loss 0.1152, train acc 0.962, test loss 0.9173, test acc 0.792, time 128.4 sec\n",
      "epoch 16, train loss 0.1053, train acc 0.964, test loss 0.8746, test acc 0.785, time 128.4 sec\n",
      "epoch 17, train loss 0.0865, train acc 0.970, test loss 0.9188, test acc 0.796, time 128.6 sec\n",
      "epoch 18, train loss 0.0849, train acc 0.971, test loss 0.9481, test acc 0.792, time 128.7 sec\n",
      "epoch 19, train loss 0.0674, train acc 0.978, test loss 0.9852, test acc 0.802, time 128.3 sec\n",
      "epoch 20, train loss 0.0600, train acc 0.981, test loss 1.0445, test acc 0.796, time 129.0 sec\n"
     ]
    }
   ],
   "source": [
    "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
    "# tamanho do batch, e lambda do weight decay\n",
    "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
    "\n",
    "\n",
    "# rede baseada na AlexNet-5 \n",
    "net = AlexNet(3, 10)\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
    "                                # and stored weights. \n",
    "\n",
    "# função de custo (ou loss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# carregamento do dado: mnist\n",
    "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
    "\n",
    "# trainer do gluon\n",
    "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
    "\n",
    "# treinamento e validação via Pytorch\n",
    "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
    "                num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgJwhj2SSGFB"
   },
   "source": [
    "É muito comum se usar redes já existentes para aprender características em novos dados.\n",
    "Por isso, muitos frameworks já deixam as arquiteturas mais famosas pré-implementadas para que possam ser usadas.\n",
    "\n",
    "No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n",
    "Há várias arquiteturas pré-definidas nessa biblioteca, incluindo várias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1824351,
     "status": "error",
     "timestamp": 1571005642036,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "f3u7xCEQM0qF",
    "outputId": "04a241b3-b978-4838-81c9-19a52bb340a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,044,810\n",
      "Trainable params: 57,044,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.48\n",
      "Params size (MB): 217.61\n",
      "Estimated Total Size (MB): 226.68\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:03, 42858845.28it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
      "Files already downloaded and verified\n",
      "training on cuda\n",
      "epoch 1, train loss 2.2150, train acc 0.160, test loss 1.9850, test acc 0.262, time 128.2 sec\n",
      "epoch 2, train loss 1.7934, train acc 0.332, test loss 1.5451, test acc 0.427, time 128.0 sec\n",
      "epoch 3, train loss 1.4409, train acc 0.475, test loss 1.3463, test acc 0.514, time 128.5 sec\n",
      "epoch 4, train loss 1.1734, train acc 0.579, test loss 1.1015, test acc 0.608, time 128.3 sec\n",
      "epoch 5, train loss 0.9665, train acc 0.662, test loss 0.9602, test acc 0.664, time 129.0 sec\n",
      "epoch 6, train loss 0.8200, train acc 0.714, test loss 0.8959, test acc 0.683, time 128.5 sec\n",
      "epoch 7, train loss 0.7055, train acc 0.752, test loss 0.7173, test acc 0.756, time 129.0 sec\n",
      "epoch 8, train loss 0.6192, train acc 0.785, test loss 0.7065, test acc 0.763, time 129.4 sec\n",
      "epoch 9, train loss 0.5458, train acc 0.810, test loss 0.6812, test acc 0.769, time 129.3 sec\n",
      "epoch 10, train loss 0.4880, train acc 0.831, test loss 0.6409, test acc 0.787, time 129.0 sec\n",
      "epoch 11, train loss 0.4223, train acc 0.853, test loss 0.6674, test acc 0.783, time 129.1 sec\n",
      "epoch 12, train loss 0.3665, train acc 0.873, test loss 0.6680, test acc 0.789, time 128.7 sec\n",
      "epoch 13, train loss 0.3263, train acc 0.885, test loss 0.6401, test acc 0.795, time 128.7 sec\n",
      "epoch 14, train loss 0.2796, train acc 0.901, test loss 0.6568, test acc 0.805, time 128.7 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ed0bdc113222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# treinamento e validação via Pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n\u001b[0;32m---> 22\u001b[0;31m                 num_epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f67a054c794a>\u001b[0m in \u001b[0;36mtrain_validate\u001b[0;34m(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
    "# tamanho do batch, e lambda do weight decay\n",
    "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
    "\n",
    "# rede baseada na AlexNet-5 \n",
    "net = torchvision.models.alexnet(num_classes=10)\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
    "                                # and stored weights. \n",
    "\n",
    "# função de custo (ou loss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# carregamento do dado: mnist\n",
    "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
    "\n",
    "# trainer do gluon\n",
    "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
    "\n",
    "# treinamento e validação via Pytorch\n",
    "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
    "                num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WyR3sukIS9D"
   },
   "source": [
    "## Extrator de características\n",
    "\n",
    "A terceira e última estratégia, mostrada na figura abaixo, é usar uma rede neural pré-treinada em algum dataset grande para extrair características de um outro dataset. Essa estratégia é preferível quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n",
    "</p>\n",
    "\n",
    "Existem duas formas de se explorar essa estratégia. A primeira consiste em substituir e treinar somente a última camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, não aprendem nada, e são somente usadas como codificadores/extratores de características. A segunda forma, *features* das imagens do dataset que se quer classificar são extraídas da penúltima camada da rede pré-treinada (geralmente, a camada antes da camada de classificação). Essas *features* são então usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que então classifica o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mJzyz8VPOW4"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1915,
     "status": "ok",
     "timestamp": 1571013564512,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "3VLBe7z2HmNK",
    "outputId": "29c7f1ff-60d7-43b7-8e7e-d22121e49a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 0\n",
      "Non-trainable params: 61,100,840\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.49\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 242.16\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,044,810\n",
      "Trainable params: 40,970\n",
      "Non-trainable params: 57,003,840\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.48\n",
      "Params size (MB): 217.61\n",
      "Estimated Total Size (MB): 226.68\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# rede baseada na AlexNet-5 \n",
    "net = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "feature_extract = True\n",
    "set_parameter_requires_grad(net, feature_extract) # Iremos treinar somente a última camada\n",
    "\n",
    "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
    "                                # and stored weights. \n",
    "\n",
    "num_ftrs = net.classifier[6].in_features\n",
    "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "\n",
    "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
    "print(net)\n",
    "\n",
    "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
    "print(summary(net,(3,227,227))) \n",
    "\n",
    "# Código retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1346537,
     "status": "error",
     "timestamp": 1571014911736,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "0fk0epQ2PDb0",
    "outputId": "9e3aa277-b42b-4bcf-85ba-05980dad636d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training on cuda\n",
      "epoch 1, train loss 1.3217, train acc 0.534, test loss 1.1989, test acc 0.581, time 87.6 sec\n",
      "epoch 2, train loss 1.1632, train acc 0.591, test loss 1.1641, test acc 0.582, time 87.6 sec\n",
      "epoch 3, train loss 1.1363, train acc 0.599, test loss 1.1220, test acc 0.604, time 86.9 sec\n",
      "epoch 4, train loss 1.1119, train acc 0.605, test loss 1.0966, test acc 0.609, time 86.1 sec\n",
      "epoch 5, train loss 1.0952, train acc 0.614, test loss 1.0971, test acc 0.609, time 85.5 sec\n",
      "epoch 6, train loss 1.0879, train acc 0.615, test loss 1.1102, test acc 0.605, time 85.1 sec\n",
      "epoch 7, train loss 1.0819, train acc 0.619, test loss 1.0763, test acc 0.619, time 86.7 sec\n",
      "epoch 8, train loss 1.0756, train acc 0.619, test loss 1.0926, test acc 0.610, time 87.2 sec\n",
      "epoch 9, train loss 1.0718, train acc 0.621, test loss 1.0838, test acc 0.616, time 86.3 sec\n",
      "epoch 10, train loss 1.0624, train acc 0.624, test loss 1.0802, test acc 0.616, time 87.1 sec\n",
      "epoch 11, train loss 1.0591, train acc 0.624, test loss 1.0768, test acc 0.616, time 87.0 sec\n",
      "epoch 12, train loss 1.0591, train acc 0.624, test loss 1.0739, test acc 0.623, time 87.0 sec\n",
      "epoch 13, train loss 1.0560, train acc 0.627, test loss 1.0501, test acc 0.623, time 86.8 sec\n",
      "epoch 14, train loss 1.0513, train acc 0.627, test loss 1.0607, test acc 0.627, time 86.3 sec\n",
      "epoch 15, train loss 1.0534, train acc 0.627, test loss 1.0670, test acc 0.624, time 86.7 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2b373394a385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# treinamento e validação via Pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n\u001b[0;32m---> 15\u001b[0;31m                 num_epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f67a054c794a>\u001b[0m in \u001b[0;36mtrain_validate\u001b[0;34m(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Treinando a última camada da rede acima\n",
    "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
    "# tamanho do batch, e lambda do weight decay\n",
    "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
    "\n",
    "\n",
    "# função de custo (ou loss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# carregamento do dado: mnist\n",
    "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
    "\n",
    "# trainer do gluon\n",
    "trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
    "\n",
    "# treinamento e validação via Pytorch\n",
    "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
    "                num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141065,
     "status": "ok",
     "timestamp": 1571009337785,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "ozt5EPQmSsx1",
    "outputId": "a70c1fd2-79c4-4a79-e1f1-2687868a636c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "================================================================\n",
      "Total params: 57,003,840\n",
      "Trainable params: 57,003,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.48\n",
      "Params size (MB): 217.45\n",
      "Estimated Total Size (MB): 226.52\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "(50000, 4096) (10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
    "# tamanho do batch, e lambda do weight decay\n",
    "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
    "\n",
    "# rede baseada na AlexNet-5 \n",
    "net = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "\n",
    "# carregamento do dado: fashion mnist\n",
    "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)  \n",
    "\n",
    "# remove last fully-connected layer\n",
    "new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n",
    "net.classifier = new_classifier\n",
    "\n",
    "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
    "                                # and stored weights. \n",
    "\n",
    "first = True    \n",
    "with torch.no_grad():\n",
    "    for X, y in train_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        features = net(X)\n",
    "        if first is True:\n",
    "          train_features = features.cpu().numpy()\n",
    "          train_labels = y.cpu().numpy()\n",
    "          first = False\n",
    "        else:\n",
    "          train_features = np.concatenate((train_features, features.cpu().numpy()))\n",
    "          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n",
    "\n",
    "\n",
    "first = True    \n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        features = net(X)\n",
    "        if first is True:\n",
    "          test_features = features.cpu().numpy()\n",
    "          test_labels = y.cpu().numpy()\n",
    "          first = False\n",
    "        else:\n",
    "          test_features = np.concatenate((test_features, features.cpu().numpy()))\n",
    "          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n",
    "\n",
    "          \n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677241,
     "status": "ok",
     "timestamp": 1571010036690,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "BR7LqiOTY6Tc",
    "outputId": "f8e5141a-bc75-45a0-c264-cad1f98bd81e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "pred = clf.predict(test_features)\n",
    "print(accuracy_score(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsOgJBcofpZN"
   },
   "source": [
    "## *Fine-tuning*\n",
    "\n",
    "A segunda estratégia é chamada de *fine-tuning*, e é comumente classificada como um estratégia de *transfer learning*, onde o aprendizado é transferido entre datasets.\n",
    "Especificamente, esta estratégia, representada na figura abaixo, tenta usar um modelo pré-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n",
    "</p>\n",
    "\n",
    "Como esses dados podem possuir características diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem número e classes diferentes, a última camada não é usada nessa transferência de peso e, geralmente, é inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n",
    "\n",
    "Por fim, é um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender características de baixo nível nas camadas iniciais. Geralmente, essas características são comuns à vários datasets. Por isso, uma opção durante o processo de *fine-tuning* é \"congelar\" as camadas iniciais (ou seja, não treiná-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificação).\n",
    "\n",
    "No bloco de código abaixo, importamos a rede pré-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a última camada e criaremos uma nova camada inicializada aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2517430,
     "status": "ok",
     "timestamp": 1571013032462,
     "user": {
      "displayName": "Felipe Marcelino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64",
      "userId": "10589390457938412332"
     },
     "user_tz": 180
    },
    "id": "2hDGgIDhdG2z",
    "outputId": "b9ee7eb8-87bf-4a2c-d013-46d46de92c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 61,100,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.49\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 242.16\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,044,810\n",
      "Trainable params: 57,044,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.48\n",
      "Params size (MB): 217.61\n",
      "Estimated Total Size (MB): 226.68\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training on cuda\n",
      "epoch 1, train loss 0.9793, train acc 0.654, test loss 0.7315, test acc 0.740, time 126.4 sec\n",
      "epoch 2, train loss 0.6691, train acc 0.765, test loss 0.6134, test acc 0.787, time 126.4 sec\n",
      "epoch 3, train loss 0.5824, train acc 0.796, test loss 0.5751, test acc 0.799, time 125.9 sec\n",
      "epoch 4, train loss 0.5360, train acc 0.812, test loss 0.5419, test acc 0.810, time 126.6 sec\n",
      "epoch 5, train loss 0.5002, train acc 0.826, test loss 0.5145, test acc 0.820, time 126.0 sec\n",
      "epoch 6, train loss 0.4713, train acc 0.835, test loss 0.4920, test acc 0.827, time 126.1 sec\n",
      "epoch 7, train loss 0.4556, train acc 0.841, test loss 0.4850, test acc 0.829, time 126.0 sec\n",
      "epoch 8, train loss 0.4285, train acc 0.851, test loss 0.4657, test acc 0.839, time 125.4 sec\n",
      "epoch 9, train loss 0.4126, train acc 0.855, test loss 0.4523, test acc 0.844, time 125.7 sec\n",
      "epoch 10, train loss 0.4008, train acc 0.860, test loss 0.4378, test acc 0.840, time 125.6 sec\n",
      "epoch 11, train loss 0.3886, train acc 0.864, test loss 0.4327, test acc 0.850, time 124.9 sec\n",
      "epoch 12, train loss 0.3771, train acc 0.867, test loss 0.4325, test acc 0.849, time 124.3 sec\n",
      "epoch 13, train loss 0.3646, train acc 0.872, test loss 0.4315, test acc 0.850, time 123.9 sec\n",
      "epoch 14, train loss 0.3594, train acc 0.873, test loss 0.4201, test acc 0.849, time 123.8 sec\n",
      "epoch 15, train loss 0.3446, train acc 0.879, test loss 0.4267, test acc 0.852, time 125.3 sec\n",
      "epoch 16, train loss 0.3376, train acc 0.881, test loss 0.4051, test acc 0.859, time 126.1 sec\n",
      "epoch 17, train loss 0.3304, train acc 0.885, test loss 0.4023, test acc 0.861, time 126.0 sec\n",
      "epoch 18, train loss 0.3214, train acc 0.888, test loss 0.4024, test acc 0.856, time 126.4 sec\n",
      "epoch 19, train loss 0.3116, train acc 0.891, test loss 0.4064, test acc 0.860, time 126.4 sec\n",
      "epoch 20, train loss 0.3055, train acc 0.893, test loss 0.3911, test acc 0.864, time 126.3 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# rede baseada na AlexNet-5 \n",
    "net = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "\n",
    "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
    "                                # and stored weights. \n",
    "\n",
    "num_ftrs = net.classifier[6].in_features\n",
    "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
    "\n",
    "# Sending model to device\n",
    "net.to(device)\n",
    "\n",
    "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
    "print(net)\n",
    "\n",
    "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
    "print(summary(net,(3,227,227))) \n",
    "\n",
    "# Treinando a última camada da rede acima\n",
    "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
    "# tamanho do batch, e lambda do weight decay\n",
    "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
    "\n",
    "\n",
    "# função de custo (ou loss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# carregamento do dado: mnist\n",
    "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
    "\n",
    "# trainer do gluon\n",
    "trainer = optim.SGD([\n",
    "                {'params': net.features.parameters(), 'lr': lr * 0.1},\n",
    "                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n",
    "                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n",
    "\n",
    "# treinamento e validação via Pytorch\n",
    "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
    "                num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_uFa_Msi-EP"
   },
   "source": [
    "## Prática\n",
    "\n",
    "1. É possível melhorar o resultado obtido anteriormente?\n",
    "Estude o [model_zoo](https://pytorch.org/docs/stable/torchvision/models.html)  e tente usar as estratégias anteriores com diferentes redes neurais para melhorar o resultado.\n",
    "Algumas redes possíveis:\n",
    "\n",
    "- [MobileNets](https://arxiv.org/abs/1801.04381)\n",
    "- [VGGs](https://arxiv.org/abs/1409.1556)\n",
    "- [ResNets](https://arxiv.org/abs/1603.05027)\n",
    "- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
    "\n",
    "2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratégia é melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n",
    "\n",
    "3. Procura usar outros algoritmos de aprendizado de máquina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraídas de uma rede neural pré-treinada.\n",
    "  1. Procure também extrair e classificar *features* de outras camadas convolucionais.\n",
    "\n",
    "4. Procure usar as diferentes estratégias para melhorar os resultados dos datasets que já usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUpWzBLYguiU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "02.1 - Estrategias-de-treino.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
