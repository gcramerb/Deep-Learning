{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03.1 - Camada-dilatada-e-separavel.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uT4cwsIl3pFL","colab_type":"text"},"source":["# Outras Camadas Convolucionais\n","\n","Além das camadas convolucionais padrões, algumas outras surgiram tentando melhorar alguns quesitos da convolução tradicional.\n","\n","Entre elas estão:\n","\n","- [convolução dilatada](https://arxiv.org/abs/1511.07122) (*dilated convolution*), que permite que o filtro convolucional tenha *buracos* aumentando o *receptive field* mas mantendo a resolução da imagem, e \n","- [convolução separável por canal](https://arxiv.org/abs/1704.04861) (*depthwise separable convolution*), que, de acordo com a literatura, alcança resultados similares ao da convolução padrão porém usando menos parâmetros (por isso, são mais rápidas)."]},{"cell_type":"markdown","metadata":{"id":"0sZ45Vhc3u5-","colab_type":"text"},"source":["Antes de começar, vamos instalar o Pytorch. Esse pequeno bloco de código abaixo é usado somente para instalar o Pytorch para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","**ATENÇÃO: a alteração deste bloco pode implicar em problemas na execução dos blocos restantes!**"]},{"cell_type":"code","metadata":{"id":"BlPJCBIC43x1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"39be2bc7-b5db-42a1-a334-a96772845856","executionInfo":{"status":"ok","timestamp":1571254022358,"user_tz":180,"elapsed":6137,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}}},"source":["!pip3 install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-y2OZ2LW44JO","colab_type":"code","colab":{}},"source":["import time, os, sys, numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","from torchsummary import summary\n","\n","\n","import time, os, sys, numpy as np\n","\n","# Test if GPU is avaliable, if not, use cpu instead\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n = torch.cuda.device_count()\n","devices_ids= list(range(n))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"125j0Pz145zN","colab_type":"code","colab":{}},"source":["def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n","        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n","    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","\n","\n","    train_iter = torch.utils.data.DataLoader(mnist_train,\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = torch.utils.data.DataLoader(mnist_test,\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True,download=True,transform=transformer)\n","    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False,download=True,transform=transformer)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","\n","\n","    train_iter = torch.utils.data.DataLoader(mnist_train,\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = torch.utils.data.DataLoader(mnist_test,\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.type() != features.type():\n","        labels = labels.type(features.type())\n","    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n","            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","\n","    acc_sum, n, l = torch.Tensor([0]), 0, 0\n","    \n","    with torch.no_grad():\n","      for X, y in data_iter:\n","          #y = y.astype('float32')\n","          X, y = X.to(device), y.to(device)\n","          y_hat = net(X)\n","          l += loss(y_hat, y).sum()\n","          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","          n += y.size()[0]\n","\n","    return acc_sum.item() / n, l.item() / len(data_iter)\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n","                   num_epochs):\n","    print('training on', device)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            trainer.zero_grad()\n","            l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step()\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.size()[0]\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CkvT5yvj57ff","colab_type":"text"},"source":["## Convolucional Dilatada (*Dilated Convolution*)\n","\n","Nas camadas convolucionais dilatadas, os pesos do filtro são empregados de maneira diferente quando comparados às convoluções padrão.\n","Especificamente, os filtros dessa camada não precisam ser contíguos e podem ter lacunas (ou \"buracos\") entre seus parâmetros.\n","Essas lacunas, inseridas de acordo com a taxa de dilatação $r \\in \\mathbb{N}$, que permite um aumento do tamanho do filtro convolucional, preservando o número de parâmetros treináveis, uma vez que os buracos inseridos não são considerados no processo de convolução.\n","Portanto, esta taxa de dilatação $ r $ pode ser vista como um parâmetro responsável por definir o alinhamento final dos pesos.\n","\n","Formalmente, uma convolução dilatada 2-D recebe uma entrada em duas dimensões $ Y $, uma taxa de dilatação $ R $ e um vetor de peso 2-D $ W $ (neste caso, com tamanho $ n \\times n $) e processos eles dessa forma: \n","\n","$$ Y[k, l] = \\sum_{i=1}^{n} \\sum_{j=1}^{n} X(k + r \\times i, l + r \\times j) K(i,j) $$\n",", onde $Y$ é a saída ou *feature map*.\n","Observe as diferenças entre a dilatação e a convolução padrão apresentadas na aula anterior.\n","\n","O efeito da taxa de dilatação diferente $ r $ é apresentado na figura abaixo.\n","Como pode ser visto, taxas menores resultam em um filtro mais clusterizado (na verdade, a taxa 1 gera um filtro idêntico à convolução padrão) enquanto as taxas maiores fazem uma expansão do filtro, produzindo um kernel maior com vários buracos.\n","Como todo esse processo de dilatação do filtro é independente dos dados de entrada, alterar a taxa de dilatação não afeta a resolução do resultado, ou seja, em uma convolução dilatada, independente da taxa, a entrada e a saída têm a mesma resolução (considerando, claro, o efeito do *padding* e do *stride*).\n","\n","<p align=\"center\">\n","  <img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1HixSXbx3HKWUrcCqJ8d-IF-RTykoT2Pz\">\n","</p>\n","\n","<p align=\"center\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/0*oX5IPr7TlVM2NpEU.gif\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/0*3cTXIemm0k3Sbask.gif\">\n","</p>\n","\n","Ao ampliar o filtro (com essas lacunas), a rede expande seu campo receptivo (já que os pesos serão organizados em uma forma mais esparsa), mas preserva a resolução e nenhuma redução de resolução nos dados é executada.\n","Portanto, esse processo tem várias vantagens, como:\n","(i) suporta a expansão do campo receptivo sem aumentar o número de parâmetros treináveis por camada, o que reduz a carga computacional, e\n","(ii) preserva a resolução do mapa de características, o que pode ajudar a rede a extrair informações ainda mais úteis dos dados, principalmente de pequenos objetos.\n","\n","### Campo Receptivo (*Receptive Field*)\n","\n","O campo receptivo é definido como a região no espaço de entrada que tem influência sobre a saída atual da rede convolucional.\n","\n","<p align=\"center\">\n","  <img src=\"https://miro.medium.com/max/1000/1*mModSYik9cD9XJNemdTraw.png\">\n","</p>\n","\n","### Implementação\n","\n","No Pytorch, a [camada convolução padrão](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) tem suporte para dilatação dos filtros de acordo com o parâmetro *dilation*.\n"]},{"cell_type":"code","metadata":{"id":"uRZAhVA947KE","colab_type":"code","colab":{}},"source":["class LeNet(nn.Module):\n","    def __init__(self, input_channels, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","\n","        self.conv1 = nn.Conv2d(in_channels=input_channels,out_channels=6, kernel_size=6, stride=1, padding=0)              # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)                                                              # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, dilation=2)             # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","        # self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)                                                            # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","        # self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0, activation='tanh')  # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","        self.flatten  = nn.Flatten()                   # lineariza formando um vetor                                       # entrada: (b, 120, 1, 1) e saida: (b, 120*20*20) = (b, 48000)\n","        self.fc1 = nn.Linear(400, 84)   # Com a dilatação teremos entrada (b, 400)                                         # entrada: (b, 48000) e saida: (b, 84)\n","        self.fc2 = nn.Linear(84, classes)                                                                                  # entrada: (b, 84) e saida: (b, 10) \n","\n","\n","    def forward(self, x):\n","\n","        output_conv1 = F.tanh(self.conv1(x))\n","        output_avgpool1 = self.avgpool1(output_conv1)\n","        output_conv2 = F.tanh(self.conv2(output_avgpool1))\n","        # print(x.shape)\n","        # x = self.avgpool2(x)\n","        # x = self.conv3(x)\n","        flatten_output = self.flatten(output_conv2)\n","        output_fc1 = F.tanh(self.fc1(flatten_output))\n","        output = self.fc2(output_fc1)\n","\n","        return output "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJoGUPx7_0V4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"outputId":"344ea845-8810-430a-8dc9-75456d86c286","executionInfo":{"status":"ok","timestamp":1571256848464,"user_tz":180,"elapsed":196257,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","\n","# rede baseada na AlexNet-5 \n","net = LeNet(1, 10)\n","\n","# Sending model to device\n","net.to(device)\n","print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n","                                # and stored weights. \n","\n","# função de custo (ou loss)\n","loss = nn.CrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","# treinamento e validação via Pytorch\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","                num_epochs)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 27, 27]             222\n","         AvgPool2d-2            [-1, 6, 13, 13]               0\n","            Conv2d-3             [-1, 16, 5, 5]           2,416\n","           Flatten-4                  [-1, 400]               0\n","            Linear-5                   [-1, 84]          33,684\n","            Linear-6                   [-1, 10]             850\n","================================================================\n","Total params: 37,172\n","Trainable params: 37,172\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.05\n","Params size (MB): 0.14\n","Estimated Total Size (MB): 0.19\n","----------------------------------------------------------------\n","None\n","training on cuda\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1, train loss 0.6004, train acc 0.775, test loss 0.4940, test acc 0.823, time 10.0 sec\n","epoch 2, train loss 0.4006, train acc 0.852, test loss 0.4459, test acc 0.838, time 9.8 sec\n","epoch 3, train loss 0.3661, train acc 0.865, test loss 0.3993, test acc 0.852, time 10.0 sec\n","epoch 4, train loss 0.3483, train acc 0.872, test loss 0.3798, test acc 0.862, time 9.9 sec\n","epoch 5, train loss 0.3268, train acc 0.880, test loss 0.3729, test acc 0.868, time 10.0 sec\n","epoch 6, train loss 0.3178, train acc 0.884, test loss 0.3983, test acc 0.860, time 9.9 sec\n","epoch 7, train loss 0.3027, train acc 0.888, test loss 0.3700, test acc 0.869, time 10.0 sec\n","epoch 8, train loss 0.2949, train acc 0.890, test loss 0.3739, test acc 0.869, time 9.9 sec\n","epoch 9, train loss 0.2847, train acc 0.895, test loss 0.3696, test acc 0.872, time 10.0 sec\n","epoch 10, train loss 0.2771, train acc 0.897, test loss 0.3825, test acc 0.868, time 9.8 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OTY9u26LFWAn","colab_type":"text"},"source":["Para efeito de **comparação**, recriamos a rede sem as duas camadas convolucionais (removidas na arquitetura anterior) e sem camadas dilatadas. Dessa forma, podemos observar o ganho das convoluções dilatadas."]},{"cell_type":"code","metadata":{"id":"KduV4haLAGNH","colab_type":"code","colab":{}},"source":["class LeNet(nn.Module):\n","    def __init__(self, input_channels, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","\n","        self.conv1 = nn.Conv2d(in_channels=input_channels,out_channels=6, kernel_size=6, stride=1, padding=0)              # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)                                                              # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)                         # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","        # self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)                                                            # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","        # self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0, activation='tanh')  # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","        self.flatten  = nn.Flatten()                   # lineariza formando um vetor                                       # entrada: (b, 120, 1, 1) e saida: (b, 120*20*20) = (b, 48000)\n","        self.fc1 = nn.Linear(1296, 84)   # Com a dilatação teremos entrada (b, 400)                                         # entrada: (b, 48000) e saida: (b, 84)\n","        self.fc2 = nn.Linear(84, classes)                                                                                  # entrada: (b, 84) e saida: (b, 10) \n","\n","\n","    def forward(self, x):\n","\n","        output_conv1 = F.tanh(self.conv1(x))\n","        output_avgpool1 = self.avgpool1(output_conv1)\n","        output_conv2 = F.tanh(self.conv2(output_avgpool1))\n","        # print(x.shape)\n","        # x = self.avgpool2(x)\n","        # x = self.conv3(x)\n","        flatten_output = self.flatten(output_conv2)\n","        output_fc1 = F.tanh(self.fc1(flatten_output))\n","        output = self.fc2(output_fc1)\n","\n","        return output "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ePkwQp-Fh55","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"outputId":"71b7e50e-1410-477a-a563-de7fc209bec9","executionInfo":{"status":"ok","timestamp":1571256749100,"user_tz":180,"elapsed":102085,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","\n","# rede baseada na AlexNet-5 \n","net = LeNet(1, 10)\n","\n","# Sending model to device\n","net.to(device)\n","print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n","                                # and stored weights. \n","\n","# função de custo (ou loss)\n","loss = nn.CrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","# treinamento e validação via Pytorch\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","                num_epochs)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 27, 27]             222\n","         AvgPool2d-2            [-1, 6, 13, 13]               0\n","            Conv2d-3             [-1, 16, 9, 9]           2,416\n","           Flatten-4                 [-1, 1296]               0\n","            Linear-5                   [-1, 84]         108,948\n","            Linear-6                   [-1, 10]             850\n","================================================================\n","Total params: 112,436\n","Trainable params: 112,436\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.06\n","Params size (MB): 0.43\n","Estimated Total Size (MB): 0.49\n","----------------------------------------------------------------\n","None\n","training on cuda\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1, train loss 0.5775, train acc 0.788, test loss 0.4875, test acc 0.821, time 10.2 sec\n","epoch 2, train loss 0.4400, train acc 0.842, test loss 0.4543, test acc 0.832, time 10.1 sec\n","epoch 3, train loss 0.4067, train acc 0.853, test loss 0.4199, test acc 0.848, time 10.2 sec\n","epoch 4, train loss 0.3881, train acc 0.859, test loss 0.4041, test acc 0.854, time 10.1 sec\n","epoch 5, train loss 0.3754, train acc 0.863, test loss 0.4239, test acc 0.845, time 10.0 sec\n","epoch 6, train loss 0.3536, train acc 0.871, test loss 0.3918, test acc 0.859, time 10.0 sec\n","epoch 7, train loss 0.3438, train acc 0.875, test loss 0.4177, test acc 0.850, time 10.1 sec\n","epoch 8, train loss 0.3404, train acc 0.875, test loss 0.4145, test acc 0.849, time 10.1 sec\n","epoch 9, train loss 0.3299, train acc 0.879, test loss 0.3908, test acc 0.859, time 10.1 sec\n","epoch 10, train loss 0.3137, train acc 0.884, test loss 0.3878, test acc 0.862, time 10.1 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"udS_9i9MGu5T","colab_type":"text"},"source":["A acurácia atingida no teste é praticamente a mesma para os dois modelos. No entanto, na rede com dilation o número de parâmetros é quase 4 vezes menor, sendo assim, uma probabilidade menor de acontecer um overfitt. "]},{"cell_type":"markdown","metadata":{"id":"NfAUBwZiGWsM","colab_type":"text"},"source":["## Convolução Separável por Canal (*Depthwise Separable Convolution*)\n","\n","Após o resurgimento das redes neurais, a cada nova arquitetura proposta, mais e mais camadas e parâmetros foram sendo usados. Por exemplo, a primeira arquitetura dessa nova onda, a [AlexNet](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi6usf1sqXjAhWFGLkGHXhPBC4QFjAAegQIAhAC&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&usg=AOvVaw2hqjjvSjIpuuCLLdojAmS5), tem **61.100.840** de parâmetros.\n","\n","Claramente, pelo tamanho de parâmetros, arquitetura como essas não são passíveis de serem treinadas em dispositivos com menos memória, como sistema embarcados, celulares, tablets, etc.\n","Por isso, uma linha de pesquisa procura otimizar o uso dos parâmetros em rede neurais.\n","Para esse fim, essa linha de pesquisa propôs uma nova camada, chamada Convolução Separável por Canal (*Depthwise Separable Convolution*), que é capaz de reproduzir arquiteturas convolucionais, obtendo resultados similar, porém com menos parâmetros.\n","\n","A ideia por trás dessa camada é representada abaixo. Ao invés de ter uma única camada de convolução que processará toda a entrada (ou seja, terá parâmetros para todos os canais de entrada), essa convolução é dividida em duas partes. Na primeira parte, cada canal é processado separadamente por um filtro específico. Formalmente, suponha que a entrada tenha $c_i$ canais.\n","Nesse caso, a primeira parte de convolução terá  $c_i$ filtros de tamanho $k\\times k$, onde cada um desses filtros processará somente um canal da entrada, gerando $c_i$ *feature maps* de saída. Na segunda parte, esses *feature maps* serão processados por uma convolução $1\\times 1$, que gerará a saída final esperada. Suponha que queiramos que essa camada gere $c_o$ canais de saída. Essa segunda parte terá $c_o$ filtros de $1\\times 1$ que processarão os *feature maps* gerados na primeira parte, gerando a saída final com $c_o$ canais.\n","\n","<p align=\"center\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/1*Voah8cvrs7gnTDf6acRvDw.png\">\n","</p>\n","\n","Vamos examinar a diferença entre a convolução padrão e a convolução separável por canal em termos de número de parâmetros. Suponha que:\n","\n","- n, seja a dimensão espacial (largura e altura), da entrada,\n","- k, seja largura e altura do filtro,\n","- c_i, seja o número de canais de entrada, e\n","- c_o, o número de canais de saída.\n","\n","Uma convolução regular tem k * k * c_i * c_o parâmetros, porque, para cada canal de saída, há um filtro $k\\times k$ para cada canal de entrada.\n","Em contrapartida, as convoluções separáveis por canal tem k * k * c_i parâmetros na primeira parte e, em seguida,  1 * 1 * c_i * c_o parâmetros para a segunda parte. Deve ser óbvio que, para um c_o não trivial, a soma desses dois é significativamente menor que k * k * c_i * c_o.\n","\n","Agora, vamos comparar o custo computacional. Para uma convolução regular, realizamos K * K * c_i operações em cada posição da entrada (para calcular a convolução 2D em 3 dimensões). Para toda a entrada, o número de cálculos é, portanto, k * k * c_i * n * n e tomando todos os canais de saída, obtemos k * k * c_i * n * n * c_o.\n","Para convoluções separáveis em profundidade, precisamos de operações k * k * c_i * n * n para a parte de profundidade; então precisamos de n * n * c_i * c_o operações para a parte de mistura. \n","\n","Vamos usar alguns números reais para sentir a diferença.\n","Assumiremos \n","\n","- n = 128, \n","- k = 3, \n","- c_i = 3, \n","- c_o = 16. \n","\n","Para convolução regular:\n","\n","     Parâmetros: 3 * 3 * 3 * 16 = 432\n","     Custo de computação: 3 * 3 * 3 * 128 * 128 * 16 = ~ 7e6\n","\n","Para a convolução separável em profundidade:\n","\n","     Parâmetros: 3 * 3 * 3 + 3 * 16 = 75\n","     Custo de computação: 3 * 3 * 3 * 128 * 128 + 128 * 128 * 3 * 16 = ~ 1.2e6"]},{"cell_type":"markdown","metadata":{"id":"D33G5ucaGZUf","colab_type":"text"},"source":["Frameworks modernos implementam esse tipo de camada de forma diferente. No Pytorch, nosso caso de estudo, a primeira parte dessa convolução é feita quando se coloca o [número de grupos da camada convolucional igual ao número de canais de entrada](https://github.com/apache/incubator-mxnet/issues/10142#issuecomment-373895855). Esse [parâmetro](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) é usado para definir o agrupamento entre canais de entrada e filtros/neurônios. Logo, quando se tem um número de canais de entrada igual ao número de filtros, e também igual ao número de grupos. Dessa forma, cada filtro processará somente um canal.\n","\n","Já a segunda parte dessa convolução é feita naturalmente, usando o *kernel*=1.\n","\n","Abaixo, implementamos a LeNet-5 usando essa convolução.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/09/LeNEt_Summary_Table.jpg\">\n","</p>\n"]},{"cell_type":"code","metadata":{"id":"xwj2n_kxFjmI","colab_type":"code","colab":{}},"source":["class LeNet(nn.Module):\n","    def __init__(self,input_channels, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","        self.conv1_1 = nn.Conv2d(in_channels=input_channels, out_channels=1, kernel_size=5, stride=1, padding=0, groups=1)  # entrada: (b, 1, 32, 32) e saida: (b, 1, 28, 28)\n","        self.conv1_2 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=1, stride=1, padding=0)                         # entrada: (b, 1, 28, 28) e saida: (b, 6, 28, 28)\n","        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)                                                               # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","        \n","        self.conv2_1 = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=5, stride=1, padding=0, groups=6)               # entrada: (b, 6, 14, 14) e saida: (b, 6, 10, 10)\n","        self.conv2_2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=1, stride=1, padding=0)                        # entrada: (b, 6, 10, 10) e saida: (b, 16, 10, 10)\n","        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)                                                               # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","        \n","        self.conv3_1 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=0, groups=16)            # entrada: (b, 16, 5, 5) e saida: (b, 16, 1, 1)\n","        self.conv3_2 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=1, stride=1, padding=0)                      # entrada: (b, 16, 1, 1) e saida: (b, 120, 1, 1)\n","\n","        self.flatten = nn.Flatten()  # lineariza formando um vetor                                                          # entrada: (b, 120, 1, 1) e saida: (b, 120*1*1) = (b, 120)\n","        self.fc1 = nn.Linear(120,84)                                                                                        # entrada: (b, 120) e saida: (b, 84)\n","        self.fc2 = nn.Linear(84,classes)                                                                                    3# entrada: (b, 84) e saida: (b, 10)\n","\n","    def forward(self, x):\n","        # print('x', x.shape)\n","        output_conv1_1 = self.conv1_1(x)\n","        # print('conv1_1', x.shape)\n","        output_conv1_2 = F.tanh(self.conv1_2(output_conv1_1))\n","        # print('conv1_2', x.shape)\n","        output_avgpool1 = self.avgpool1(output_conv1_2)\n","        output_conv2_1 = self.conv2_1(output_avgpool1)\n","        # print('conv2_1', x.shape)\n","        output_conv2_2 = F.tanh(self.conv2_2(output_conv2_1))\n","        # print('conv2_2', x.shape)\n","        output_avgpool2 = self.avgpool2(output_conv2_2)\n","        output_conv3_1 = self.conv3_1(output_avgpool2)\n","        # print('conv3_1', x.shape)\n","        output_conv3_2 = F.tanh(self.conv3_2(output_conv3_1))\n","        # print('conv3_2', x.shape)\n","        output_flatten = self.flatten(output_conv3_2)\n","        output_fc1 = F.tanh(self.fc1(output_flatten))\n","        output = self.fc2(output_fc1)\n","\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsDktcegK2YS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"39ada151-092e-4f17-c2ea-79bc03bc2898","executionInfo":{"status":"ok","timestamp":1571256502824,"user_tz":180,"elapsed":114795,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.01, 128, 0.000001\n","\n","# rede baseada na AlexNet-5 \n","net = LeNet(1, 10)\n","\n","# Sending model to device\n","net.to(device)\n","print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n","                                # and stored weights. \n","\n","# função de custo (ou loss)\n","loss = nn.CrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\n","\n","# treinamento e validação via Pytorch\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","                num_epochs)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 1, 28, 28]              26\n","            Conv2d-2            [-1, 6, 28, 28]              12\n","         AvgPool2d-3            [-1, 6, 14, 14]               0\n","            Conv2d-4            [-1, 6, 10, 10]             156\n","            Conv2d-5           [-1, 16, 10, 10]             112\n","         AvgPool2d-6             [-1, 16, 5, 5]               0\n","            Conv2d-7             [-1, 16, 1, 1]             416\n","            Conv2d-8            [-1, 120, 1, 1]           2,040\n","           Flatten-9                  [-1, 120]               0\n","           Linear-10                   [-1, 84]          10,164\n","           Linear-11                   [-1, 10]             850\n","================================================================\n","Total params: 13,776\n","Trainable params: 13,776\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.07\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 0.13\n","----------------------------------------------------------------\n","None\n","training on cuda\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1, train loss 0.7262, train acc 0.725, test loss 0.5702, test acc 0.784, time 11.4 sec\n","epoch 2, train loss 0.5160, train acc 0.809, test loss 0.5542, test acc 0.792, time 11.3 sec\n","epoch 3, train loss 0.4765, train acc 0.824, test loss 0.5051, test acc 0.812, time 11.3 sec\n","epoch 4, train loss 0.4611, train acc 0.830, test loss 0.4653, test acc 0.831, time 11.4 sec\n","epoch 5, train loss 0.4404, train acc 0.839, test loss 0.4471, test acc 0.836, time 11.3 sec\n","epoch 6, train loss 0.4273, train acc 0.843, test loss 0.4798, test acc 0.824, time 11.3 sec\n","epoch 7, train loss 0.4254, train acc 0.844, test loss 0.4483, test acc 0.836, time 11.5 sec\n","epoch 8, train loss 0.4179, train acc 0.846, test loss 0.4646, test acc 0.830, time 11.3 sec\n","epoch 9, train loss 0.4163, train acc 0.845, test loss 0.4709, test acc 0.834, time 11.3 sec\n","epoch 10, train loss 0.4171, train acc 0.848, test loss 0.4547, test acc 0.833, time 11.5 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oD4mk7lcLUtr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}