{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBvUmcHxonaS"
   },
   "source": [
    "# Aprendizado Profundo - UFMG\n",
    "\n",
    "## Preâmbulo\n",
    "\n",
    "O código abaixo consiste dos imports comuns. Além do mais, configuramos as imagens para ficar de um tamanho aceitável e criamos algumas funções auxiliares. No geral, você pode ignorar a próxima célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4_nqeBgonaV"
   },
   "outputs": [],
   "source": [
    "# !pip install mxnet-cu100==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-iRUIgyouKm"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize']  = (18, 10)\n",
    "plt.rcParams['axes.labelsize']  = 20\n",
    "plt.rcParams['axes.titlesize']  = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 4\n",
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5J4r1Joonac"
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams['figure.figsize']  = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1hxSo7nonag"
   },
   "source": [
    "Para testar o resultado dos seus algoritmos vamos usar o módulo testing do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKAN6JuJonah"
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_equal\n",
    "from numpy.testing import assert_almost_equal\n",
    "from numpy.testing import assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FVe1G2wonak"
   },
   "source": [
    "## Aula 02 - Regressão Linear e Logística from Scratch\n",
    "\n",
    "Para brincar um pouco mais com essa diferenciação automatica, presente em frameworks como pytorch e mxnet, nesta aula vamos implementar a regressão linear e logística do zero. Vamos fazer duas versões de cada:\n",
    "\n",
    "1. Derivando na mão, não é complicado.\n",
    "2. Derivando com autograd de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waN0vx9fonal"
   },
   "source": [
    "## Conjunto de Problemas 1: Mais Derivadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK0g7SKdonam"
   },
   "source": [
    "Antes de entrar na regressão, vamos brincar um pouco de derivadas dentro de funções. Dado dois números `x` and `y`, implemente a função `log_exp` que retorna:\n",
    "\n",
    "$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsgyDlAHpBdZ"
   },
   "outputs": [],
   "source": [
    "def log_exp(x, y):\n",
    "    return (-torch.log(torch.exp(x) / (torch.exp(x) + torch.exp(y)))).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnoHouBPonap"
   },
   "source": [
    "1. Abaixo vamos testar o seu código com algumas entradas simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2fd-sln-w2Op",
    "outputId": "ccd69185-7759-4ce6-9aec-68f2049bb32e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3132617474], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = torch.tensor([2.0]), torch.tensor([3.0])\n",
    "z = log_exp(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQNEAUNoonau"
   },
   "outputs": [],
   "source": [
    "# Teste. Não apague\n",
    "assert_almost_equal(1.31326175, z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdhvPzMxonax"
   },
   "source": [
    "2. Agora implementa uma função para computar $\\partial z/\\partial x$ e $\\partial z/\\partial y$ usando `autograd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHBQrZD7qsYN"
   },
   "outputs": [],
   "source": [
    "# O argumento funcao_forward é uma função python. Será a sua log_exp.\n",
    "# A ideia aqui é deixar claro a ideia de forward e backward propagation, depois\n",
    "# de avaliar a função chamamos backward e temos as derivadas.\n",
    "def grad(funcao_forward, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "    z = funcao_forward(x, y)\n",
    "    z.backward()\n",
    "    return x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WFpkBMvona2"
   },
   "source": [
    "Testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMVfDIKQrAJL"
   },
   "outputs": [],
   "source": [
    "x, y = torch.tensor([2.0], dtype = torch.double) ,torch.tensor([3.0], dtype = torch.double)\n",
    "dx, dy = grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIkTfFH0snPD"
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(-0.7310586, dx.numpy())\n",
    "assert_almost_equal(0.7310586, dy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oNpz1wIona9"
   },
   "source": [
    "4. Agora teste com números maiores, algum problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0qEsHY5VsuH_",
    "outputId": "2526c869-f329-415b-9900-92312e526d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = torch.tensor([400.0]).double() ,torch.tensor([800.0]).double() #Problema: com os numeros originais do nb o pytorch nao dava nan se a variavel fosse double (necessario para que o stable funcione), entao aumentao os numeros significantemente\n",
    "grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGUiPmJLonbB"
   },
   "source": [
    "5. Pense um pouco sobre o motivo do erro acima. Usando as propriedade de logaritmos, é possível fazer uma função mais estável? Implemente a mesma abaixo. O problema aqui é que o exponencial \"explode\" quando x ou y são muito grandes. Use o [link](http://www.wolframalpha.com/input/?i=log[e%5Ex+%2F+[e%5Ex+%2B+e%5Ey]]) para lhe ajudar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnj8B4EyttvL"
   },
   "outputs": [],
   "source": [
    "x, y = torch.tensor([400.0], dtype = torch.double) ,torch.tensor([800.0], dtype = torch.double)\n",
    "def stable_log_exp(x, y):\n",
    "    return torch.log(torch.exp(y-x) )\n",
    "dx = 0\n",
    "\n",
    "dx, dy = grad(stable_log_exp, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B9QIVgN1onbF",
    "outputId": "cf866822-eaac-4df4-ee3a-bcbcfad0a83c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([400.], dtype=torch.float64, grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_log_exp(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVWzzA4-t9J2"
   },
   "outputs": [],
   "source": [
    "# Teste. Não apague\n",
    "assert_equal(-1, dx.numpy())\n",
    "assert_equal(1, dy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esV2XR7jonbL"
   },
   "source": [
    "O exemplo acima mostra um pouco de problemas de estabilidade númerica. às vezes é melhor usar versões alternativas de funções. Isto vai ocorrer quando você ver vários nans na sua frente :-) Claro, estamos assumindo que existe uma outra função equivalente que é mais estável para o computador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qI91TX7onbM"
   },
   "source": [
    "## Conjunto de Problemas 2: Regressão Linear\n",
    "\n",
    "Agora, vamos explorar uma regressão linear. Embora não vamos fazer uso da logexp acima, a ideia de derivar parcialmente dentro de funções pode nos ajudar. Lembrando da regressão linear, inicialmente temos um conjunto observações representadas como tuplas $(\\mathbf{x}_i, y_i)$. Aqui, $\\mathbf{x}_i$ é um vetor de atributos. Vamo forçar $\\mathbf{x}_{i0} = 1$, capturando assim o intercepto. Além do mais, $\\mathbf{x}_{ij}$ quando $j\\neq 0$, são os outros atributos de entrada. $y_i$ uma valor real representando uma resposta. Nossa regressão visa capturar:\n",
    "\n",
    "$$y_i = 1 + \\theta_1 x_{i1} + \\theta_2 x_{i2} + \\cdots + \\theta_k x_{if}$$\n",
    "\n",
    "Lembrando da regressão linear multivariada, podemos representar as equações como uma multiplicação de uma matriz com um vetor\n",
    "\n",
    "![](./figs/linear.png)\n",
    "\n",
    "7. Crie uma função de previsao. A mesma recebe uma matrix $\\mathbf{X}$ e um vetor de parâmetros $\\theta$. Sua função deve retornar um vetor de previsões para cada linha de $\\mathbf{X}$. Não use nenhum laço!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HveutorucYMJ"
   },
   "outputs": [],
   "source": [
    "def previsao(X, theta):\n",
    "    return torch.matmul(X, theta.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNRX8E0MonbP"
   },
   "source": [
    "**Erros quadrados**. Para aprender os parâmetros ótimos da regressão linear, precisamos fazer uso de um modelo de erros quadrados. Em particular nosso objetico é aprender os parâmetros que minimizam a função:\n",
    "\n",
    "$$L(\\mathbf{\\theta}) = n^{-1} \\sum_i ({\\hat{y}_i - y_i})^2$$\n",
    "\n",
    "Onde $\\hat{y}_i$ é uma previsão (vêm da sua função python acima). $y_i$ é o valor real dos dados.\n",
    "\n",
    "8. Implemente uma função para a média dos os erros quadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sS7y5Wb2cusy"
   },
   "outputs": [],
   "source": [
    "def media_erros_quadrados(X, theta, y):\n",
    "    pred = previsao(X, theta) \n",
    "    return torch.pow(pred- y, 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVqJCucconbT"
   },
   "source": [
    "9. Agora, crie **DUAS** funções que derivam o erro acima. A primeira deve usar o autograd de mxnet. Lembre-se que temos um vetor de parâmetros $\\theta$. Por sorte, você pode fazer derivadas de tais vetores também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ao1G8uSc8Bp"
   },
   "outputs": [],
   "source": [
    "def derivada_torch(X, theta, y): #Lembre que o theta passado devera ser uma variavel com requires_grad == True\n",
    "    e = media_erros_quadrados(X, theta, y)\n",
    "    e.backward()\n",
    "    return theta.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnWTcJubonba"
   },
   "source": [
    "10. A segunda versão não usa autograd. Implemente as derivadas do zero. Nos [slides](https://docs.google.com/presentation/d/1bz3G3fEohNtvERKSDtThfGPYOjF83Fzy2yHPdCAlFZw/edit#slide=id.g584f66d2ae_3_74) do link explicamos como fazer tal operação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBpOTZjPdLrq"
   },
   "outputs": [],
   "source": [
    "def derivada_navera(X, theta, y):\n",
    "    return ((torch.matmul(X, theta) - y) * X.T).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tj5LkKLzonbf"
   },
   "source": [
    "11. Por fim, otimize sua função usando o algoritmo de gradiente descendente abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-9buFPGfVPG"
   },
   "outputs": [],
   "source": [
    "def gd(d_fun, loss_fun, X, y, lambda_=0.01, tol=0.00001, max_iter=10000):\n",
    "    '''\n",
    "    Executa Gradiente Descendente. Aqui:\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    d_fun : é uma função de derivadas\n",
    "    loss_fun : é uma função de perda\n",
    "    X : é um vetor de fatores explanatórios.\n",
    "        Copie seu código de intercepto da primeira aula.\n",
    "        para adicionar o intercepto em X.\n",
    "    y : é a resposta\n",
    "    lambda : é a taxa de aprendizad\n",
    "    tol : é a tolerância, define quando o algoritmo vai parar.\n",
    "    max_ter : é a segunda forma de parada, mesmo sem convergir\n",
    "              paramos depois de max_iter iterações.\n",
    "    '''\n",
    "    theta = torch.randn(X.shape[1])\n",
    "    theta.requires_grad_(True)\n",
    "    \n",
    "    print('Iter {}; theta = '.format(0), theta)\n",
    "    \n",
    "    old_err_sq = np.inf\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Computar as derivadas\n",
    "                \n",
    "        theta.requires_grad_(True)  #Necessario pois ao final, theta recebe o theta novo, que não tem requires_grad == True\n",
    "        grad = d_fun(X,theta,y)\n",
    "\n",
    "        # Atualizar\n",
    "        with torch.no_grad(): \n",
    "            theta_novo = theta - lambda_ * grad\n",
    "        \n",
    "        #Parar quando o erro convergir\n",
    "        err_sq = loss_fun(X, theta, y)\n",
    "        if torch.abs(old_err_sq - err_sq) <= tol:\n",
    "            break\n",
    "        \n",
    "         #Atualizar parâmetros e erro\n",
    "        theta = theta_novo\n",
    "        old_err_sq = err_sq\n",
    "        \n",
    "        # Informação de debug\n",
    "        print('Iter {}; theta = '.format(i+1), theta)\n",
    "        i += 1\n",
    "        if i == max_iter:\n",
    "            break\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVWvK5mffuqd"
   },
   "outputs": [],
   "source": [
    "# Para testes, não apague!!!\n",
    "X = torch.zeros(1000, 2)\n",
    "X[:, 0] = 1.0\n",
    "X[:, 1] = torch.randn(1000)\n",
    "\n",
    "theta_0_real = 7.0\n",
    "theta_1_real = 9.0\n",
    "y = theta_0_real + theta_1_real * X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IxE4o8ALonbm",
    "outputId": "7d907831-9cc7-4145-820c-13bdd44decff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; theta =  tensor([ 1.3832284212, -1.0070865154], requires_grad=True)\n",
      "Iter 1; theta =  tensor([ 1.4967978001, -0.7964086533])\n",
      "Iter 2; theta =  tensor([ 1.6080697775, -0.5901656151])\n",
      "Iter 3; theta =  tensor([ 1.7170909643, -0.3882640004])\n",
      "Iter 4; theta =  tensor([ 1.8239067793, -0.1906124800])\n",
      "Iter 5; theta =  tensor([1.9285619259, 0.0028784722])\n",
      "Iter 6; theta =  tensor([2.0311000347, 0.1922963411])\n",
      "Iter 7; theta =  tensor([2.1315641403, 0.3777268827])\n",
      "Iter 8; theta =  tensor([2.2299959660, 0.5592540503])\n",
      "Iter 9; theta =  tensor([2.3264367580, 0.7369599342])\n",
      "Iter 10; theta =  tensor([2.4209270477, 0.9109250307])\n",
      "Iter 11; theta =  tensor([2.5135059357, 1.0812280178])\n",
      "Iter 12; theta =  tensor([2.6042122841, 1.2479460239])\n",
      "Iter 13; theta =  tensor([2.6930840015, 1.4111545086])\n",
      "Iter 14; theta =  tensor([2.7801580429, 1.5709272623])\n",
      "Iter 15; theta =  tensor([2.8654708862, 1.7273367643])\n",
      "Iter 16; theta =  tensor([2.9490582943, 1.8804535866])\n",
      "Iter 17; theta =  tensor([3.0309550762, 2.0303471088])\n",
      "Iter 18; theta =  tensor([3.1111953259, 2.1770853996])\n",
      "Iter 19; theta =  tensor([3.1898126602, 2.3207345009])\n",
      "Iter 20; theta =  tensor([3.2668399811, 2.4613597393])\n",
      "Iter 21; theta =  tensor([3.3423094749, 2.5990245342])\n",
      "Iter 22; theta =  tensor([3.4162526131, 2.7337913513])\n",
      "Iter 23; theta =  tensor([3.4887001514, 2.8657212257])\n",
      "Iter 24; theta =  tensor([3.5596826077, 2.9948737621])\n",
      "Iter 25; theta =  tensor([3.6292293072, 3.1213073730])\n",
      "Iter 26; theta =  tensor([3.6973695755, 3.2450795174])\n",
      "Iter 27; theta =  tensor([3.7641317844, 3.3662459850])\n",
      "Iter 28; theta =  tensor([3.8295438290, 3.4848618507])\n",
      "Iter 29; theta =  tensor([3.8936328888, 3.6009805202])\n",
      "Iter 30; theta =  tensor([3.9564259052, 3.7146546841])\n",
      "Iter 31; theta =  tensor([4.0179491043, 3.8259358406])\n",
      "Iter 32; theta =  tensor([4.0782279968, 3.9348742962])\n",
      "Iter 33; theta =  tensor([4.1372880936, 4.0415191650])\n",
      "Iter 34; theta =  tensor([4.1951537132, 4.1459193230])\n",
      "Iter 35; theta =  tensor([4.2518491745, 4.2481217384])\n",
      "Iter 36; theta =  tensor([4.3073983192, 4.3481721878])\n",
      "Iter 37; theta =  tensor([4.3618240356, 4.4461164474])\n",
      "Iter 38; theta =  tensor([4.4151492119, 4.5419988632])\n",
      "Iter 39; theta =  tensor([4.4673957825, 4.6358628273])\n",
      "Iter 40; theta =  tensor([4.5185861588, 4.7277507782])\n",
      "Iter 41; theta =  tensor([4.5687413216, 4.8177042007])\n",
      "Iter 42; theta =  tensor([4.6178822517, 4.9057636261])\n",
      "Iter 43; theta =  tensor([4.6660294533, 4.9919691086])\n",
      "Iter 44; theta =  tensor([4.7132029533, 5.0763602257])\n",
      "Iter 45; theta =  tensor([4.7594227791, 5.1589746475])\n",
      "Iter 46; theta =  tensor([4.8047080040, 5.2398495674])\n",
      "Iter 47; theta =  tensor([4.8490777016, 5.3190221786])\n",
      "Iter 48; theta =  tensor([4.8925499916, 5.3965277672])\n",
      "Iter 49; theta =  tensor([4.9351434708, 5.4724016190])\n",
      "Iter 50; theta =  tensor([4.9768757820, 5.5466780663])\n",
      "Iter 51; theta =  tensor([5.0177640915, 5.6193909645])\n",
      "Iter 52; theta =  tensor([5.0578255653, 5.6905727386])\n",
      "Iter 53; theta =  tensor([5.0970768929, 5.7602562904])\n",
      "Iter 54; theta =  tensor([5.1355347633, 5.8284726143])\n",
      "Iter 55; theta =  tensor([5.1732149124, 5.8952527046])\n",
      "Iter 56; theta =  tensor([5.2101335526, 5.9606270790])\n",
      "Iter 57; theta =  tensor([5.2463054657, 6.0246248245])\n",
      "Iter 58; theta =  tensor([5.2817463875, 6.0872755051])\n",
      "Iter 59; theta =  tensor([5.3164706230, 6.1486067772])\n",
      "Iter 60; theta =  tensor([5.3504929543, 6.2086472511])\n",
      "Iter 61; theta =  tensor([5.3838272095, 6.2674236298])\n",
      "Iter 62; theta =  tensor([5.4164876938, 6.3249621391])\n",
      "Iter 63; theta =  tensor([5.4484877586, 6.3812894821])\n",
      "Iter 64; theta =  tensor([5.4798407555, 6.4364309311])\n",
      "Iter 65; theta =  tensor([5.5105600357, 6.4904112816])\n",
      "Iter 66; theta =  tensor([5.5406584740, 6.5432553291])\n",
      "Iter 67; theta =  tensor([5.5701484680, 6.5949869156])\n",
      "Iter 68; theta =  tensor([5.5990419388, 6.6456294060])\n",
      "Iter 69; theta =  tensor([5.6273512840, 6.6952056885])\n",
      "Iter 70; theta =  tensor([5.6550884247, 6.7437381744])\n",
      "Iter 71; theta =  tensor([5.6822648048, 6.7912487984])\n",
      "Iter 72; theta =  tensor([5.7088918686, 6.8377590179])\n",
      "Iter 73; theta =  tensor([5.7349805832, 6.8832898140])\n",
      "Iter 74; theta =  tensor([5.7605419159, 6.9278621674])\n",
      "Iter 75; theta =  tensor([5.7855863571, 6.9714961052])\n",
      "Iter 76; theta =  tensor([5.8101248741, 7.0142111778])\n",
      "Iter 77; theta =  tensor([5.8341670036, 7.0560269356])\n",
      "Iter 78; theta =  tensor([5.8577232361, 7.0969624519])\n",
      "Iter 79; theta =  tensor([5.8808035851, 7.1370358467])\n",
      "Iter 80; theta =  tensor([5.9034171104, 7.1762657166])\n",
      "Iter 81; theta =  tensor([5.9255738258, 7.2146697044])\n",
      "Iter 82; theta =  tensor([5.9472823143, 7.2522649765])\n",
      "Iter 83; theta =  tensor([5.9685521126, 7.2890686989])\n",
      "Iter 84; theta =  tensor([5.9893918037, 7.3250975609])\n",
      "Iter 85; theta =  tensor([6.0098104477, 7.3603677750])\n",
      "Iter 86; theta =  tensor([6.0298166275, 7.3948955536])\n",
      "Iter 87; theta =  tensor([6.0494184494, 7.4286961555])\n",
      "Iter 88; theta =  tensor([6.0686240196, 7.4617848396])\n",
      "Iter 89; theta =  tensor([6.0874414444, 7.4941768646])\n",
      "Iter 90; theta =  tensor([6.1058783531, 7.5258870125])\n",
      "Iter 91; theta =  tensor([6.1239423752, 7.5569295883])\n",
      "Iter 92; theta =  tensor([6.1416416168, 7.5873184204])\n",
      "Iter 93; theta =  tensor([6.1589827538, 7.6170673370])\n",
      "Iter 94; theta =  tensor([6.1759734154, 7.6461901665])\n",
      "Iter 95; theta =  tensor([6.1926207542, 7.6746997833])\n",
      "Iter 96; theta =  tensor([6.2089319229, 7.7026090622])\n",
      "Iter 97; theta =  tensor([6.2249131203, 7.7299304008])\n",
      "Iter 98; theta =  tensor([6.2405714989, 7.7566766739])\n",
      "Iter 99; theta =  tensor([6.2559132576, 7.7828598022])\n",
      "Iter 100; theta =  tensor([6.2709450722, 7.8084917068])\n",
      "Iter 101; theta =  tensor([6.2856731415, 7.8335838318])\n",
      "Iter 102; theta =  tensor([6.3001036644, 7.8581476212])\n",
      "Iter 103; theta =  tensor([6.3142423630, 7.8821940422])\n",
      "Iter 104; theta =  tensor([6.3280954361, 7.9057340622])\n",
      "Iter 105; theta =  tensor([6.3416686058, 7.9287786484])\n",
      "Iter 106; theta =  tensor([6.3549671173, 7.9513378143])\n",
      "Iter 107; theta =  tensor([6.3679971695, 7.9734220505])\n",
      "Iter 108; theta =  tensor([6.3807640076, 7.9950413704])\n",
      "Iter 109; theta =  tensor([6.3932728767, 8.0162057877])\n",
      "Iter 110; theta =  tensor([6.4055285454, 8.0369243622])\n",
      "Iter 111; theta =  tensor([6.4175367355, 8.0572061539])\n",
      "Iter 112; theta =  tensor([6.4293022156, 8.0770616531])\n",
      "Iter 113; theta =  tensor([6.4408297539, 8.0964984894])\n",
      "Iter 114; theta =  tensor([6.4521245956, 8.1155261993])\n",
      "Iter 115; theta =  tensor([6.4631910324, 8.1341533661])\n",
      "Iter 116; theta =  tensor([6.4740338326, 8.1523885727])\n",
      "Iter 117; theta =  tensor([6.4846577644, 8.1702394485])\n",
      "Iter 118; theta =  tensor([6.4950671196, 8.1877145767])\n",
      "Iter 119; theta =  tensor([6.5052657127, 8.2048215866])\n",
      "Iter 120; theta =  tensor([6.5152583122, 8.2215681076])\n",
      "Iter 121; theta =  tensor([6.5250492096, 8.2379617691])\n",
      "Iter 122; theta =  tensor([6.5346422195, 8.2540111542])\n",
      "Iter 123; theta =  tensor([6.5440411568, 8.2697219849])\n",
      "Iter 124; theta =  tensor([6.5532503128, 8.2851018906])\n",
      "Iter 125; theta =  tensor([6.5622735023, 8.3001585007])\n",
      "Iter 126; theta =  tensor([6.5711145401, 8.3148975372])\n",
      "Iter 127; theta =  tensor([6.5797767639, 8.3293266296])\n",
      "Iter 128; theta =  tensor([6.5882639885, 8.3434514999])\n",
      "Iter 129; theta =  tensor([6.5965795517, 8.3572788239])\n",
      "Iter 130; theta =  tensor([6.6047272682, 8.3708152771])\n",
      "Iter 131; theta =  tensor([6.6127104759, 8.3840665817])\n",
      "Iter 132; theta =  tensor([6.6205320358, 8.3970384598])\n",
      "Iter 133; theta =  tensor([6.6281957626, 8.4097375870])\n",
      "Iter 134; theta =  tensor([6.6357045174, 8.4221696854])\n",
      "Iter 135; theta =  tensor([6.6430616379, 8.4343395233])\n",
      "Iter 136; theta =  tensor([6.6502699852, 8.4462528229])\n",
      "Iter 137; theta =  tensor([6.6573328972, 8.4579153061])\n",
      "Iter 138; theta =  tensor([6.6642532349, 8.4693326950])\n",
      "Iter 139; theta =  tensor([6.6710333824, 8.4805097580])\n",
      "Iter 140; theta =  tensor([6.6776766777, 8.4914512634])\n",
      "Iter 141; theta =  tensor([6.6841859818, 8.5021619797])\n",
      "Iter 142; theta =  tensor([6.6905636787, 8.5126476288])\n",
      "Iter 143; theta =  tensor([6.6968126297, 8.5229120255])\n",
      "Iter 144; theta =  tensor([6.7029352188, 8.5329608917])\n",
      "Iter 145; theta =  tensor([6.7089343071, 8.5427980423])\n",
      "Iter 146; theta =  tensor([6.7148118019, 8.5524272919])\n",
      "Iter 147; theta =  tensor([6.7205705643, 8.5618543625])\n",
      "Iter 148; theta =  tensor([6.7262129784, 8.5710830688])\n",
      "Iter 149; theta =  tensor([6.7317414284, 8.5801172256])\n",
      "Iter 150; theta =  tensor([6.7371582985, 8.5889606476])\n",
      "Iter 151; theta =  tensor([6.7424659729, 8.5976181030])\n",
      "Iter 152; theta =  tensor([6.7476663589, 8.6060934067])\n",
      "Iter 153; theta =  tensor([6.7527613640, 8.6143903732])\n",
      "Iter 154; theta =  tensor([6.7577538490, 8.6225128174])\n",
      "Iter 155; theta =  tensor([6.7626452446, 8.6304636002])\n",
      "Iter 156; theta =  tensor([6.7674379349, 8.6382474899])\n",
      "Iter 157; theta =  tensor([6.7721338272, 8.6458673477])\n",
      "Iter 158; theta =  tensor([6.7767348289, 8.6533260345])\n",
      "Iter 159; theta =  tensor([6.7812428474, 8.6606283188])\n",
      "Iter 160; theta =  tensor([6.7856597900, 8.6677761078])\n",
      "Iter 161; theta =  tensor([6.7899875641, 8.6747741699])\n",
      "Iter 162; theta =  tensor([6.7942280769, 8.6816244125])\n",
      "Iter 163; theta =  tensor([6.7983827591, 8.6883306503])\n",
      "Iter 164; theta =  tensor([6.8024535179, 8.6948957443])\n",
      "Iter 165; theta =  tensor([6.8064422607, 8.7013225555])\n",
      "Iter 166; theta =  tensor([6.8103504181, 8.7076139450])\n",
      "Iter 167; theta =  tensor([6.8141794205, 8.7137727737])\n",
      "Iter 168; theta =  tensor([6.8179311752, 8.7198019028])\n",
      "Iter 169; theta =  tensor([6.8216071129, 8.7257041931])\n",
      "Iter 170; theta =  tensor([6.8252086639, 8.7314815521])\n",
      "Iter 171; theta =  tensor([6.8287377357, 8.7371377945])\n",
      "Iter 172; theta =  tensor([6.8321952820, 8.7426748276])\n",
      "Iter 173; theta =  tensor([6.8355832100, 8.7480955124])\n",
      "Iter 174; theta =  tensor([6.8389024734, 8.7534017563])\n",
      "Iter 175; theta =  tensor([6.8421549797, 8.7585964203])\n",
      "Iter 176; theta =  tensor([6.8453416824, 8.7636814117])\n",
      "Iter 177; theta =  tensor([6.8484640121, 8.7686595917])\n",
      "Iter 178; theta =  tensor([6.8515233994, 8.7735328674])\n",
      "Iter 179; theta =  tensor([6.8545207977, 8.7783031464])\n",
      "Iter 180; theta =  tensor([6.8574576378, 8.7829732895])\n",
      "Iter 181; theta =  tensor([6.8603353500, 8.7875452042])\n",
      "Iter 182; theta =  tensor([6.8631548882, 8.7920207977])\n",
      "Iter 183; theta =  tensor([6.8659172058, 8.7964019775])\n",
      "Iter 184; theta =  tensor([6.8686237335, 8.8006906509])\n",
      "Iter 185; theta =  tensor([6.8712759018, 8.8048887253])\n",
      "Iter 186; theta =  tensor([6.8738746643, 8.8089990616])\n",
      "Iter 187; theta =  tensor([6.8764204979, 8.8130226135])\n",
      "Iter 188; theta =  tensor([6.8789153099, 8.8169612885])\n",
      "Iter 189; theta =  tensor([6.8813595772, 8.8208169937])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190; theta =  tensor([6.8837542534, 8.8245916367])\n",
      "Iter 191; theta =  tensor([6.8861007690, 8.8282871246])\n",
      "Iter 192; theta =  tensor([6.8884000778, 8.8319044113])\n",
      "Iter 193; theta =  tensor([6.8906526566, 8.8354454041])\n",
      "Iter 194; theta =  tensor([6.8928599358, 8.8389120102])\n",
      "Iter 195; theta =  tensor([6.8950223923, 8.8423051834])\n",
      "Iter 196; theta =  tensor([6.8971414566, 8.8456268311])\n",
      "Iter 197; theta =  tensor([6.8992176056, 8.8488788605])\n",
      "Iter 198; theta =  tensor([6.9012517929, 8.8520622253])\n",
      "Iter 199; theta =  tensor([6.9032449722, 8.8551788330])\n",
      "Iter 200; theta =  tensor([6.9051980972, 8.8582296371])\n",
      "Iter 201; theta =  tensor([6.9071116447, 8.8612165451])\n",
      "Iter 202; theta =  tensor([6.9089865685, 8.8641405106])\n",
      "Iter 203; theta =  tensor([6.9108238220, 8.8670024872])\n",
      "Iter 204; theta =  tensor([6.9126238823, 8.8698043823])\n",
      "Iter 205; theta =  tensor([6.9143872261, 8.8725471497])\n",
      "Iter 206; theta =  tensor([6.9161152840, 8.8752317429])\n",
      "Iter 207; theta =  tensor([6.9178085327, 8.8778600693])\n",
      "Iter 208; theta =  tensor([6.9194674492, 8.8804330826])\n",
      "Iter 209; theta =  tensor([6.9210929871, 8.8829517365])\n",
      "Iter 210; theta =  tensor([6.9226856232, 8.8854179382])\n",
      "Iter 211; theta =  tensor([6.9242458344, 8.8878316879])\n",
      "Iter 212; theta =  tensor([6.9257745743, 8.8901948929])\n",
      "Iter 213; theta =  tensor([6.9272727966, 8.8925085068])\n",
      "Iter 214; theta =  tensor([6.9287405014, 8.8947734833])\n",
      "Iter 215; theta =  tensor([6.9301786423, 8.8969907761])\n",
      "Iter 216; theta =  tensor([6.9315876961, 8.8991613388])\n",
      "Iter 217; theta =  tensor([6.9329681396, 8.9012861252])\n",
      "Iter 218; theta =  tensor([6.9343209267, 8.9033660889])\n",
      "Iter 219; theta =  tensor([6.9356465340, 8.9054021835])\n",
      "Iter 220; theta =  tensor([6.9369454384, 8.9073953629])\n",
      "Iter 221; theta =  tensor([6.9382181168, 8.9093465805])\n",
      "Iter 222; theta =  tensor([6.9394650459, 8.9112567902])\n",
      "Iter 223; theta =  tensor([6.9406867027, 8.9131259918])\n",
      "Iter 224; theta =  tensor([6.9418835640, 8.9149560928])\n",
      "Iter 225; theta =  tensor([6.9430565834, 8.9167480469])\n",
      "Iter 226; theta =  tensor([6.9442057610, 8.9185018539])\n",
      "Iter 227; theta =  tensor([6.9453315735, 8.9202184677])\n",
      "Iter 228; theta =  tensor([6.9464349747, 8.9218988419])\n",
      "Iter 229; theta =  tensor([6.9475159645, 8.9235439301])\n",
      "Iter 230; theta =  tensor([6.9485750198, 8.9251546860])\n",
      "Iter 231; theta =  tensor([6.9496126175, 8.9267311096])\n",
      "Iter 232; theta =  tensor([6.9506292343, 8.9282751083])\n",
      "Iter 233; theta =  tensor([6.9516253471, 8.9297866821])\n",
      "Iter 234; theta =  tensor([6.9526014328, 8.9312658310])\n",
      "Iter 235; theta =  tensor([6.9535579681, 8.9327135086])\n",
      "Iter 236; theta =  tensor([6.9544949532, 8.9341316223])\n",
      "Iter 237; theta =  tensor([6.9554133415, 8.9355192184])\n",
      "Iter 238; theta =  tensor([6.9563131332, 8.9368782043])\n",
      "Iter 239; theta =  tensor([6.9571948051, 8.9382085800])\n",
      "Iter 240; theta =  tensor([6.9580583572, 8.9395103455])\n",
      "Iter 241; theta =  tensor([6.9589047432, 8.9407844543])\n",
      "Iter 242; theta =  tensor([6.9597339630, 8.9420318604])\n",
      "Iter 243; theta =  tensor([6.9605464935, 8.9432535172])\n",
      "Iter 244; theta =  tensor([6.9613423347, 8.9444494247])\n",
      "Iter 245; theta =  tensor([6.9621224403, 8.9456195831])\n",
      "Iter 246; theta =  tensor([6.9628868103, 8.9467649460])\n",
      "Iter 247; theta =  tensor([6.9636354446, 8.9478864670])\n",
      "Iter 248; theta =  tensor([6.9643692970, 8.9489841461])\n",
      "Iter 249; theta =  tensor([6.9650883675, 8.9500589371])\n",
      "Iter 250; theta =  tensor([6.9657926559, 8.9511108398])\n",
      "Iter 251; theta =  tensor([6.9664826393, 8.9521408081])\n",
      "Iter 252; theta =  tensor([6.9671587944, 8.9531488419])\n",
      "Iter 253; theta =  tensor([6.9678215981, 8.9541358948])\n",
      "Iter 254; theta =  tensor([6.9684710503, 8.9551019669])\n",
      "Iter 255; theta =  tensor([6.9691071510, 8.9560480118])\n",
      "Iter 256; theta =  tensor([6.9697303772, 8.9569740295])\n",
      "Iter 257; theta =  tensor([6.9703412056, 8.9578809738])\n",
      "Iter 258; theta =  tensor([6.9709396362, 8.9587688446])\n",
      "Iter 259; theta =  tensor([6.9715261459, 8.9596376419])\n",
      "Iter 260; theta =  tensor([6.9721007347, 8.9604883194])\n",
      "Iter 261; theta =  tensor([6.9726634026, 8.9613208771])\n",
      "Iter 262; theta =  tensor([6.9732151031, 8.9621362686])\n",
      "Iter 263; theta =  tensor([6.9737553596, 8.9629344940])\n",
      "Iter 264; theta =  tensor([6.9742846489, 8.9637155533])\n",
      "Iter 265; theta =  tensor([6.9748034477, 8.9644804001])\n",
      "Iter 266; theta =  tensor([6.9753117561, 8.9652290344])\n",
      "Iter 267; theta =  tensor([6.9758095741, 8.9659614563])\n",
      "Iter 268; theta =  tensor([6.9762973785, 8.9666786194])\n",
      "Iter 269; theta =  tensor([6.9767756462, 8.9673805237])\n",
      "Iter 270; theta =  tensor([6.9772443771, 8.9680681229])\n",
      "Iter 271; theta =  tensor([6.9777035713, 8.9687414169])\n",
      "Iter 272; theta =  tensor([6.9781532288, 8.9694004059])\n",
      "Iter 273; theta =  tensor([6.9785938263, 8.9700450897])\n",
      "Iter 274; theta =  tensor([6.9790258408, 8.9706764221])\n",
      "Iter 275; theta =  tensor([6.9794487953, 8.9712944031])\n",
      "Iter 276; theta =  tensor([6.9798631668, 8.9718990326])\n",
      "Iter 277; theta =  tensor([6.9802694321, 8.9724912643])\n",
      "Iter 278; theta =  tensor([6.9806675911, 8.9730710983])\n",
      "Iter 279; theta =  tensor([6.9810576439, 8.9736385345])\n",
      "Iter 280; theta =  tensor([6.9814395905, 8.9741935730])\n",
      "Iter 281; theta =  tensor([6.9818139076, 8.9747371674])\n",
      "Iter 282; theta =  tensor([6.9821805954, 8.9752693176])\n",
      "Iter 283; theta =  tensor([6.9825401306, 8.9757900238])\n",
      "Iter 284; theta =  tensor([6.9828925133, 8.9763002396])\n",
      "Iter 285; theta =  tensor([6.9832377434, 8.9767999649])\n",
      "Iter 286; theta =  tensor([6.9835758209, 8.9772891998])\n",
      "Iter 287; theta =  tensor([6.9839072227, 8.9777679443])\n",
      "Iter 288; theta =  tensor([6.9842319489, 8.9782361984])\n",
      "Iter 289; theta =  tensor([6.9845499992, 8.9786949158])\n",
      "Iter 290; theta =  tensor([6.9848618507, 8.9791440964])\n",
      "Iter 291; theta =  tensor([6.9851670265, 8.9795837402])\n",
      "Iter 292; theta =  tensor([6.9854660034, 8.9800138474])\n",
      "Iter 293; theta =  tensor([6.9857592583, 8.9804353714])\n",
      "Iter 294; theta =  tensor([6.9860463142, 8.9808473587])\n",
      "Iter 295; theta =  tensor([6.9863276482, 8.9812507629])\n",
      "Iter 296; theta =  tensor([6.9866032600, 8.9816455841])\n",
      "Iter 297; theta =  tensor([6.9868736267, 8.9820327759])\n",
      "Iter 298; theta =  tensor([6.9871382713, 8.9824113846])\n",
      "Iter 299; theta =  tensor([6.9873976707, 8.9827823639])\n",
      "Iter 300; theta =  tensor([6.9876518250, 8.9831447601])\n",
      "Iter 301; theta =  tensor([6.9879007339, 8.9834995270])\n",
      "Iter 302; theta =  tensor([6.9881448746, 8.9838476181])\n",
      "Iter 303; theta =  tensor([6.9883837700, 8.9841880798])\n",
      "Iter 304; theta =  tensor([6.9886178970, 8.9845209122])\n",
      "Iter 305; theta =  tensor([6.9888472557, 8.9848470688])\n",
      "Iter 306; theta =  tensor([6.9890723228, 8.9851665497])\n",
      "Iter 307; theta =  tensor([6.9892926216, 8.9854793549])\n",
      "Iter 308; theta =  tensor([6.9895086288, 8.9857854843])\n",
      "Iter 309; theta =  tensor([6.9897203445, 8.9860849380])\n",
      "Iter 310; theta =  tensor([6.9899277687, 8.9863786697])\n",
      "Iter 311; theta =  tensor([6.9901309013, 8.9866657257])\n",
      "Iter 312; theta =  tensor([6.9903297424, 8.9869470596])\n",
      "Iter 313; theta =  tensor([6.9905247688, 8.9872217178])\n",
      "Iter 314; theta =  tensor([6.9907159805, 8.9874906540])\n",
      "Iter 315; theta =  tensor([6.9909033775, 8.9877538681])\n",
      "Iter 316; theta =  tensor([6.9910869598, 8.9880123138])\n"
     ]
    }
   ],
   "source": [
    "# Testando com derivada autograd. Sua função deve retornar algo perto de 7 e 9\n",
    "theta = gd(derivada_torch, media_erros_quadrados, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YZwD4GZonbo",
    "outputId": "03a7c537-d1db-485e-d90b-d025c6574f6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.9910869598, 8.9880123138], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9DuRmmjonbr",
    "outputId": "f51fa272-f50d-4bcb-af6a-7e37da116d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; theta =  tensor([-1.3507395983,  1.4760649204], requires_grad=True)\n",
      "Iter 1; theta =  tensor([-1.2667683363,  1.5555195808])\n",
      "Iter 2; theta =  tensor([-1.1836416721,  1.6341354847])\n",
      "Iter 3; theta =  tensor([-1.1013512611,  1.7119214535])\n",
      "Iter 4; theta =  tensor([-1.0198884010,  1.7888861895])\n",
      "Iter 5; theta =  tensor([-0.9392449260,  1.8650383949])\n",
      "Iter 6; theta =  tensor([-0.8594126105,  1.9403866529])\n",
      "Iter 7; theta =  tensor([-0.7803832293,  2.0149393082])\n",
      "Iter 8; theta =  tensor([-0.7021487951,  2.0887050629])\n",
      "Iter 9; theta =  tensor([-0.6247012019,  2.1616921425])\n",
      "Iter 10; theta =  tensor([-0.5480325818,  2.2339086533])\n",
      "Iter 11; theta =  tensor([-0.4721350670,  2.3053627014])\n",
      "Iter 12; theta =  tensor([-0.3970009685,  2.3760623932])\n",
      "Iter 13; theta =  tensor([-0.3226225376,  2.4460155964])\n",
      "Iter 14; theta =  tensor([-0.2489922643,  2.5152304173])\n",
      "Iter 15; theta =  tensor([-0.1761024445,  2.5837144852])\n",
      "Iter 16; theta =  tensor([-0.1039458439,  2.6514754295])\n",
      "Iter 17; theta =  tensor([-0.0325149298,  2.7185211182])\n",
      "Iter 18; theta =  tensor([0.0381975099, 2.7848589420])\n",
      "Iter 19; theta =  tensor([0.1081986800, 2.8504962921])\n",
      "Iter 20; theta =  tensor([0.1774958074, 2.9154407978])\n",
      "Iter 21; theta =  tensor([0.2460959852, 2.9796996117])\n",
      "Iter 22; theta =  tensor([0.3140061796, 3.0432798862])\n",
      "Iter 23; theta =  tensor([0.3812333345, 3.1061890125])\n",
      "Iter 24; theta =  tensor([0.4477843344, 3.1684339046])\n",
      "Iter 25; theta =  tensor([0.5136660337, 3.2300217152])\n",
      "Iter 26; theta =  tensor([0.5788851380, 3.2909591198])\n",
      "Iter 27; theta =  tensor([0.6434482336, 3.3512532711])\n",
      "Iter 28; theta =  tensor([0.7073619962, 3.4109108448])\n",
      "Iter 29; theta =  tensor([0.7706329823, 3.4699385166])\n",
      "Iter 30; theta =  tensor([0.8332675695, 3.5283429623])\n",
      "Iter 31; theta =  tensor([0.8952722549, 3.5861308575])\n",
      "Iter 32; theta =  tensor([0.9566533566, 3.6433086395])\n",
      "Iter 33; theta =  tensor([1.0174171925, 3.6998827457])\n",
      "Iter 34; theta =  tensor([1.0775698423, 3.7558596134])\n",
      "Iter 35; theta =  tensor([1.1371175051, 3.8112454414])\n",
      "Iter 36; theta =  tensor([1.1960662603, 3.8660464287])\n",
      "Iter 37; theta =  tensor([1.2544220686, 3.9202687740])\n",
      "Iter 38; theta =  tensor([1.3121910095, 3.9739186764])\n",
      "Iter 39; theta =  tensor([1.3693789244, 4.0270023346])\n",
      "Iter 40; theta =  tensor([1.4259917736, 4.0795254707])\n",
      "Iter 41; theta =  tensor([1.4820351601, 4.1314940453])\n",
      "Iter 42; theta =  tensor([1.5375149250, 4.1829137802])\n",
      "Iter 43; theta =  tensor([1.5924367905, 4.2337903976])\n",
      "Iter 44; theta =  tensor([1.6468062401, 4.2841300964])\n",
      "Iter 45; theta =  tensor([1.7006288767, 4.3339381218])\n",
      "Iter 46; theta =  tensor([1.7539103031, 4.3832201958])\n",
      "Iter 47; theta =  tensor([1.8066557646, 4.4319820404])\n",
      "Iter 48; theta =  tensor([1.8588708639, 4.4802289009])\n",
      "Iter 49; theta =  tensor([1.9105607271, 4.5279664993])\n",
      "Iter 50; theta =  tensor([1.9617308378, 4.5752000809])\n",
      "Iter 51; theta =  tensor([2.0123863220, 4.6219348907])\n",
      "Iter 52; theta =  tensor([2.0625324249, 4.6681761742])\n",
      "Iter 53; theta =  tensor([2.1121742725, 4.7139291763])\n",
      "Iter 54; theta =  tensor([2.1613166332, 4.7591991425])\n",
      "Iter 55; theta =  tensor([2.2099649906, 4.8039913177])\n",
      "Iter 56; theta =  tensor([2.2581241131, 4.8483104706])\n",
      "Iter 57; theta =  tensor([2.3057987690, 4.8921618462])\n",
      "Iter 58; theta =  tensor([2.3529939651, 4.9355497360])\n",
      "Iter 59; theta =  tensor([2.3997147083, 4.9784798622])\n",
      "Iter 60; theta =  tensor([2.4459655285, 5.0209565163])\n",
      "Iter 61; theta =  tensor([2.4917511940, 5.0629849434])\n",
      "Iter 62; theta =  tensor([2.5370764732, 5.1045694351])\n",
      "Iter 63; theta =  tensor([2.5819458961, 5.1457147598])\n",
      "Iter 64; theta =  tensor([2.6263639927, 5.1864256859])\n",
      "Iter 65; theta =  tensor([2.6703355312, 5.2267065048])\n",
      "Iter 66; theta =  tensor([2.7138648033, 5.2665619850])\n",
      "Iter 67; theta =  tensor([2.7569563389, 5.3059968948])\n",
      "Iter 68; theta =  tensor([2.7996144295, 5.3450155258])\n",
      "Iter 69; theta =  tensor([2.8418436050, 5.3836221695])\n",
      "Iter 70; theta =  tensor([2.8836481571, 5.4218211174])\n",
      "Iter 71; theta =  tensor([2.9250323772, 5.4596166611])\n",
      "Iter 72; theta =  tensor([2.9660003185, 5.4970130920])\n",
      "Iter 73; theta =  tensor([3.0065562725, 5.5340147018])\n",
      "Iter 74; theta =  tensor([3.0467042923, 5.5706253052])\n",
      "Iter 75; theta =  tensor([3.0864486694, 5.6068496704])\n",
      "Iter 76; theta =  tensor([3.1257934570, 5.6426911354])\n",
      "Iter 77; theta =  tensor([3.1647424698, 5.6781544685])\n",
      "Iter 78; theta =  tensor([3.2032997608, 5.7132430077])\n",
      "Iter 79; theta =  tensor([3.2414693832, 5.7479610443])\n",
      "Iter 80; theta =  tensor([3.2792551517, 5.7823123932])\n",
      "Iter 81; theta =  tensor([3.3166608810, 5.8163013458])\n",
      "Iter 82; theta =  tensor([3.3536906242, 5.8499312401])\n",
      "Iter 83; theta =  tensor([3.3903479576, 5.8832058907])\n",
      "Iter 84; theta =  tensor([3.4266366959, 5.9161291122])\n",
      "Iter 85; theta =  tensor([3.4625604153, 5.9487047195])\n",
      "Iter 86; theta =  tensor([3.4981229305, 5.9809365273])\n",
      "Iter 87; theta =  tensor([3.5333278179, 6.0128278732])\n",
      "Iter 88; theta =  tensor([3.5681786537, 6.0443825722])\n",
      "Iter 89; theta =  tensor([3.6026790142, 6.0756039619])\n",
      "Iter 90; theta =  tensor([3.6368324757, 6.1064958572])\n",
      "Iter 91; theta =  tensor([3.6706426144, 6.1370611191])\n",
      "Iter 92; theta =  tensor([3.7041127682, 6.1673040390])\n",
      "Iter 93; theta =  tensor([3.7372462749, 6.1972274780])\n",
      "Iter 94; theta =  tensor([3.7700467110, 6.2268347740])\n",
      "Iter 95; theta =  tensor([3.8025171757, 6.2561292648])\n",
      "Iter 96; theta =  tensor([3.8346612453, 6.2851147652])\n",
      "Iter 97; theta =  tensor([3.8664820194, 6.3137941360])\n",
      "Iter 98; theta =  tensor([3.8979828358, 6.3421707153])\n",
      "Iter 99; theta =  tensor([3.9291667938, 6.3702473640])\n",
      "Iter 100; theta =  tensor([3.9600372314, 6.3980274200])\n",
      "Iter 101; theta =  tensor([3.9905972481, 6.4255142212])\n",
      "Iter 102; theta =  tensor([4.0208501816, 6.4527106285])\n",
      "Iter 103; theta =  tensor([4.0507988930, 6.4796199799])\n",
      "Iter 104; theta =  tensor([4.0804462433, 6.5062451363])\n",
      "Iter 105; theta =  tensor([4.1097955704, 6.5325889587])\n",
      "Iter 106; theta =  tensor([4.1388497353, 6.5586547852])\n",
      "Iter 107; theta =  tensor([4.1676115990, 6.5844454765])\n",
      "Iter 108; theta =  tensor([4.1960844994, 6.6099638939])\n",
      "Iter 109; theta =  tensor([4.2242708206, 6.6352124214])\n",
      "Iter 110; theta =  tensor([4.2521739006, 6.6601943970])\n",
      "Iter 111; theta =  tensor([4.2797966003, 6.6849126816])\n",
      "Iter 112; theta =  tensor([4.3071413040, 6.7093696594])\n",
      "Iter 113; theta =  tensor([4.3342108727, 6.7335686684])\n",
      "Iter 114; theta =  tensor([4.3610086441, 6.7575120926])\n",
      "Iter 115; theta =  tensor([4.3875370026, 6.7812027931])\n",
      "Iter 116; theta =  tensor([4.4137983322, 6.8046431541])\n",
      "Iter 117; theta =  tensor([4.4397954941, 6.8278360367])\n",
      "Iter 118; theta =  tensor([4.4655313492, 6.8507838249])\n",
      "Iter 119; theta =  tensor([4.4910087585, 6.8734893799])\n",
      "Iter 120; theta =  tensor([4.5162296295, 6.8959550858])\n",
      "Iter 121; theta =  tensor([4.5411968231, 6.9181833267])\n",
      "Iter 122; theta =  tensor([4.5659132004, 6.9401769638])\n",
      "Iter 123; theta =  tensor([4.5903811455, 6.9619383812])\n",
      "Iter 124; theta =  tensor([4.6146030426, 6.9834699631])\n",
      "Iter 125; theta =  tensor([4.6385812759, 7.0047740936])\n",
      "Iter 126; theta =  tensor([4.6623182297, 7.0258531570])\n",
      "Iter 127; theta =  tensor([4.6858167648, 7.0467095375])\n",
      "Iter 128; theta =  tensor([4.7090792656, 7.0673456192])\n",
      "Iter 129; theta =  tensor([4.7321076393, 7.0877637863])\n",
      "Iter 130; theta =  tensor([4.7549042702, 7.1079664230])\n",
      "Iter 131; theta =  tensor([4.7774720192, 7.1279559135])\n",
      "Iter 132; theta =  tensor([4.7998127937, 7.1477341652])\n",
      "Iter 133; theta =  tensor([4.8219289780, 7.1673035622])\n",
      "Iter 134; theta =  tensor([4.8438224792, 7.1866660118])\n",
      "Iter 135; theta =  tensor([4.8654961586, 7.2058243752])\n",
      "Iter 136; theta =  tensor([4.8869519234, 7.2247800827])\n",
      "Iter 137; theta =  tensor([4.9081916809, 7.2435355186])\n",
      "Iter 138; theta =  tensor([4.9292182922, 7.2620930672])\n",
      "Iter 139; theta =  tensor([4.9500331879, 7.2804546356])\n",
      "Iter 140; theta =  tensor([4.9706387520, 7.2986221313])\n",
      "Iter 141; theta =  tensor([4.9910373688, 7.3165979385])\n",
      "Iter 142; theta =  tensor([5.0112309456, 7.3343839645])\n",
      "Iter 143; theta =  tensor([5.0312213898, 7.3519821167])\n",
      "Iter 144; theta =  tensor([5.0510106087, 7.3693943024])\n",
      "Iter 145; theta =  tensor([5.0706009865, 7.3866224289])\n",
      "Iter 146; theta =  tensor([5.0899944305, 7.4036688805])\n",
      "Iter 147; theta =  tensor([5.1091928482, 7.4205350876])\n",
      "Iter 148; theta =  tensor([5.1281981468, 7.4372229576])\n",
      "Iter 149; theta =  tensor([5.1470127106, 7.4537348747])\n",
      "Iter 150; theta =  tensor([5.1656379700, 7.4700722694])\n",
      "Iter 151; theta =  tensor([5.1840758324, 7.4862370491])\n",
      "Iter 152; theta =  tensor([5.2023282051, 7.5022311211])\n",
      "Iter 153; theta =  tensor([5.2203974724, 7.5180563927])\n",
      "Iter 154; theta =  tensor([5.2382850647, 7.5337142944])\n",
      "Iter 155; theta =  tensor([5.2559924126, 7.5492067337])\n",
      "Iter 156; theta =  tensor([5.2735219002, 7.5645356178])\n",
      "Iter 157; theta =  tensor([5.2908749580, 7.5797028542])\n",
      "Iter 158; theta =  tensor([5.3080539703, 7.5947098732])\n",
      "Iter 159; theta =  tensor([5.3250598907, 7.6095581055])\n",
      "Iter 160; theta =  tensor([5.3418951035, 7.6242494583])\n",
      "Iter 161; theta =  tensor([5.3585610390, 7.6387858391])\n",
      "Iter 162; theta =  tensor([5.3750591278, 7.6531686783])\n",
      "Iter 163; theta =  tensor([5.3913917542, 7.6673994064])\n",
      "Iter 164; theta =  tensor([5.4075598717, 7.6814799309])\n",
      "Iter 165; theta =  tensor([5.4235653877, 7.6954116821])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 166; theta =  tensor([5.4394102097, 7.7091965675])\n",
      "Iter 167; theta =  tensor([5.4550957680, 7.7228355408])\n",
      "Iter 168; theta =  tensor([5.4706234932, 7.7363305092])\n",
      "Iter 169; theta =  tensor([5.4859952927, 7.7496829033])\n",
      "Iter 170; theta =  tensor([5.5012125969, 7.7628941536])\n",
      "Iter 171; theta =  tensor([5.5162768364, 7.7759661674])\n",
      "Iter 172; theta =  tensor([5.5311894417, 7.7888998985])\n",
      "Iter 173; theta =  tensor([5.5459523201, 7.8016972542])\n",
      "Iter 174; theta =  tensor([5.5605669022, 7.8143591881])\n",
      "Iter 175; theta =  tensor([5.5750341415, 7.8268876076])\n",
      "Iter 176; theta =  tensor([5.5893559456, 7.8392834663])\n",
      "Iter 177; theta =  tensor([5.6035337448, 7.8515486717])\n",
      "Iter 178; theta =  tensor([5.6175694466, 7.8636841774])\n",
      "Iter 179; theta =  tensor([5.6314640045, 7.8756914139])\n",
      "Iter 180; theta =  tensor([5.6452188492, 7.8875718117])\n",
      "Iter 181; theta =  tensor([5.6588354111, 7.8993268013])\n",
      "Iter 182; theta =  tensor([5.6723151207, 7.9109573364])\n",
      "Iter 183; theta =  tensor([5.6856589317, 7.9224653244])\n",
      "Iter 184; theta =  tensor([5.6988687515, 7.9338517189])\n",
      "Iter 185; theta =  tensor([5.7119460106, 7.9451179504])\n",
      "Iter 186; theta =  tensor([5.7248916626, 7.9562649727])\n",
      "Iter 187; theta =  tensor([5.7377071381, 7.9672942162])\n",
      "Iter 188; theta =  tensor([5.7503938675, 7.9782071114])\n",
      "Iter 189; theta =  tensor([5.7629528046, 7.9890046120])\n",
      "Iter 190; theta =  tensor([5.7753853798, 7.9996881485])\n",
      "Iter 191; theta =  tensor([5.7876930237, 8.0102586746])\n",
      "Iter 192; theta =  tensor([5.7998771667, 8.0207176208])\n",
      "Iter 193; theta =  tensor([5.8119387627, 8.0310659409])\n",
      "Iter 194; theta =  tensor([5.8238792419, 8.0413055420])\n",
      "Iter 195; theta =  tensor([5.8356995583, 8.0514364243])\n",
      "Iter 196; theta =  tensor([5.8474011421, 8.0614604950])\n",
      "Iter 197; theta =  tensor([5.8589849472, 8.0713787079])\n",
      "Iter 198; theta =  tensor([5.8704524040, 8.0811920166])\n",
      "Iter 199; theta =  tensor([5.8818044662, 8.0909013748])\n",
      "Iter 200; theta =  tensor([5.8930425644, 8.1005086899])\n",
      "Iter 201; theta =  tensor([5.9041676521, 8.1100139618])\n",
      "Iter 202; theta =  tensor([5.9151806831, 8.1194190979])\n",
      "Iter 203; theta =  tensor([5.9260830879, 8.1287250519])\n",
      "Iter 204; theta =  tensor([5.9368758202, 8.1379327774])\n",
      "Iter 205; theta =  tensor([5.9475603104, 8.1470432281])\n",
      "Iter 206; theta =  tensor([5.9581375122, 8.1560573578])\n",
      "Iter 207; theta =  tensor([5.9686083794, 8.1649761200])\n",
      "Iter 208; theta =  tensor([5.9789738655, 8.1738004684])\n",
      "Iter 209; theta =  tensor([5.9892349243, 8.1825313568])\n",
      "Iter 210; theta =  tensor([5.9993929863, 8.1911706924])\n",
      "Iter 211; theta =  tensor([6.0094490051, 8.1997184753])\n",
      "Iter 212; theta =  tensor([6.0194039345, 8.2081756592])\n",
      "Iter 213; theta =  tensor([6.0292587280, 8.2165441513])\n",
      "Iter 214; theta =  tensor([6.0390143394, 8.2248239517])\n",
      "Iter 215; theta =  tensor([6.0486721992, 8.2330160141])\n",
      "Iter 216; theta =  tensor([6.0582327843, 8.2411212921])\n",
      "Iter 217; theta =  tensor([6.0676970482, 8.2491416931])\n",
      "Iter 218; theta =  tensor([6.0770664215, 8.2570772171])\n",
      "Iter 219; theta =  tensor([6.0863413811, 8.2649288177])\n",
      "Iter 220; theta =  tensor([6.0955233574, 8.2726974487])\n",
      "Iter 221; theta =  tensor([6.1046128273, 8.2803840637])\n",
      "Iter 222; theta =  tensor([6.1136112213, 8.2879896164])\n",
      "Iter 223; theta =  tensor([6.1225190163, 8.2955141068])\n",
      "Iter 224; theta =  tensor([6.1313371658, 8.3029594421])\n",
      "Iter 225; theta =  tensor([6.1400666237, 8.3103265762])\n",
      "Iter 226; theta =  tensor([6.1487083435, 8.3176155090])\n",
      "Iter 227; theta =  tensor([6.1572632790, 8.3248271942])\n",
      "Iter 228; theta =  tensor([6.1657323837, 8.3319625854])\n",
      "Iter 229; theta =  tensor([6.1741161346, 8.3390226364])\n",
      "Iter 230; theta =  tensor([6.1824159622, 8.3460083008])\n",
      "Iter 231; theta =  tensor([6.1906323433, 8.3529205322])\n",
      "Iter 232; theta =  tensor([6.1987657547, 8.3597593307])\n",
      "Iter 233; theta =  tensor([6.2068176270, 8.3665256500])\n",
      "Iter 234; theta =  tensor([6.2147884369, 8.3732204437])\n",
      "Iter 235; theta =  tensor([6.2226791382, 8.3798446655])\n",
      "Iter 236; theta =  tensor([6.2304906845, 8.3863992691])\n",
      "Iter 237; theta =  tensor([6.2382235527, 8.3928842545])\n",
      "Iter 238; theta =  tensor([6.2458786964, 8.3993005753])\n",
      "Iter 239; theta =  tensor([6.2534570694, 8.4056491852])\n",
      "Iter 240; theta =  tensor([6.2609591484, 8.4119310379])\n",
      "Iter 241; theta =  tensor([6.2683858871, 8.4181461334])\n",
      "Iter 242; theta =  tensor([6.2757377625, 8.4242963791])\n",
      "Iter 243; theta =  tensor([6.2830157280, 8.4303808212])\n",
      "Iter 244; theta =  tensor([6.2902207375, 8.4364013672])\n",
      "Iter 245; theta =  tensor([6.2973532677, 8.4423580170])\n",
      "Iter 246; theta =  tensor([6.3044142723, 8.4482517242])\n",
      "Iter 247; theta =  tensor([6.3114042282, 8.4540834427])\n",
      "Iter 248; theta =  tensor([6.3183236122, 8.4598531723])\n",
      "Iter 249; theta =  tensor([6.3251738548, 8.4655618668])\n",
      "Iter 250; theta =  tensor([6.3319549561, 8.4712104797])\n",
      "Iter 251; theta =  tensor([6.3386678696, 8.4767999649])\n",
      "Iter 252; theta =  tensor([6.3453135490, 8.4823303223])\n",
      "Iter 253; theta =  tensor([6.3518924713, 8.4878015518])\n",
      "Iter 254; theta =  tensor([6.3584051132, 8.4932155609])\n",
      "Iter 255; theta =  tensor([6.3648524284, 8.4985723495])\n",
      "Iter 256; theta =  tensor([6.3712348938, 8.5038728714])\n",
      "Iter 257; theta =  tensor([6.3775529861, 8.5091171265])\n",
      "Iter 258; theta =  tensor([6.3838076591, 8.5143060684])\n",
      "Iter 259; theta =  tensor([6.3899993896, 8.5194396973])\n",
      "Iter 260; theta =  tensor([6.3961291313, 8.5245189667])\n",
      "Iter 261; theta =  tensor([6.4021973610, 8.5295448303])\n",
      "Iter 262; theta =  tensor([6.4082045555, 8.5345172882])\n",
      "Iter 263; theta =  tensor([6.4141511917, 8.5394372940])\n",
      "Iter 264; theta =  tensor([6.4200382233, 8.5443058014])\n",
      "Iter 265; theta =  tensor([6.4258661270, 8.5491228104])\n",
      "Iter 266; theta =  tensor([6.4316353798, 8.5538883209])\n",
      "Iter 267; theta =  tensor([6.4373464584, 8.5586042404])\n",
      "Iter 268; theta =  tensor([6.4430003166, 8.5632696152])\n",
      "Iter 269; theta =  tensor([6.4485974312, 8.5678863525])\n",
      "Iter 270; theta =  tensor([6.4541382790, 8.5724544525])\n",
      "Iter 271; theta =  tensor([6.4596233368, 8.5769739151])\n",
      "Iter 272; theta =  tensor([6.4650530815, 8.5814456940])\n",
      "Iter 273; theta =  tensor([6.4704284668, 8.5858697891])\n",
      "Iter 274; theta =  tensor([6.4757494926, 8.5902471542])\n",
      "Iter 275; theta =  tensor([6.4810171127, 8.5945787430])\n",
      "Iter 276; theta =  tensor([6.4862318039, 8.5988645554])\n",
      "Iter 277; theta =  tensor([6.4913940430, 8.6031045914])\n",
      "Iter 278; theta =  tensor([6.4965047836, 8.6072998047])\n",
      "Iter 279; theta =  tensor([6.5015640259, 8.6114511490])\n",
      "Iter 280; theta =  tensor([6.5065722466, 8.6155586243])\n",
      "Iter 281; theta =  tensor([6.5115303993, 8.6196222305])\n",
      "Iter 282; theta =  tensor([6.5164384842, 8.6236429214])\n",
      "Iter 283; theta =  tensor([6.5212974548, 8.6276216507])\n",
      "Iter 284; theta =  tensor([6.5261073112, 8.6315584183])\n",
      "Iter 285; theta =  tensor([6.5308690071, 8.6354532242])\n",
      "Iter 286; theta =  tensor([6.5355830193, 8.6393070221])\n",
      "Iter 287; theta =  tensor([6.5402493477, 8.6431198120])\n",
      "Iter 288; theta =  tensor([6.5448689461, 8.6468925476])\n",
      "Iter 289; theta =  tensor([6.5494418144, 8.6506252289])\n",
      "Iter 290; theta =  tensor([6.5539689064, 8.6543188095])\n",
      "Iter 291; theta =  tensor([6.5584506989, 8.6579732895])\n",
      "Iter 292; theta =  tensor([6.5628871918, 8.6615886688])\n",
      "Iter 293; theta =  tensor([6.5672793388, 8.6651659012])\n",
      "Iter 294; theta =  tensor([6.5716271400, 8.6687059402])\n",
      "Iter 295; theta =  tensor([6.5759310722, 8.6722078323])\n",
      "Iter 296; theta =  tensor([6.5801920891, 8.6756734848])\n",
      "Iter 297; theta =  tensor([6.5844101906, 8.6791019440])\n",
      "Iter 298; theta =  tensor([6.5885858536, 8.6824941635])\n",
      "Iter 299; theta =  tensor([6.5927195549, 8.6858510971])\n",
      "Iter 300; theta =  tensor([6.5968117714, 8.6891717911])\n",
      "Iter 301; theta =  tensor([6.6008629799, 8.6924581528])\n",
      "Iter 302; theta =  tensor([6.6048731804, 8.6957092285])\n",
      "Iter 303; theta =  tensor([6.6088433266, 8.6989259720])\n",
      "Iter 304; theta =  tensor([6.6127734184, 8.7021093369])\n",
      "Iter 305; theta =  tensor([6.6166639328, 8.7052583694])\n",
      "Iter 306; theta =  tensor([6.6205153465, 8.7083740234])\n",
      "Iter 307; theta =  tensor([6.6243281364, 8.7114572525])\n",
      "Iter 308; theta =  tensor([6.6281027794, 8.7145080566])\n",
      "Iter 309; theta =  tensor([6.6318392754, 8.7175264359])\n",
      "Iter 310; theta =  tensor([6.6355381012, 8.7205123901])\n",
      "Iter 311; theta =  tensor([6.6391997337, 8.7234668732])\n",
      "Iter 312; theta =  tensor([6.6428246498, 8.7263908386])\n",
      "Iter 313; theta =  tensor([6.6464133263, 8.7292833328])\n",
      "Iter 314; theta =  tensor([6.6499657631, 8.7321453094])\n",
      "Iter 315; theta =  tensor([6.6534824371, 8.7349767685])\n",
      "Iter 316; theta =  tensor([6.6569638252, 8.7377786636])\n",
      "Iter 317; theta =  tensor([6.6604104042, 8.7405509949])\n",
      "Iter 318; theta =  tensor([6.6638221741, 8.7432937622])\n",
      "Iter 319; theta =  tensor([6.6671996117, 8.7460079193])\n",
      "Iter 320; theta =  tensor([6.6705431938, 8.7486934662])\n",
      "Iter 321; theta =  tensor([6.6738533974, 8.7513504028])\n",
      "Iter 322; theta =  tensor([6.6771302223, 8.7539796829])\n",
      "Iter 323; theta =  tensor([6.6803741455, 8.7565803528])\n",
      "Iter 324; theta =  tensor([6.6835856438, 8.7591543198])\n",
      "Iter 325; theta =  tensor([6.6867647171, 8.7617006302])\n",
      "Iter 326; theta =  tensor([6.6899118423, 8.7642202377])\n",
      "Iter 327; theta =  tensor([6.6930274963, 8.7667131424])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 328; theta =  tensor([6.6961116791, 8.7691793442])\n",
      "Iter 329; theta =  tensor([6.6991648674, 8.7716197968])\n",
      "Iter 330; theta =  tensor([6.7021870613, 8.7740345001])\n",
      "Iter 331; theta =  tensor([6.7051792145, 8.7764234543])\n",
      "Iter 332; theta =  tensor([6.7081413269, 8.7787876129])\n",
      "Iter 333; theta =  tensor([6.7110733986, 8.7811269760])\n",
      "Iter 334; theta =  tensor([6.7139763832, 8.7834415436])\n",
      "Iter 335; theta =  tensor([6.7168498039, 8.7857313156])\n",
      "Iter 336; theta =  tensor([6.7196946144, 8.7879972458])\n",
      "Iter 337; theta =  tensor([6.7225108147, 8.7902383804])\n",
      "Iter 338; theta =  tensor([6.7252984047, 8.7924566269])\n",
      "Iter 339; theta =  tensor([6.7280583382, 8.7946510315])\n",
      "Iter 340; theta =  tensor([6.7307906151, 8.7968225479])\n",
      "Iter 341; theta =  tensor([6.7334952354, 8.7989711761])\n",
      "Iter 342; theta =  tensor([6.7361726761, 8.8010969162])\n",
      "Iter 343; theta =  tensor([6.7388234138, 8.8031997681])\n",
      "Iter 344; theta =  tensor([6.7414474487, 8.8052806854])\n",
      "Iter 345; theta =  tensor([6.7440447807, 8.8073396683])\n",
      "Iter 346; theta =  tensor([6.7466163635, 8.8093767166])\n",
      "Iter 347; theta =  tensor([6.7491617203, 8.8113927841])\n",
      "Iter 348; theta =  tensor([6.7516818047, 8.8133869171])\n",
      "Iter 349; theta =  tensor([6.7541766167, 8.8153600693])\n",
      "Iter 350; theta =  tensor([6.7566461563, 8.8173122406])\n",
      "Iter 351; theta =  tensor([6.7590909004, 8.8192443848])\n",
      "Iter 352; theta =  tensor([6.7615113258, 8.8211555481])\n",
      "Iter 353; theta =  tensor([6.7639074326, 8.8230466843])\n",
      "Iter 354; theta =  tensor([6.7662792206, 8.8249177933])\n",
      "Iter 355; theta =  tensor([6.7686271667, 8.8267688751])\n",
      "Iter 356; theta =  tensor([6.7709517479, 8.8286008835])\n",
      "Iter 357; theta =  tensor([6.7732529640, 8.8304128647])\n",
      "Iter 358; theta =  tensor([6.7755308151, 8.8322057724])\n",
      "Iter 359; theta =  tensor([6.7777857780, 8.8339796066])\n",
      "Iter 360; theta =  tensor([6.7800183296, 8.8357353210])\n",
      "Iter 361; theta =  tensor([6.7822284698, 8.8374719620])\n",
      "Iter 362; theta =  tensor([6.7844161987, 8.8391904831])\n",
      "Iter 363; theta =  tensor([6.7865819931, 8.8408908844])\n",
      "Iter 364; theta =  tensor([6.7887258530, 8.8425731659])\n",
      "Iter 365; theta =  tensor([6.7908482552, 8.8442382812])\n",
      "Iter 366; theta =  tensor([6.7929491997, 8.8458852768])\n",
      "Iter 367; theta =  tensor([6.7950291634, 8.8475151062])\n",
      "Iter 368; theta =  tensor([6.7970881462, 8.8491277695])\n",
      "Iter 369; theta =  tensor([6.7991266251, 8.8507232666])\n",
      "Iter 370; theta =  tensor([6.8011445999, 8.8523015976])\n",
      "Iter 371; theta =  tensor([6.8031420708, 8.8538637161])\n",
      "Iter 372; theta =  tensor([6.8051195145, 8.8554086685])\n",
      "Iter 373; theta =  tensor([6.8070774078, 8.8569374084])\n",
      "Iter 374; theta =  tensor([6.8090152740, 8.8584499359])\n",
      "Iter 375; theta =  tensor([6.8109340668, 8.8599472046])\n",
      "Iter 376; theta =  tensor([6.8128333092, 8.8614282608])\n",
      "Iter 377; theta =  tensor([6.8147134781, 8.8628940582])\n",
      "Iter 378; theta =  tensor([6.8165745735, 8.8643436432])\n",
      "Iter 379; theta =  tensor([6.8184170723, 8.8657779694])\n",
      "Iter 380; theta =  tensor([6.8202409744, 8.8671970367])\n",
      "Iter 381; theta =  tensor([6.8220467567, 8.8686017990])\n",
      "Iter 382; theta =  tensor([6.8238344193, 8.8699913025])\n",
      "Iter 383; theta =  tensor([6.8256039619, 8.8713665009])\n",
      "Iter 384; theta =  tensor([6.8273558617, 8.8727264404])\n",
      "Iter 385; theta =  tensor([6.8290901184, 8.8740720749])\n",
      "Iter 386; theta =  tensor([6.8308072090, 8.8754034042])\n",
      "Iter 387; theta =  tensor([6.8325066566, 8.8767213821])\n",
      "Iter 388; theta =  tensor([6.8341894150, 8.8780250549])\n",
      "Iter 389; theta =  tensor([6.8358550072, 8.8793153763])\n",
      "Iter 390; theta =  tensor([6.8375039101, 8.8805913925])\n",
      "Iter 391; theta =  tensor([6.8391361237, 8.8818540573])\n",
      "Iter 392; theta =  tensor([6.8407521248, 8.8831033707])\n",
      "Iter 393; theta =  tensor([6.8423519135, 8.8843393326])\n",
      "Iter 394; theta =  tensor([6.8439354897, 8.8855628967])\n",
      "Iter 395; theta =  tensor([6.8455033302, 8.8867731094])\n",
      "Iter 396; theta =  tensor([6.8470554352, 8.8879709244])\n",
      "Iter 397; theta =  tensor([6.8485918045, 8.8891553879])\n",
      "Iter 398; theta =  tensor([6.8501129150, 8.8903274536])\n",
      "Iter 399; theta =  tensor([6.8516187668, 8.8914871216])\n",
      "Iter 400; theta =  tensor([6.8531093597, 8.8926343918])\n",
      "Iter 401; theta =  tensor([6.8545846939, 8.8937702179])\n",
      "Iter 402; theta =  tensor([6.8560452461, 8.8948936462])\n",
      "Iter 403; theta =  tensor([6.8574914932, 8.8960056305])\n",
      "Iter 404; theta =  tensor([6.8589229584, 8.8971052170])\n",
      "Iter 405; theta =  tensor([6.8603401184, 8.8981933594])\n",
      "Iter 406; theta =  tensor([6.8617429733, 8.8992700577])\n",
      "Iter 407; theta =  tensor([6.8631315231, 8.9003353119])\n",
      "Iter 408; theta =  tensor([6.8645062447, 8.9013891220])\n",
      "Iter 409; theta =  tensor([6.8658671379, 8.9024324417])\n",
      "Iter 410; theta =  tensor([6.8672146797, 8.9034643173])\n",
      "Iter 411; theta =  tensor([6.8685483932, 8.9044857025])\n",
      "Iter 412; theta =  tensor([6.8698687553, 8.9054956436])\n",
      "Iter 413; theta =  tensor([6.8711757660, 8.9064950943])\n",
      "Iter 414; theta =  tensor([6.8724699020, 8.9074840546])\n",
      "Iter 415; theta =  tensor([6.8737506866, 8.9084625244])\n",
      "Iter 416; theta =  tensor([6.8750185966, 8.9094305038])\n",
      "Iter 417; theta =  tensor([6.8762741089, 8.9103879929])\n",
      "Iter 418; theta =  tensor([6.8775167465, 8.9113359451])\n",
      "Iter 419; theta =  tensor([6.8787469864, 8.9122734070])\n",
      "Iter 420; theta =  tensor([6.8799648285, 8.9132013321])\n",
      "Iter 421; theta =  tensor([6.8811707497, 8.9141197205])\n",
      "Iter 422; theta =  tensor([6.8823642731, 8.9150276184])\n",
      "Iter 423; theta =  tensor([6.8835458755, 8.9159259796])\n",
      "Iter 424; theta =  tensor([6.8847155571, 8.9168148041])\n",
      "Iter 425; theta =  tensor([6.8858733177, 8.9176950455])\n",
      "Iter 426; theta =  tensor([6.8870196342, 8.9185657501])\n",
      "Iter 427; theta =  tensor([6.8881545067, 8.9194269180])\n",
      "Iter 428; theta =  tensor([6.8892779350, 8.9202795029])\n",
      "Iter 429; theta =  tensor([6.8903899193, 8.9211225510])\n",
      "Iter 430; theta =  tensor([6.8914909363, 8.9219570160])\n",
      "Iter 431; theta =  tensor([6.8925809860, 8.9227828979])\n",
      "Iter 432; theta =  tensor([6.8936600685, 8.9235992432])\n",
      "Iter 433; theta =  tensor([6.8947281837, 8.9244070053])\n",
      "Iter 434; theta =  tensor([6.8957853317, 8.9252061844])\n",
      "Iter 435; theta =  tensor([6.8968319893, 8.9259977341])\n",
      "Iter 436; theta =  tensor([6.8978681564, 8.9267807007])\n",
      "Iter 437; theta =  tensor([6.8988938332, 8.9275550842])\n",
      "Iter 438; theta =  tensor([6.8999094963, 8.9283218384])\n",
      "Iter 439; theta =  tensor([6.9009146690, 8.9290800095])\n",
      "Iter 440; theta =  tensor([6.9019098282, 8.9298305511])\n",
      "Iter 441; theta =  tensor([6.9028949738, 8.9305725098])\n",
      "Iter 442; theta =  tensor([6.9038701057, 8.9313068390])\n",
      "Iter 443; theta =  tensor([6.9048357010, 8.9320335388])\n",
      "Iter 444; theta =  tensor([6.9057917595, 8.9327526093])\n",
      "Iter 445; theta =  tensor([6.9067378044, 8.9334640503])\n",
      "Iter 446; theta =  tensor([6.9076743126, 8.9341678619])\n",
      "Iter 447; theta =  tensor([6.9086017609, 8.9348640442])\n",
      "Iter 448; theta =  tensor([6.9095196724, 8.9355535507])\n",
      "Iter 449; theta =  tensor([6.9104285240, 8.9362354279])\n",
      "Iter 450; theta =  tensor([6.9113283157, 8.9369096756])\n",
      "Iter 451; theta =  tensor([6.9122190475, 8.9375772476])\n",
      "Iter 452; theta =  tensor([6.9131007195, 8.9382371902])\n",
      "Iter 453; theta =  tensor([6.9139733315, 8.9388904572])\n",
      "Iter 454; theta =  tensor([6.9148373604, 8.9395370483])\n",
      "Iter 455; theta =  tensor([6.9156928062, 8.9401769638])\n",
      "Iter 456; theta =  tensor([6.9165396690, 8.9408102036])\n",
      "Iter 457; theta =  tensor([6.9173779488, 8.9414367676])\n",
      "Iter 458; theta =  tensor([6.9182076454, 8.9420566559])\n",
      "Iter 459; theta =  tensor([6.9190292358, 8.9426698685])\n",
      "Iter 460; theta =  tensor([6.9198422432, 8.9432764053])\n",
      "Iter 461; theta =  tensor([6.9206471443, 8.9438762665])\n",
      "Iter 462; theta =  tensor([6.9214439392, 8.9444704056])\n",
      "Iter 463; theta =  tensor([6.9222331047, 8.9450578690])\n",
      "Iter 464; theta =  tensor([6.9230141640, 8.9456386566])\n",
      "Iter 465; theta =  tensor([6.9237875938, 8.9462137222])\n",
      "Iter 466; theta =  tensor([6.9245529175, 8.9467830658])\n",
      "Iter 467; theta =  tensor([6.9253106117, 8.9473457336])\n",
      "Iter 468; theta =  tensor([6.9260606766, 8.9479026794])\n",
      "Iter 469; theta =  tensor([6.9268031120, 8.9484539032])\n",
      "Iter 470; theta =  tensor([6.9275383949, 8.9489994049])\n",
      "Iter 471; theta =  tensor([6.9282660484, 8.9495391846])\n",
      "Iter 472; theta =  tensor([6.9289865494, 8.9500732422])\n",
      "Iter 473; theta =  tensor([6.9296998978, 8.9506015778])\n",
      "Iter 474; theta =  tensor([6.9304060936, 8.9511241913])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 475; theta =  tensor([6.9311051369, 8.9516410828])\n",
      "Iter 476; theta =  tensor([6.9317970276, 8.9521522522])\n",
      "Iter 477; theta =  tensor([6.9324822426, 8.9526586533])\n",
      "Iter 478; theta =  tensor([6.9331603050, 8.9531593323])\n",
      "Iter 479; theta =  tensor([6.9338316917, 8.9536552429])\n",
      "Iter 480; theta =  tensor([6.9344964027, 8.9541454315])\n",
      "Iter 481; theta =  tensor([6.9351544380, 8.9546308517])\n",
      "Iter 482; theta =  tensor([6.9358057976, 8.9551105499])\n",
      "Iter 483; theta =  tensor([6.9364504814, 8.9555854797])\n",
      "Iter 484; theta =  tensor([6.9370884895, 8.9560556412])\n",
      "Iter 485; theta =  tensor([6.9377202988, 8.9565210342])\n",
      "Iter 486; theta =  tensor([6.9383459091, 8.9569807053])\n",
      "Iter 487; theta =  tensor([6.9389653206, 8.9574356079])\n",
      "Iter 488; theta =  tensor([6.9395780563, 8.9578857422])\n",
      "Iter 489; theta =  tensor([6.9401850700, 8.9583311081])\n",
      "Iter 490; theta =  tensor([6.9407858849, 8.9587717056])\n",
      "Iter 491; theta =  tensor([6.9413805008, 8.9592075348])\n",
      "Iter 492; theta =  tensor([6.9419693947, 8.9596395493])\n",
      "Iter 493; theta =  tensor([6.9425520897, 8.9600667953])\n",
      "Iter 494; theta =  tensor([6.9431290627, 8.9604892731])\n",
      "Iter 495; theta =  tensor([6.9437003136, 8.9609069824])\n",
      "Iter 496; theta =  tensor([6.9442658424, 8.9613208771])\n",
      "Iter 497; theta =  tensor([6.9448256493, 8.9617300034])\n",
      "Iter 498; theta =  tensor([6.9453797340, 8.9621353149])\n",
      "Iter 499; theta =  tensor([6.9459280968, 8.9625358582])\n",
      "Iter 500; theta =  tensor([6.9464712143, 8.9629325867])\n",
      "Iter 501; theta =  tensor([6.9470086098, 8.9633245468])\n",
      "Iter 502; theta =  tensor([6.9475407600, 8.9637126923])\n",
      "Iter 503; theta =  tensor([6.9480676651, 8.9640970230])\n",
      "Iter 504; theta =  tensor([6.9485893250, 8.9644765854])\n",
      "Iter 505; theta =  tensor([6.9491057396, 8.9648523331])\n",
      "Iter 506; theta =  tensor([6.9496169090, 8.9652242661])\n",
      "Iter 507; theta =  tensor([6.9501228333, 8.9655923843])\n",
      "Iter 508; theta =  tensor([6.9506235123, 8.9659566879])\n",
      "Iter 509; theta =  tensor([6.9511194229, 8.9663171768])\n",
      "Iter 510; theta =  tensor([6.9516100883, 8.9666738510])\n",
      "Iter 511; theta =  tensor([6.9520959854, 8.9670267105])\n",
      "Iter 512; theta =  tensor([6.9525771141, 8.9673757553])\n",
      "Iter 513; theta =  tensor([6.9530534744, 8.9677209854])\n",
      "Iter 514; theta =  tensor([6.9535250664, 8.9680624008])\n",
      "Iter 515; theta =  tensor([6.9539918900, 8.9684000015])\n",
      "Iter 516; theta =  tensor([6.9544539452, 8.9687347412])\n",
      "Iter 517; theta =  tensor([6.9549112320, 8.9690656662])\n",
      "Iter 518; theta =  tensor([6.9553642273, 8.9693927765])\n",
      "Iter 519; theta =  tensor([6.9558124542, 8.9697170258])\n",
      "Iter 520; theta =  tensor([6.9562563896, 8.9700374603])\n",
      "Iter 521; theta =  tensor([6.9566955566, 8.9703540802])\n",
      "Iter 522; theta =  tensor([6.9571304321, 8.9706678391])\n",
      "Iter 523; theta =  tensor([6.9575610161, 8.9709777832])\n",
      "Iter 524; theta =  tensor([6.9579873085, 8.9712848663])\n",
      "Iter 525; theta =  tensor([6.9584093094, 8.9715890884])\n",
      "Iter 526; theta =  tensor([6.9588270187, 8.9718894958])\n",
      "Iter 527; theta =  tensor([6.9592404366, 8.9721870422])\n",
      "Iter 528; theta =  tensor([6.9596495628, 8.9724817276])\n",
      "Iter 529; theta =  tensor([6.9600548744, 8.9727725983])\n",
      "Iter 530; theta =  tensor([6.9604558945, 8.9730606079])\n",
      "Iter 531; theta =  tensor([6.9608530998, 8.9733457565])\n",
      "Iter 532; theta =  tensor([6.9612460136, 8.9736280441])\n",
      "Iter 533; theta =  tensor([6.9616351128, 8.9739074707])\n",
      "Iter 534; theta =  tensor([6.9620203972, 8.9741840363])\n",
      "Iter 535; theta =  tensor([6.9624018669, 8.9744567871])\n",
      "Iter 536; theta =  tensor([6.9627795219, 8.9747266769])\n",
      "Iter 537; theta =  tensor([6.9631533623, 8.9749937057])\n",
      "Iter 538; theta =  tensor([6.9635233879, 8.9752578735])\n",
      "Iter 539; theta =  tensor([6.9638895988, 8.9755201340])\n",
      "Iter 540; theta =  tensor([6.9642519951, 8.9757795334])\n",
      "Iter 541; theta =  tensor([6.9646110535, 8.9760360718])\n",
      "Iter 542; theta =  tensor([6.9649662971, 8.9762897491])\n",
      "Iter 543; theta =  tensor([6.9653182030, 8.9765405655])\n",
      "Iter 544; theta =  tensor([6.9656662941, 8.9767885208])\n",
      "Iter 545; theta =  tensor([6.9660110474, 8.9770345688])\n",
      "Iter 546; theta =  tensor([6.9663524628, 8.9772777557])\n",
      "Iter 547; theta =  tensor([6.9666905403, 8.9775180817])\n",
      "Iter 548; theta =  tensor([6.9670248032, 8.9777555466])\n",
      "Iter 549; theta =  tensor([6.9673557281, 8.9779911041])\n",
      "Iter 550; theta =  tensor([6.9676833153, 8.9782238007])\n",
      "Iter 551; theta =  tensor([6.9680080414, 8.9784545898])\n",
      "Iter 552; theta =  tensor([6.9683294296, 8.9786825180])\n",
      "Iter 553; theta =  tensor([6.9686474800, 8.9789085388])\n",
      "Iter 554; theta =  tensor([6.9689621925, 8.9791316986])\n",
      "Iter 555; theta =  tensor([6.9692740440, 8.9793529510])\n",
      "Iter 556; theta =  tensor([6.9695825577, 8.9795713425])\n",
      "Iter 557; theta =  tensor([6.9698882103, 8.9797878265])\n",
      "Iter 558; theta =  tensor([6.9701905251, 8.9800014496])\n",
      "Iter 559; theta =  tensor([6.9704899788, 8.9802131653])\n",
      "Iter 560; theta =  tensor([6.9707860947, 8.9804229736])\n",
      "Iter 561; theta =  tensor([6.9710793495, 8.9806299210])\n",
      "Iter 562; theta =  tensor([6.9713697433, 8.9808349609])\n",
      "Iter 563; theta =  tensor([6.9716572762, 8.9810380936])\n",
      "Iter 564; theta =  tensor([6.9719419479, 8.9812383652])\n",
      "Iter 565; theta =  tensor([6.9722237587, 8.9814367294])\n",
      "Iter 566; theta =  tensor([6.9725027084, 8.9816331863])\n",
      "Iter 567; theta =  tensor([6.9727787971, 8.9818277359])\n",
      "Iter 568; theta =  tensor([6.9730520248, 8.9820203781])\n",
      "Iter 569; theta =  tensor([6.9733223915, 8.9822111130])\n",
      "Iter 570; theta =  tensor([6.9735903740, 8.9823989868])\n",
      "Iter 571; theta =  tensor([6.9738554955, 8.9825849533])\n",
      "Iter 572; theta =  tensor([6.9741182327, 8.9827690125])\n",
      "Iter 573; theta =  tensor([6.9743781090, 8.9829511642])\n",
      "Iter 574; theta =  tensor([6.9746356010, 8.9831314087])\n",
      "Iter 575; theta =  tensor([6.9748902321, 8.9833097458])\n",
      "Iter 576; theta =  tensor([6.9751424789, 8.9834861755])\n",
      "Iter 577; theta =  tensor([6.9753918648, 8.9836606979])\n",
      "Iter 578; theta =  tensor([6.9756388664, 8.9838333130])\n",
      "Iter 579; theta =  tensor([6.9758834839, 8.9840040207])\n",
      "Iter 580; theta =  tensor([6.9761257172, 8.9841737747])\n",
      "Iter 581; theta =  tensor([6.9763655663, 8.9843416214])\n",
      "Iter 582; theta =  tensor([6.9766030312, 8.9845075607])\n",
      "Iter 583; theta =  tensor([6.9768381119, 8.9846715927])\n",
      "Iter 584; theta =  tensor([6.9770708084, 8.9848337173])\n",
      "Iter 585; theta =  tensor([6.9773011208, 8.9849939346])\n",
      "Iter 586; theta =  tensor([6.9775290489, 8.9851531982])\n",
      "Iter 587; theta =  tensor([6.9777545929, 8.9853105545])\n",
      "Iter 588; theta =  tensor([6.9779777527, 8.9854660034])\n",
      "Iter 589; theta =  tensor([6.9781990051, 8.9856195450])\n",
      "Iter 590; theta =  tensor([6.9784178734, 8.9857721329])\n",
      "Iter 591; theta =  tensor([6.9786343575, 8.9859228134])\n",
      "Iter 592; theta =  tensor([6.9788489342, 8.9860715866])\n",
      "Iter 593; theta =  tensor([6.9790611267, 8.9862194061])\n",
      "Iter 594; theta =  tensor([6.9792714119, 8.9863653183])\n",
      "Iter 595; theta =  tensor([6.9794793129, 8.9865093231])\n",
      "Iter 596; theta =  tensor([6.9796853065, 8.9866523743])\n",
      "Iter 597; theta =  tensor([6.9798893929, 8.9867935181])\n",
      "Iter 598; theta =  tensor([6.9800910950, 8.9869337082])\n",
      "Iter 599; theta =  tensor([6.9802908897, 8.9870719910])\n",
      "Iter 600; theta =  tensor([6.9804887772, 8.9872093201])\n",
      "Iter 601; theta =  tensor([6.9806847572, 8.9873447418])\n",
      "Iter 602; theta =  tensor([6.9808788300, 8.9874782562])\n",
      "Iter 603; theta =  tensor([6.9810709953, 8.9876108170])\n",
      "Iter 604; theta =  tensor([6.9812612534, 8.9877424240])\n",
      "Iter 605; theta =  tensor([6.9814496040, 8.9878721237])\n",
      "Iter 606; theta =  tensor([6.9816360474, 8.9880008698])\n",
      "Iter 607; theta =  tensor([6.9818205833, 8.9881277084])\n"
     ]
    }
   ],
   "source": [
    "# Testando com derivada manual. Sua função deve retornar algo perto de 7 e 9\n",
    "theta = gd(derivada_navera, media_erros_quadrados, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6SbuwB7onbt",
    "outputId": "f1e6afa3-4cb2-4203-fc5d-d37155d9ef47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.9818205833, 8.9881277084], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQY5_lJvonbv"
   },
   "source": [
    "12. Altere a função de Gradiente Descendente para funcionar com minibatches. Em outras palavras, não compute o erro usando todos os dados de X. Use um `slice` de tamanho do minibatch. Uma ideia é seguir o pseudocódigo abaixo.\n",
    "\n",
    "```python\n",
    "index = np.arange(len(X))\n",
    "while True:\n",
    "    minib = np.random.choice(index, minibatchsize) # aqui estou usando numpy para selection minibatch elementos\n",
    "    X_batch = X[minib]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOyf2F26onbv",
    "outputId": "2d6ca1bc-9c4e-4750-8a4e-ce559e713307",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18 875 431 531 874 274 500 606 565 213 144 761 423 101  15 506 721 836\n",
      "  99 707 537 695 120  69 660 587 407 286 691 585 358 306  66 881 677 315\n",
      " 567 744 713 549 211 363 756 963 984 180 648 812 631 365]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000000000,  0.9554776549],\n",
       "        [ 1.0000000000,  0.2271338403],\n",
       "        [ 1.0000000000,  1.6697291136],\n",
       "        [ 1.0000000000, -0.8208400011],\n",
       "        [ 1.0000000000,  0.1728801131],\n",
       "        [ 1.0000000000, -0.5653861165],\n",
       "        [ 1.0000000000, -1.1271778345],\n",
       "        [ 1.0000000000, -0.3065211773],\n",
       "        [ 1.0000000000, -1.3163980246],\n",
       "        [ 1.0000000000, -0.8325572014],\n",
       "        [ 1.0000000000,  0.3088090718],\n",
       "        [ 1.0000000000, -2.2304661274],\n",
       "        [ 1.0000000000, -1.1195486784],\n",
       "        [ 1.0000000000,  1.0486443043],\n",
       "        [ 1.0000000000, -0.4781374335],\n",
       "        [ 1.0000000000,  0.7729234099],\n",
       "        [ 1.0000000000,  0.0849680379],\n",
       "        [ 1.0000000000,  0.5483353734],\n",
       "        [ 1.0000000000,  1.2060762644],\n",
       "        [ 1.0000000000,  2.3435075283],\n",
       "        [ 1.0000000000,  0.9441922903],\n",
       "        [ 1.0000000000,  1.6634535789],\n",
       "        [ 1.0000000000, -0.5386458635],\n",
       "        [ 1.0000000000,  0.5982029438],\n",
       "        [ 1.0000000000, -0.8068934679],\n",
       "        [ 1.0000000000, -0.2874993682],\n",
       "        [ 1.0000000000,  1.4074001312],\n",
       "        [ 1.0000000000, -0.8125162721],\n",
       "        [ 1.0000000000,  0.5076500177],\n",
       "        [ 1.0000000000,  1.1539475918],\n",
       "        [ 1.0000000000, -1.3232605457],\n",
       "        [ 1.0000000000, -0.1253492832],\n",
       "        [ 1.0000000000,  1.3479737043],\n",
       "        [ 1.0000000000, -0.1953429431],\n",
       "        [ 1.0000000000,  0.5050106049],\n",
       "        [ 1.0000000000, -0.3933345079],\n",
       "        [ 1.0000000000, -1.4276400805],\n",
       "        [ 1.0000000000,  1.0467292070],\n",
       "        [ 1.0000000000, -0.4991362691],\n",
       "        [ 1.0000000000,  0.1215938851],\n",
       "        [ 1.0000000000,  0.9778665304],\n",
       "        [ 1.0000000000,  0.2687079906],\n",
       "        [ 1.0000000000, -1.2001441717],\n",
       "        [ 1.0000000000,  0.0605064295],\n",
       "        [ 1.0000000000,  1.3528225422],\n",
       "        [ 1.0000000000,  0.6608756781],\n",
       "        [ 1.0000000000,  1.0200723410],\n",
       "        [ 1.0000000000, -1.5330649614],\n",
       "        [ 1.0000000000, -1.0671395063],\n",
       "        [ 1.0000000000, -0.4982965887]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo abaixo\n",
    "index = np.arange(len(X))\n",
    "mb = np.random.choice(index, 50)\n",
    "print(mb)\n",
    "X[mb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_gd(d_fun, loss_fun, X, y, lambda_=0.01, tol=0.00001,\n",
    "                 max_iter=10000, batch_size=10):\n",
    "    '''\n",
    "    Executa Gradiente Descendente. Aqui:\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    d_fun : é uma função de derivadas\n",
    "    loss_fun : é uma função de perda\n",
    "    X : é um vetor de fatores explanatórios.\n",
    "        Copie seu código de intercepto da primeira aula.\n",
    "        para adicionar o intercepto em X.\n",
    "    y : é a resposta\n",
    "    lambda : é a taxa de aprendizad\n",
    "    tol : é a tolerância, define quando o algoritmo vai parar.\n",
    "    max_ter : é a segunda forma de parada, mesmo sem convergir\n",
    "              paramos depois de max_iter iterações.\n",
    "    batch_size : tamanho do batch\n",
    "    '''\n",
    "    theta = torch.randn(X.shape[1]).double()\n",
    "    theta.requires_grad_(True)\n",
    "    print('Iter {}; theta = '.format(0), theta)\n",
    "    old_err_sq = np.inf\n",
    "    i = 0\n",
    "    \n",
    "    index = np.arange(len(X))\n",
    "    while True:\n",
    "        theta.requires_grad_(True)\n",
    "        # pega o mini batch\n",
    "        mb = np.random.choice(index, 50)\n",
    "        Xmb = X[mb]\n",
    "        ymb = y[mb]\n",
    "        \n",
    "        # Computar as derivadas\n",
    "        grad = d_fun(Xmb, theta, ymb)\n",
    "        # Atualizar\n",
    "        with torch.no_grad():\n",
    "            theta_novo = theta - lambda_ * grad\n",
    "        \n",
    "        # Parar quando o erro convergir\n",
    "        err_sq = loss_fun(Xmb, theta, ymb)\n",
    "        if torch.abs(old_err_sq - err_sq) <= tol:\n",
    "            break\n",
    "        \n",
    "        # Atualizar parâmetros e erro\n",
    "        theta = theta_novo\n",
    "        old_err_sq = err_sq\n",
    "        \n",
    "        # Informação de debug\n",
    "        print('Iter {}; theta = '.format(i+1), theta)\n",
    "        i += 1\n",
    "        if i == max_iter:\n",
    "            break\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5gzuUW4onb3",
    "outputId": "d8357b1e-5750-48ad-bc96-9fb4ee75bdc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; theta =  tensor([-2.1935026646, -1.5653724670], dtype=torch.float64, requires_grad=True)\n",
      "Iter 1; theta =  tensor([-2.0079698658, -1.4339302731], dtype=torch.float64)\n",
      "Iter 2; theta =  tensor([-1.8216756535, -1.2367364025], dtype=torch.float64)\n",
      "Iter 3; theta =  tensor([-1.6293707752, -1.0336711216], dtype=torch.float64)\n",
      "Iter 4; theta =  tensor([-1.4385902500, -0.7255203342], dtype=torch.float64)\n",
      "Iter 5; theta =  tensor([-1.1995216274, -0.4600080776], dtype=torch.float64)\n",
      "Iter 6; theta =  tensor([-0.9952649403, -0.1626058865], dtype=torch.float64)\n",
      "Iter 7; theta =  tensor([-0.8535451508, -0.0137565136], dtype=torch.float64)\n",
      "Iter 8; theta =  tensor([-0.7124014187,  0.1171632099], dtype=torch.float64)\n",
      "Iter 9; theta =  tensor([-0.5404680347,  0.2601912022], dtype=torch.float64)\n",
      "Iter 10; theta =  tensor([-0.3511270046,  0.4906035709], dtype=torch.float64)\n",
      "Iter 11; theta =  tensor([-0.1741362476,  0.6885706425], dtype=torch.float64)\n",
      "Iter 12; theta =  tensor([-0.0525055885,  0.8765153980], dtype=torch.float64)\n",
      "Iter 13; theta =  tensor([0.1195572281, 1.0492405605], dtype=torch.float64)\n",
      "Iter 14; theta =  tensor([0.2892568779, 1.2971635532], dtype=torch.float64)\n",
      "Iter 15; theta =  tensor([0.4899482155, 1.5295356464], dtype=torch.float64)\n",
      "Iter 16; theta =  tensor([0.6380914497, 1.6996535015], dtype=torch.float64)\n",
      "Iter 17; theta =  tensor([0.7510621929, 1.8072520733], dtype=torch.float64)\n",
      "Iter 18; theta =  tensor([0.8791224766, 1.9695765018], dtype=torch.float64)\n",
      "Iter 19; theta =  tensor([0.9849763107, 2.1531384945], dtype=torch.float64)\n",
      "Iter 20; theta =  tensor([1.0880953884, 2.3070117855], dtype=torch.float64)\n",
      "Iter 21; theta =  tensor([1.2251815224, 2.4676818562], dtype=torch.float64)\n",
      "Iter 22; theta =  tensor([1.3343637371, 2.6147619438], dtype=torch.float64)\n",
      "Iter 23; theta =  tensor([1.4406994820, 2.7194573975], dtype=torch.float64)\n",
      "Iter 24; theta =  tensor([1.5423730087, 2.8122601509], dtype=torch.float64)\n",
      "Iter 25; theta =  tensor([1.6404798603, 2.9032278252], dtype=torch.float64)\n",
      "Iter 26; theta =  tensor([1.7055272055, 3.0236058617], dtype=torch.float64)\n",
      "Iter 27; theta =  tensor([1.8060334063, 3.1673546982], dtype=torch.float64)\n",
      "Iter 28; theta =  tensor([1.9116524363, 3.2961417770], dtype=torch.float64)\n",
      "Iter 29; theta =  tensor([2.0253819323, 3.4038385677], dtype=torch.float64)\n",
      "Iter 30; theta =  tensor([2.1185173559, 3.5351732254], dtype=torch.float64)\n",
      "Iter 31; theta =  tensor([2.1933291435, 3.6420173550], dtype=torch.float64)\n",
      "Iter 32; theta =  tensor([2.2976736450, 3.7463764858], dtype=torch.float64)\n",
      "Iter 33; theta =  tensor([2.3902989388, 3.9047631454], dtype=torch.float64)\n",
      "Iter 34; theta =  tensor([2.4491314983, 3.9948503780], dtype=torch.float64)\n",
      "Iter 35; theta =  tensor([2.5441654587, 4.1180629158], dtype=torch.float64)\n",
      "Iter 36; theta =  tensor([2.6511804199, 4.2469572735], dtype=torch.float64)\n",
      "Iter 37; theta =  tensor([2.7350189209, 4.3259617233], dtype=torch.float64)\n",
      "Iter 38; theta =  tensor([2.8466641998, 4.4187798786], dtype=torch.float64)\n",
      "Iter 39; theta =  tensor([2.9230265665, 4.4962130213], dtype=torch.float64)\n",
      "Iter 40; theta =  tensor([2.9845634604, 4.5916986990], dtype=torch.float64)\n",
      "Iter 41; theta =  tensor([3.0529197311, 4.7114255190], dtype=torch.float64)\n",
      "Iter 42; theta =  tensor([3.1401561451, 4.8278302431], dtype=torch.float64)\n",
      "Iter 43; theta =  tensor([3.2150286293, 4.9242931795], dtype=torch.float64)\n",
      "Iter 44; theta =  tensor([3.3096817493, 5.0284382582], dtype=torch.float64)\n",
      "Iter 45; theta =  tensor([3.3863804865, 5.0963647366], dtype=torch.float64)\n",
      "Iter 46; theta =  tensor([3.4623137569, 5.1935120773], dtype=torch.float64)\n",
      "Iter 47; theta =  tensor([3.5263135576, 5.2557094193], dtype=torch.float64)\n",
      "Iter 48; theta =  tensor([3.6135738611, 5.3652457809], dtype=torch.float64)\n",
      "Iter 49; theta =  tensor([3.6780449533, 5.4353682947], dtype=torch.float64)\n",
      "Iter 50; theta =  tensor([3.7370900059, 5.4823677015], dtype=torch.float64)\n",
      "Iter 51; theta =  tensor([3.7874697542, 5.5372337103], dtype=torch.float64)\n",
      "Iter 52; theta =  tensor([3.8306952429, 5.5911061049], dtype=torch.float64)\n",
      "Iter 53; theta =  tensor([3.9036057377, 5.6736312342], dtype=torch.float64)\n",
      "Iter 54; theta =  tensor([3.9589742136, 5.7339267588], dtype=torch.float64)\n",
      "Iter 55; theta =  tensor([4.0356967783, 5.8524580812], dtype=torch.float64)\n",
      "Iter 56; theta =  tensor([4.0908953571, 5.9134695721], dtype=torch.float64)\n",
      "Iter 57; theta =  tensor([4.1359537506, 5.9789301062], dtype=torch.float64)\n",
      "Iter 58; theta =  tensor([4.2057193470, 6.0724950838], dtype=torch.float64)\n",
      "Iter 59; theta =  tensor([4.2561128378, 6.1922756910], dtype=torch.float64)\n",
      "Iter 60; theta =  tensor([4.2992868328, 6.2627497721], dtype=torch.float64)\n",
      "Iter 61; theta =  tensor([4.3535309029, 6.3259496212], dtype=torch.float64)\n",
      "Iter 62; theta =  tensor([4.3984119081, 6.3749804354], dtype=torch.float64)\n",
      "Iter 63; theta =  tensor([4.4624961424, 6.4422974253], dtype=torch.float64)\n",
      "Iter 64; theta =  tensor([4.5092151594, 6.4847230005], dtype=torch.float64)\n",
      "Iter 65; theta =  tensor([4.5727991819, 6.5734617662], dtype=torch.float64)\n",
      "Iter 66; theta =  tensor([4.6154592466, 6.6297069359], dtype=torch.float64)\n",
      "Iter 67; theta =  tensor([4.6558625031, 6.6631979585], dtype=torch.float64)\n",
      "Iter 68; theta =  tensor([4.7109229946, 6.7217442966], dtype=torch.float64)\n",
      "Iter 69; theta =  tensor([4.7547188282, 6.7652436233], dtype=torch.float64)\n",
      "Iter 70; theta =  tensor([4.8046192980, 6.8239189506], dtype=torch.float64)\n",
      "Iter 71; theta =  tensor([4.8460329819, 6.8766207242], dtype=torch.float64)\n",
      "Iter 72; theta =  tensor([4.8880469227, 6.9168005109], dtype=torch.float64)\n",
      "Iter 73; theta =  tensor([4.9172851634, 6.9422129941], dtype=torch.float64)\n",
      "Iter 74; theta =  tensor([4.9549869919, 6.9721423149], dtype=torch.float64)\n",
      "Iter 75; theta =  tensor([5.0056467485, 7.0248374844], dtype=torch.float64)\n",
      "Iter 76; theta =  tensor([5.0424216914, 7.0655654335], dtype=torch.float64)\n",
      "Iter 77; theta =  tensor([5.0796118808, 7.1100909233], dtype=torch.float64)\n",
      "Iter 78; theta =  tensor([5.1063042092, 7.1566734695], dtype=torch.float64)\n",
      "Iter 79; theta =  tensor([5.1406103873, 7.2031575203], dtype=torch.float64)\n",
      "Iter 80; theta =  tensor([5.1742357469, 7.2329457426], dtype=torch.float64)\n",
      "Iter 81; theta =  tensor([5.2104011655, 7.2847010088], dtype=torch.float64)\n",
      "Iter 82; theta =  tensor([5.2375166583, 7.3045784569], dtype=torch.float64)\n",
      "Iter 83; theta =  tensor([5.2744786811, 7.3387771487], dtype=torch.float64)\n",
      "Iter 84; theta =  tensor([5.3089991689, 7.3632056618], dtype=torch.float64)\n",
      "Iter 85; theta =  tensor([5.3400838494, 7.3929204845], dtype=torch.float64)\n",
      "Iter 86; theta =  tensor([5.3813448501, 7.4224742651], dtype=torch.float64)\n",
      "Iter 87; theta =  tensor([5.4131232285, 7.4540504718], dtype=torch.float64)\n",
      "Iter 88; theta =  tensor([5.4506778836, 7.4896001911], dtype=torch.float64)\n",
      "Iter 89; theta =  tensor([5.4884100819, 7.5345652723], dtype=torch.float64)\n",
      "Iter 90; theta =  tensor([5.5167010307, 7.5569392943], dtype=torch.float64)\n",
      "Iter 91; theta =  tensor([5.5480611610, 7.5899642301], dtype=torch.float64)\n",
      "Iter 92; theta =  tensor([5.5847253227, 7.6359390283], dtype=torch.float64)\n",
      "Iter 93; theta =  tensor([5.6172115183, 7.6622386980], dtype=torch.float64)\n",
      "Iter 94; theta =  tensor([5.6467676210, 7.6921597600], dtype=torch.float64)\n",
      "Iter 95; theta =  tensor([5.6722304106, 7.7194262981], dtype=torch.float64)\n",
      "Iter 96; theta =  tensor([5.7031533933, 7.7480793905], dtype=torch.float64)\n",
      "Iter 97; theta =  tensor([5.7314556122, 7.7811327410], dtype=torch.float64)\n",
      "Iter 98; theta =  tensor([5.7612994337, 7.8117805004], dtype=torch.float64)\n",
      "Iter 99; theta =  tensor([5.7869242215, 7.8374951482], dtype=torch.float64)\n",
      "Iter 100; theta =  tensor([5.8108245730, 7.8522163033], dtype=torch.float64)\n",
      "Iter 101; theta =  tensor([5.8357977629, 7.8769703937], dtype=torch.float64)\n",
      "Iter 102; theta =  tensor([5.8540065157, 7.8955206609], dtype=torch.float64)\n",
      "Iter 103; theta =  tensor([5.8785233319, 7.9253925920], dtype=torch.float64)\n",
      "Iter 104; theta =  tensor([5.8943029225, 7.9419887400], dtype=torch.float64)\n",
      "Iter 105; theta =  tensor([5.9144139016, 7.9708044171], dtype=torch.float64)\n",
      "Iter 106; theta =  tensor([5.9367486298, 7.9889028764], dtype=torch.float64)\n",
      "Iter 107; theta =  tensor([5.9611948240, 8.0100313902], dtype=torch.float64)\n",
      "Iter 108; theta =  tensor([5.9774664605, 8.0264408827], dtype=torch.float64)\n",
      "Iter 109; theta =  tensor([5.9941541278, 8.0429026592], dtype=torch.float64)\n",
      "Iter 110; theta =  tensor([6.0145757520, 8.0638094079], dtype=torch.float64)\n",
      "Iter 111; theta =  tensor([6.0306962836, 8.0843580806], dtype=torch.float64)\n",
      "Iter 112; theta =  tensor([6.0480268490, 8.0991922653], dtype=torch.float64)\n",
      "Iter 113; theta =  tensor([6.0686936367, 8.1149033558], dtype=torch.float64)\n",
      "Iter 114; theta =  tensor([6.0844098902, 8.1305141366], dtype=torch.float64)\n",
      "Iter 115; theta =  tensor([6.1041041386, 8.1480554891], dtype=torch.float64)\n",
      "Iter 116; theta =  tensor([6.1253830159, 8.1733833194], dtype=torch.float64)\n",
      "Iter 117; theta =  tensor([6.1432455206, 8.1882813644], dtype=torch.float64)\n",
      "Iter 118; theta =  tensor([6.1638762689, 8.2092032933], dtype=torch.float64)\n",
      "Iter 119; theta =  tensor([6.1824652624, 8.2279591525], dtype=torch.float64)\n",
      "Iter 120; theta =  tensor([6.1999011564, 8.2438526690], dtype=torch.float64)\n",
      "Iter 121; theta =  tensor([6.2177649271, 8.2613166535], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 122; theta =  tensor([6.2364773464, 8.2762124848], dtype=torch.float64)\n",
      "Iter 123; theta =  tensor([6.2529206622, 8.2930880022], dtype=torch.float64)\n",
      "Iter 124; theta =  tensor([6.2678484774, 8.3082937193], dtype=torch.float64)\n",
      "Iter 125; theta =  tensor([6.2812716675, 8.3215651405], dtype=torch.float64)\n",
      "Iter 126; theta =  tensor([6.2942026651, 8.3417565215], dtype=torch.float64)\n",
      "Iter 127; theta =  tensor([6.3113004506, 8.3598664916], dtype=torch.float64)\n",
      "Iter 128; theta =  tensor([6.3246856093, 8.3736564553], dtype=torch.float64)\n",
      "Iter 129; theta =  tensor([6.3370364857, 8.3832537144], dtype=torch.float64)\n",
      "Iter 130; theta =  tensor([6.3532759058, 8.3958930975], dtype=torch.float64)\n",
      "Iter 131; theta =  tensor([6.3677480781, 8.4106663686], dtype=torch.float64)\n",
      "Iter 132; theta =  tensor([6.3826222026, 8.4299588221], dtype=torch.float64)\n",
      "Iter 133; theta =  tensor([6.4006885421, 8.4524099320], dtype=torch.float64)\n",
      "Iter 134; theta =  tensor([6.4125453126, 8.4657516867], dtype=torch.float64)\n",
      "Iter 135; theta =  tensor([6.4218630767, 8.4715783376], dtype=torch.float64)\n",
      "Iter 136; theta =  tensor([6.4319378269, 8.4825356477], dtype=torch.float64)\n",
      "Iter 137; theta =  tensor([6.4443421721, 8.4934945804], dtype=torch.float64)\n",
      "Iter 138; theta =  tensor([6.4547042012, 8.5052401692], dtype=torch.float64)\n",
      "Iter 139; theta =  tensor([6.4673969913, 8.5192380172], dtype=torch.float64)\n",
      "Iter 140; theta =  tensor([6.4775813246, 8.5282650560], dtype=torch.float64)\n",
      "Iter 141; theta =  tensor([6.4888120365, 8.5438417119], dtype=torch.float64)\n",
      "Iter 142; theta =  tensor([6.4989295304, 8.5527683896], dtype=torch.float64)\n",
      "Iter 143; theta =  tensor([6.5085784721, 8.5636325163], dtype=torch.float64)\n",
      "Iter 144; theta =  tensor([6.5169264102, 8.5741436666], dtype=torch.float64)\n",
      "Iter 145; theta =  tensor([6.5269194525, 8.5842054838], dtype=torch.float64)\n",
      "Iter 146; theta =  tensor([6.5379095250, 8.5956505066], dtype=torch.float64)\n",
      "Iter 147; theta =  tensor([6.5451094836, 8.6031880862], dtype=torch.float64)\n",
      "Iter 148; theta =  tensor([6.5538437194, 8.6114360601], dtype=torch.float64)\n",
      "Iter 149; theta =  tensor([6.5640375429, 8.6224190146], dtype=torch.float64)\n",
      "Iter 150; theta =  tensor([6.5722037894, 8.6272598812], dtype=torch.float64)\n",
      "Iter 151; theta =  tensor([6.5818223274, 8.6375348613], dtype=torch.float64)\n",
      "Iter 152; theta =  tensor([6.5894297278, 8.6454912439], dtype=torch.float64)\n",
      "Iter 153; theta =  tensor([6.5960425419, 8.6507139698], dtype=torch.float64)\n",
      "Iter 154; theta =  tensor([6.6037226140, 8.6558903047], dtype=torch.float64)\n",
      "Iter 155; theta =  tensor([6.6100011659, 8.6612020347], dtype=torch.float64)\n",
      "Iter 156; theta =  tensor([6.6165863675, 8.6658249480], dtype=torch.float64)\n",
      "Iter 157; theta =  tensor([6.6241601747, 8.6760068816], dtype=torch.float64)\n",
      "Iter 158; theta =  tensor([6.6318785304, 8.6818729711], dtype=torch.float64)\n",
      "Iter 159; theta =  tensor([6.6400873470, 8.6886845726], dtype=torch.float64)\n",
      "Iter 160; theta =  tensor([6.6466865647, 8.6953082752], dtype=torch.float64)\n",
      "Iter 161; theta =  tensor([6.6528247094, 8.7031212401], dtype=torch.float64)\n",
      "Iter 162; theta =  tensor([6.6604527992, 8.7107783294], dtype=torch.float64)\n",
      "Iter 163; theta =  tensor([6.6679515600, 8.7183127564], dtype=torch.float64)\n",
      "Iter 164; theta =  tensor([6.6744892967, 8.7241188323], dtype=torch.float64)\n",
      "Iter 165; theta =  tensor([6.6803264034, 8.7332543159], dtype=torch.float64)\n",
      "Iter 166; theta =  tensor([6.6858572602, 8.7386714518], dtype=torch.float64)\n",
      "Iter 167; theta =  tensor([6.6921463513, 8.7428976706], dtype=torch.float64)\n",
      "Iter 168; theta =  tensor([6.6979415500, 8.7460786730], dtype=torch.float64)\n",
      "Iter 169; theta =  tensor([6.7031650484, 8.7520010161], dtype=torch.float64)\n",
      "Iter 170; theta =  tensor([6.7098917645, 8.7568829915], dtype=torch.float64)\n",
      "Iter 171; theta =  tensor([6.7151358181, 8.7610003832], dtype=torch.float64)\n",
      "Iter 172; theta =  tensor([6.7200881636, 8.7659238565], dtype=torch.float64)\n",
      "Iter 173; theta =  tensor([6.7259253061, 8.7698245692], dtype=torch.float64)\n",
      "Iter 174; theta =  tensor([6.7308121935, 8.7737941861], dtype=torch.float64)\n",
      "Iter 175; theta =  tensor([6.7364891180, 8.7787386808], dtype=torch.float64)\n",
      "Iter 176; theta =  tensor([6.7414144647, 8.7836340088], dtype=torch.float64)\n",
      "Iter 177; theta =  tensor([6.7462345532, 8.7870654368], dtype=torch.float64)\n",
      "Iter 178; theta =  tensor([6.7514108518, 8.7917985111], dtype=torch.float64)\n",
      "Iter 179; theta =  tensor([6.7554174882, 8.7965805057], dtype=torch.float64)\n",
      "Iter 180; theta =  tensor([6.7602988204, 8.8014971697], dtype=torch.float64)\n",
      "Iter 181; theta =  tensor([6.7652839640, 8.8050311637], dtype=torch.float64)\n",
      "Iter 182; theta =  tensor([6.7702965876, 8.8083418539], dtype=torch.float64)\n",
      "Iter 183; theta =  tensor([6.7748969245, 8.8127177128], dtype=torch.float64)\n",
      "Iter 184; theta =  tensor([6.7800469524, 8.8179639217], dtype=torch.float64)\n",
      "Iter 185; theta =  tensor([6.7845910579, 8.8208904082], dtype=torch.float64)\n",
      "Iter 186; theta =  tensor([6.7888591084, 8.8235100609], dtype=torch.float64)\n",
      "Iter 187; theta =  tensor([6.7934377035, 8.8269128549], dtype=torch.float64)\n",
      "Iter 188; theta =  tensor([6.7975899625, 8.8314046019], dtype=torch.float64)\n",
      "Iter 189; theta =  tensor([6.8014039510, 8.8336106925], dtype=torch.float64)\n",
      "Iter 190; theta =  tensor([6.8049018177, 8.8370809801], dtype=torch.float64)\n",
      "Iter 191; theta =  tensor([6.8100326332, 8.8414700149], dtype=torch.float64)\n",
      "Iter 192; theta =  tensor([6.8140157959, 8.8453034712], dtype=torch.float64)\n",
      "Iter 193; theta =  tensor([6.8178288391, 8.8486000679], dtype=torch.float64)\n",
      "Iter 194; theta =  tensor([6.8211004043, 8.8516545580], dtype=torch.float64)\n",
      "Iter 195; theta =  tensor([6.8244978318, 8.8546228497], dtype=torch.float64)\n",
      "Iter 196; theta =  tensor([6.8273341638, 8.8566897981], dtype=torch.float64)\n",
      "Iter 197; theta =  tensor([6.8303026253, 8.8586136164], dtype=torch.float64)\n",
      "Iter 198; theta =  tensor([6.8333574602, 8.8612114383], dtype=torch.float64)\n",
      "Iter 199; theta =  tensor([6.8368122521, 8.8641132097], dtype=torch.float64)\n",
      "Iter 200; theta =  tensor([6.8403944176, 8.8671718644], dtype=torch.float64)\n",
      "Iter 201; theta =  tensor([6.8435786760, 8.8700755329], dtype=torch.float64)\n",
      "Iter 202; theta =  tensor([6.8468572509, 8.8730169059], dtype=torch.float64)\n",
      "Iter 203; theta =  tensor([6.8500078517, 8.8756456472], dtype=torch.float64)\n",
      "Iter 204; theta =  tensor([6.8531067130, 8.8784860848], dtype=torch.float64)\n",
      "Iter 205; theta =  tensor([6.8559899041, 8.8809083748], dtype=torch.float64)\n",
      "Iter 206; theta =  tensor([6.8592321920, 8.8834661925], dtype=torch.float64)\n",
      "Iter 207; theta =  tensor([6.8620031247, 8.8859437887], dtype=torch.float64)\n",
      "Iter 208; theta =  tensor([6.8650954041, 8.8883416335], dtype=torch.float64)\n",
      "Iter 209; theta =  tensor([6.8673083115, 8.8896121161], dtype=torch.float64)\n",
      "Iter 210; theta =  tensor([6.8698293990, 8.8920437017], dtype=torch.float64)\n",
      "Iter 211; theta =  tensor([6.8718292113, 8.8931850051], dtype=torch.float64)\n",
      "Iter 212; theta =  tensor([6.8744873025, 8.8960860061], dtype=torch.float64)\n",
      "Iter 213; theta =  tensor([6.8768203995, 8.8982028642], dtype=torch.float64)\n",
      "Iter 214; theta =  tensor([6.8794298372, 8.9011101847], dtype=torch.float64)\n",
      "Iter 215; theta =  tensor([6.8813527571, 8.9031088673], dtype=torch.float64)\n",
      "Iter 216; theta =  tensor([6.8838756491, 8.9055909268], dtype=torch.float64)\n",
      "Iter 217; theta =  tensor([6.8861251196, 8.9069588376], dtype=torch.float64)\n",
      "Iter 218; theta =  tensor([6.8880078898, 8.9079157020], dtype=torch.float64)\n",
      "Iter 219; theta =  tensor([6.8899787873, 8.9099341358], dtype=torch.float64)\n",
      "Iter 220; theta =  tensor([6.8924602129, 8.9119749588], dtype=torch.float64)\n",
      "Iter 221; theta =  tensor([6.8943015501, 8.9133003859], dtype=torch.float64)\n",
      "Iter 222; theta =  tensor([6.8968888927, 8.9162360273], dtype=torch.float64)\n",
      "Iter 223; theta =  tensor([6.8987069346, 8.9177186567], dtype=torch.float64)\n",
      "Iter 224; theta =  tensor([6.9003065135, 8.9185182755], dtype=torch.float64)\n",
      "Iter 225; theta =  tensor([6.9020369087, 8.9197651929], dtype=torch.float64)\n",
      "Iter 226; theta =  tensor([6.9041506861, 8.9218252779], dtype=torch.float64)\n",
      "Iter 227; theta =  tensor([6.9062135729, 8.9235436969], dtype=torch.float64)\n",
      "Iter 228; theta =  tensor([6.9079190210, 8.9251421691], dtype=torch.float64)\n",
      "Iter 229; theta =  tensor([6.9098487867, 8.9263801236], dtype=torch.float64)\n",
      "Iter 230; theta =  tensor([6.9118500946, 8.9285831492], dtype=torch.float64)\n",
      "Iter 231; theta =  tensor([6.9137543607, 8.9298652747], dtype=torch.float64)\n",
      "Iter 232; theta =  tensor([6.9156251258, 8.9310818072], dtype=torch.float64)\n",
      "Iter 233; theta =  tensor([6.9175367172, 8.9324935044], dtype=torch.float64)\n",
      "Iter 234; theta =  tensor([6.9193099532, 8.9335789261], dtype=torch.float64)\n",
      "Iter 235; theta =  tensor([6.9210044719, 8.9350629187], dtype=torch.float64)\n",
      "Iter 236; theta =  tensor([6.9225156212, 8.9363979424], dtype=torch.float64)\n",
      "Iter 237; theta =  tensor([6.9240200782, 8.9374541879], dtype=torch.float64)\n",
      "Iter 238; theta =  tensor([6.9255185954, 8.9386047832], dtype=torch.float64)\n",
      "Iter 239; theta =  tensor([6.9271399869, 8.9399075126], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6.9271399869, 8.9399075126], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sua função deve retornar algo perto de 7 e 9\n",
    "minibatch_gd(derivada_torch, media_erros_quadrados, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khoTY_BZonb7"
   },
   "source": [
    "## Conjunto de Problemas 3: Logistic from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puVaL8Kuonb8"
   },
   "source": [
    "12. Repita o mesmo processo para a Logística. Lembrando que a mesma tem a seguinte forma:\n",
    "\n",
    "$$f(x_i) = \\frac{1}{1 + e^{-(1 + \\theta_1 x_{i1} + \\theta_2 x_{i2} + \\cdots \\theta_k x_{ik})}}$$\n",
    "\n",
    "Implemente a função logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X, theta):\n",
    "    return 1.0 / (1 + torch.exp(-torch.matmul(X, theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague!\n",
    "X_teste = torch.randn(1000, 20000)\n",
    "theta = torch.randn(20000)\n",
    "y_hat_teste = logistic(X_teste, theta)\n",
    "assert_equal(True, (y_hat_teste >= 0).numpy().all())\n",
    "assert_equal(True, (y_hat_teste <= 1).numpy().all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcOzTSYqoncA"
   },
   "source": [
    "Usando a logística acima implemente uma função logistica_prever que retorna 0 ou 1. Use o limar dado na função. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IzJAoDYoncB"
   },
   "outputs": [],
   "source": [
    "def logistica_prever(X, theta, limiar=0.5):\n",
    "    return logistic(X, theta) > limiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague!\n",
    "X_teste = torch.randn(1000, 20000)\n",
    "theta = torch.randn(20000)\n",
    "y_hat_teste = logistica_prever(X_teste, theta)\n",
    "for yi in y_hat_teste.numpy():\n",
    "    assert(yi in {0, 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34WQX2AloncI"
   },
   "source": [
    "Agora, implemente uma função de entropia cruzada da logística. A mesma, é proporcional ao inverso da verossimilhança. Para entender a derivação entre as duas faça uso dos [Slides](https://docs.google.com/presentation/d/1yGPETPe8o7PPOP6_CF38LHr3vpxgTEnF5LjP-1pkGIc/edit?usp=sharing). \n",
    "\n",
    "Sendo:\n",
    "\n",
    "$$ll(x_i,y_i~|~\\theta) = y_i \\log f(x_i\\theta) + (1-y_i) \\log (1-f(x_i\\theta))$$\n",
    "\n",
    "A verossimilhança para uma observação. A entropia cruzada é a media da negação do termo para todos os exemplos:\n",
    "\n",
    "$$L(\\theta) = -n^{-1}\\sum_i \\big((1-y_i)\\log (1-f_{\\theta}(x_i)) + y_i\\log (f_{\\theta}(x_i))\\big)$$\n",
    "\n",
    "`dica: use torch.clamp(logistic(X, theta), min = 0.001, max = 0.999)`. A função remove os 0 e 1s da logistic, evitando assim o valor log(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_mean(X, theta, y):\n",
    "    logit = logistic(X, theta)\n",
    "    logit = torch.clamp(logit, min=0.00001, max = 0.99999)\n",
    "    return -(y * torch.log(logit) + (1 - y) * torch.log(1 - logit)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MC_fPXj0oncM"
   },
   "outputs": [],
   "source": [
    "# testes, não apague!\n",
    "from sklearn import datasets\n",
    "state = np.random.seed(20190187)\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=200, n_features=2, centers=2)\n",
    "X = torch.tensor(X).double()\n",
    "y = torch.tensor(y).double()\n",
    "\n",
    "for _ in range(100):\n",
    "    theta = torch.randn(2,1).double()\n",
    "    assert(cross_entropy_mean(X, theta, y) >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1E_BSkhoncO"
   },
   "source": [
    "Agora implemente a derivada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivada_torch_logit(X, theta, y):\n",
    "    e = cross_entropy_mean(X, theta, y)\n",
    "    e.backward()\n",
    "    return theta.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4kELMG4oncS"
   },
   "source": [
    "A partir daqui basta executar código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZP6mlFIoncT",
    "outputId": "aef7cc0f-d70b-4abd-f59a-85f7a1fe5f6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7eff1ed16450>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], s=80, edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlRLH5sMoncW"
   },
   "source": [
    "13. Assim como foi feito na primeira aula, abaixo testamos o seu código com um toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mY_Dfj8oncW"
   },
   "outputs": [],
   "source": [
    "# Use essa função antes de executar o GD\n",
    "def add_intercept(X):\n",
    "    Xn = torch.zeros(X.shape[0], X.shape[1] + 1).double()\n",
    "    Xn[:, 0]  = 1.0\n",
    "    Xn[:, 1:] = X\n",
    "    return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT4OCJwYoncb",
    "outputId": "77ea02e1-5aa9-4e0c-9944-d8491544d956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; theta =  tensor([-0.8599472642, -1.4107571840, -0.1103338823], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Iter 1; theta =  tensor([-0.8567792973, -1.4126434266, -0.0802032104], dtype=torch.float64)\n",
      "Iter 2; theta =  tensor([-0.8540394320, -1.4142716085, -0.0542502057], dtype=torch.float64)\n",
      "Iter 3; theta =  tensor([-0.8510760009, -1.4156790606, -0.0270581021], dtype=torch.float64)\n",
      "Iter 4; theta =  tensor([-8.4808106480e-01, -1.4163981188e+00,  4.8596724321e-04],\n",
      "       dtype=torch.float64)\n",
      "Iter 5; theta =  tensor([-0.8457030689, -1.4174502911,  0.0225152206], dtype=torch.float64)\n",
      "Iter 6; theta =  tensor([-0.8439808195, -1.4183113074,  0.0392452831], dtype=torch.float64)\n",
      "Iter 7; theta =  tensor([-0.8418592173, -1.4186830690,  0.0593379522], dtype=torch.float64)\n",
      "Iter 8; theta =  tensor([-0.8397000898, -1.4190715360,  0.0792534041], dtype=torch.float64)\n",
      "Iter 9; theta =  tensor([-0.8381510094, -1.4195925298,  0.0943488604], dtype=torch.float64)\n",
      "Iter 10; theta =  tensor([-0.8362264778, -1.4198687862,  0.1122870362], dtype=torch.float64)\n",
      "Iter 11; theta =  tensor([-0.8349544257, -1.4199318795,  0.1239983587], dtype=torch.float64)\n",
      "Iter 12; theta =  tensor([-0.8336932849, -1.4201132175,  0.1355439646], dtype=torch.float64)\n",
      "Iter 13; theta =  tensor([-0.8325497484, -1.4205327199,  0.1464745201], dtype=torch.float64)\n",
      "Iter 14; theta =  tensor([-0.8316450672, -1.4206430884,  0.1547029576], dtype=torch.float64)\n",
      "Iter 15; theta =  tensor([-0.8309100153, -1.4209191743,  0.1613309610], dtype=torch.float64)\n",
      "Iter 16; theta =  tensor([-0.8295993827, -1.4209426804,  0.1734869981], dtype=torch.float64)\n",
      "Iter 17; theta =  tensor([-0.8287088816, -1.4211616618,  0.1817953126], dtype=torch.float64)\n",
      "Iter 18; theta =  tensor([-0.8277900720, -1.4213461648,  0.1902322129], dtype=torch.float64)\n",
      "Iter 19; theta =  tensor([-0.8269349906, -1.4215324882,  0.1982111457], dtype=torch.float64)\n",
      "Iter 20; theta =  tensor([-0.8265287290, -1.4217849889,  0.2020015328], dtype=torch.float64)\n",
      "Iter 21; theta =  tensor([-0.8258316135, -1.4219778175,  0.2087318741], dtype=torch.float64)\n",
      "Iter 22; theta =  tensor([-0.8252506907, -1.4221577065,  0.2139827780], dtype=torch.float64)\n",
      "Iter 23; theta =  tensor([-0.8248307961, -1.4224293918,  0.2180112420], dtype=torch.float64)\n",
      "Iter 24; theta =  tensor([-0.8241214064, -1.4225226561,  0.2244269797], dtype=torch.float64)\n",
      "Iter 25; theta =  tensor([-0.8233943256, -1.4225192237,  0.2313398980], dtype=torch.float64)\n",
      "Iter 26; theta =  tensor([-0.8223073070, -1.4222682568,  0.2406899084], dtype=torch.float64)\n",
      "Iter 27; theta =  tensor([-0.8218029211, -1.4224086821,  0.2454788228], dtype=torch.float64)\n",
      "Iter 28; theta =  tensor([-0.8210912341, -1.4223276301,  0.2517766651], dtype=torch.float64)\n",
      "Iter 29; theta =  tensor([-0.8207034034, -1.4224489660,  0.2552510647], dtype=torch.float64)\n",
      "Iter 30; theta =  tensor([-0.8202277930, -1.4225686351,  0.2595936183], dtype=torch.float64)\n",
      "Iter 31; theta =  tensor([-0.8198844485, -1.4226174804,  0.2629483562], dtype=torch.float64)\n",
      "Iter 32; theta =  tensor([-0.8193207051, -1.4226271621,  0.2683183366], dtype=torch.float64)\n",
      "Iter 33; theta =  tensor([-0.8188326036, -1.4226911401,  0.2728218547], dtype=torch.float64)\n",
      "Iter 34; theta =  tensor([-0.8183485167, -1.4227126927,  0.2772371701], dtype=torch.float64)\n",
      "Iter 35; theta =  tensor([-0.8179888571, -1.4227969241,  0.2806306348], dtype=torch.float64)\n",
      "Iter 36; theta =  tensor([-0.8176767575, -1.4228990689,  0.2835284829], dtype=torch.float64)\n",
      "Iter 37; theta =  tensor([-0.8171057114, -1.4229591480,  0.2886972598], dtype=torch.float64)\n",
      "Iter 38; theta =  tensor([-0.8167190584, -1.4229597454,  0.2921117112], dtype=torch.float64)\n",
      "Iter 39; theta =  tensor([-0.8165115395, -1.4230627398,  0.2941117875], dtype=torch.float64)\n",
      "Iter 40; theta =  tensor([-0.8161511516, -1.4231128661,  0.2973967913], dtype=torch.float64)\n",
      "Iter 41; theta =  tensor([-0.8157462887, -1.4231373814,  0.3011130579], dtype=torch.float64)\n",
      "Iter 42; theta =  tensor([-0.8152998146, -1.4232590293,  0.3050653526], dtype=torch.float64)\n",
      "Iter 43; theta =  tensor([-0.8149724960, -1.4232938365,  0.3081469567], dtype=torch.float64)\n",
      "Iter 44; theta =  tensor([-0.8148017441, -1.4233886741,  0.3097971758], dtype=torch.float64)\n",
      "Iter 45; theta =  tensor([-0.8145454705, -1.4234748377,  0.3122266930], dtype=torch.float64)\n",
      "Iter 46; theta =  tensor([-0.8142438879, -1.4235447704,  0.3149337616], dtype=torch.float64)\n",
      "Iter 47; theta =  tensor([-0.8139534495, -1.4235715124,  0.3176441007], dtype=torch.float64)\n",
      "Iter 48; theta =  tensor([-0.8137338013, -1.4236128514,  0.3196980025], dtype=torch.float64)\n",
      "Iter 49; theta =  tensor([-0.8135489890, -1.4236915807,  0.3215438191], dtype=torch.float64)\n",
      "Iter 50; theta =  tensor([-0.8132669296, -1.4237917123,  0.3241016452], dtype=torch.float64)\n",
      "Iter 51; theta =  tensor([-0.8128728732, -1.4237823808,  0.3277317919], dtype=torch.float64)\n",
      "Iter 52; theta =  tensor([-0.8124803728, -1.4237224489,  0.3312351315], dtype=torch.float64)\n",
      "Iter 53; theta =  tensor([-0.8122346276, -1.4237755263,  0.3335049209], dtype=torch.float64)\n",
      "Iter 54; theta =  tensor([-0.8119960901, -1.4238303042,  0.3357389644], dtype=torch.float64)\n",
      "Iter 55; theta =  tensor([-0.8117396966, -1.4238829147,  0.3381413526], dtype=torch.float64)\n",
      "Iter 56; theta =  tensor([-0.8115572054, -1.4239629131,  0.3398720755], dtype=torch.float64)\n",
      "Iter 57; theta =  tensor([-0.8113339751, -1.4240378730,  0.3419733037], dtype=torch.float64)\n",
      "Iter 58; theta =  tensor([-0.8111020039, -1.4240856194,  0.3441944949], dtype=torch.float64)\n",
      "Iter 59; theta =  tensor([-0.8109305683, -1.4241295343,  0.3458222629], dtype=torch.float64)\n",
      "Iter 60; theta =  tensor([-0.8107389574, -1.4241556556,  0.3475600595], dtype=torch.float64)\n",
      "Iter 61; theta =  tensor([-0.8105040363, -1.4241689089,  0.3496306214], dtype=torch.float64)\n",
      "Iter 62; theta =  tensor([-0.8102469990, -1.4241602098,  0.3519081264], dtype=torch.float64)\n",
      "Iter 63; theta =  tensor([-0.8099941927, -1.4241529759,  0.3542833410], dtype=torch.float64)\n",
      "Iter 64; theta =  tensor([-0.8097991564, -1.4241983548,  0.3560387862], dtype=torch.float64)\n",
      "Iter 65; theta =  tensor([-0.8096021545, -1.4242157196,  0.3579856756], dtype=torch.float64)\n",
      "Iter 66; theta =  tensor([-0.8094071690, -1.4242347786,  0.3598449741], dtype=torch.float64)\n",
      "Iter 67; theta =  tensor([-0.8091127087, -1.4242568860,  0.3624306468], dtype=torch.float64)\n",
      "Iter 68; theta =  tensor([-0.8089825717, -1.4243188255,  0.3636399751], dtype=torch.float64)\n",
      "Iter 69; theta =  tensor([-0.8086958923, -1.4242721974,  0.3662922294], dtype=torch.float64)\n",
      "Iter 70; theta =  tensor([-0.8085002166, -1.4243544078,  0.3680281350], dtype=torch.float64)\n",
      "Iter 71; theta =  tensor([-0.8083480573, -1.4244274969,  0.3693783691], dtype=torch.float64)\n",
      "Iter 72; theta =  tensor([-0.8079662149, -1.4243323650,  0.3727291434], dtype=torch.float64)\n",
      "Iter 73; theta =  tensor([-0.8078232110, -1.4244128258,  0.3740660042], dtype=torch.float64)\n",
      "Iter 74; theta =  tensor([-0.8076605696, -1.4244337996,  0.3756323623], dtype=torch.float64)\n",
      "Iter 75; theta =  tensor([-0.8074806690, -1.4244465008,  0.3772108990], dtype=torch.float64)\n",
      "Iter 76; theta =  tensor([-0.8073641125, -1.4245138676,  0.3783159370], dtype=torch.float64)\n",
      "Iter 77; theta =  tensor([-0.8071964228, -1.4245173591,  0.3798499813], dtype=torch.float64)\n",
      "Iter 78; theta =  tensor([-0.8071086772, -1.4245662833,  0.3807478101], dtype=torch.float64)\n",
      "Iter 79; theta =  tensor([-0.8069211742, -1.4245698796,  0.3824472920], dtype=torch.float64)\n",
      "Iter 80; theta =  tensor([-0.8068082038, -1.4246261692,  0.3834892895], dtype=torch.float64)\n",
      "Iter 81; theta =  tensor([-0.8066322495, -1.4246208078,  0.3851846522], dtype=torch.float64)\n",
      "Iter 82; theta =  tensor([-0.8064344730, -1.4246104727,  0.3869567290], dtype=torch.float64)\n",
      "Iter 83; theta =  tensor([-0.8062371375, -1.4245484583,  0.3887113878], dtype=torch.float64)\n",
      "Iter 84; theta =  tensor([-0.8060564409, -1.4245559954,  0.3903048971], dtype=torch.float64)\n",
      "Iter 85; theta =  tensor([-0.8058998263, -1.4246056690,  0.3917654923], dtype=torch.float64)\n",
      "Iter 86; theta =  tensor([-0.8057334914, -1.4245769109,  0.3932858211], dtype=torch.float64)\n",
      "Iter 87; theta =  tensor([-0.8056241364, -1.4245834695,  0.3943252154], dtype=torch.float64)\n",
      "Iter 88; theta =  tensor([-0.8055316427, -1.4246272658,  0.3952687503], dtype=torch.float64)\n",
      "Iter 89; theta =  tensor([-0.8054115135, -1.4246488803,  0.3963429843], dtype=torch.float64)\n",
      "Iter 90; theta =  tensor([-0.8052494459, -1.4246930346,  0.3978292134], dtype=torch.float64)\n",
      "Iter 91; theta =  tensor([-0.8051332733, -1.4247491365,  0.3989753679], dtype=torch.float64)\n",
      "Iter 92; theta =  tensor([-0.8049539554, -1.4247551722,  0.4006483502], dtype=torch.float64)\n",
      "Iter 93; theta =  tensor([-0.8047547472, -1.4247547940,  0.4024518392], dtype=torch.float64)\n",
      "Iter 94; theta =  tensor([-0.8046333412, -1.4247720399,  0.4035858705], dtype=torch.float64)\n",
      "Iter 95; theta =  tensor([-0.8044954116, -1.4247861044,  0.4048548942], dtype=torch.float64)\n",
      "Iter 96; theta =  tensor([-0.8043738567, -1.4248258792,  0.4059768569], dtype=torch.float64)\n",
      "Iter 97; theta =  tensor([-0.8042540411, -1.4248597984,  0.4071529116], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 98; theta =  tensor([-0.8040584419, -1.4248515463,  0.4089737330], dtype=torch.float64)\n",
      "Iter 99; theta =  tensor([-0.8038845562, -1.4248359941,  0.4105135490], dtype=torch.float64)\n",
      "Iter 100; theta =  tensor([-0.8037315946, -1.4248658465,  0.4119583488], dtype=torch.float64)\n",
      "Iter 101; theta =  tensor([-0.8035793851, -1.4249007030,  0.4132549561], dtype=torch.float64)\n",
      "Iter 102; theta =  tensor([-0.8034624676, -1.4249250362,  0.4143857510], dtype=torch.float64)\n",
      "Iter 103; theta =  tensor([-0.8033751882, -1.4249359464,  0.4152720370], dtype=torch.float64)\n",
      "Iter 104; theta =  tensor([-0.8031923605, -1.4249140853,  0.4169573313], dtype=torch.float64)\n",
      "Iter 105; theta =  tensor([-0.8030266271, -1.4249229678,  0.4184984127], dtype=torch.float64)\n",
      "Iter 106; theta =  tensor([-0.8029554780, -1.4249665239,  0.4192251544], dtype=torch.float64)\n",
      "Iter 107; theta =  tensor([-0.8028008696, -1.4250000970,  0.4205675364], dtype=torch.float64)\n",
      "Iter 108; theta =  tensor([-0.8027038400, -1.4250451717,  0.4214779610], dtype=torch.float64)\n",
      "Iter 109; theta =  tensor([-0.8026168494, -1.4250892446,  0.4223188894], dtype=torch.float64)\n",
      "Iter 110; theta =  tensor([-0.8024573136, -1.4250808384,  0.4237691560], dtype=torch.float64)\n",
      "Iter 111; theta =  tensor([-0.8023362373, -1.4250920086,  0.4248843660], dtype=torch.float64)\n",
      "Iter 112; theta =  tensor([-0.8022233102, -1.4251207458,  0.4259267133], dtype=torch.float64)\n",
      "Iter 113; theta =  tensor([-0.8020342921, -1.4251316765,  0.4275276027], dtype=torch.float64)\n",
      "Iter 114; theta =  tensor([-0.8019461474, -1.4251162392,  0.4283470431], dtype=torch.float64)\n",
      "Iter 115; theta =  tensor([-0.8018746824, -1.4251563557,  0.4290329040], dtype=torch.float64)\n",
      "Iter 116; theta =  tensor([-0.8017679165, -1.4251809010,  0.4300675121], dtype=torch.float64)\n",
      "Iter 117; theta =  tensor([-0.8016483955, -1.4251976412,  0.4311241613], dtype=torch.float64)\n",
      "Iter 118; theta =  tensor([-0.8015728604, -1.4252340184,  0.4318588997], dtype=torch.float64)\n",
      "Iter 119; theta =  tensor([-0.8013580954, -1.4252108274,  0.4337120709], dtype=torch.float64)\n",
      "Iter 120; theta =  tensor([-0.8012373761, -1.4252179225,  0.4347686012], dtype=torch.float64)\n",
      "Iter 121; theta =  tensor([-0.8011664556, -1.4252401719,  0.4354622619], dtype=torch.float64)\n",
      "Iter 122; theta =  tensor([-0.8010575425, -1.4252656073,  0.4364840674], dtype=torch.float64)\n",
      "Iter 123; theta =  tensor([-0.8009684862, -1.4253117416,  0.4373026287], dtype=torch.float64)\n",
      "Iter 124; theta =  tensor([-0.8008412506, -1.4253123532,  0.4384532446], dtype=torch.float64)\n",
      "Iter 125; theta =  tensor([-0.8007891836, -1.4253430881,  0.4389853014], dtype=torch.float64)\n",
      "Iter 126; theta =  tensor([-0.8007041111, -1.4253644106,  0.4397324792], dtype=torch.float64)\n",
      "Iter 127; theta =  tensor([-0.8005889637, -1.4253703128,  0.4407706981], dtype=torch.float64)\n",
      "Iter 128; theta =  tensor([-0.8004415509, -1.4253614824,  0.4420597122], dtype=torch.float64)\n",
      "Iter 129; theta =  tensor([-0.8003729603, -1.4253905849,  0.4426959757], dtype=torch.float64)\n",
      "Iter 130; theta =  tensor([-0.8002725338, -1.4254143556,  0.4435375760], dtype=torch.float64)\n",
      "Iter 131; theta =  tensor([-0.8002014940, -1.4254577737,  0.4442573423], dtype=torch.float64)\n",
      "Iter 132; theta =  tensor([-0.8001028408, -1.4254581176,  0.4451594968], dtype=torch.float64)\n",
      "Iter 133; theta =  tensor([-0.8000241265, -1.4254924856,  0.4458857250], dtype=torch.float64)\n",
      "Iter 134; theta =  tensor([-0.7998767514, -1.4254817321,  0.4471264989], dtype=torch.float64)\n",
      "Iter 135; theta =  tensor([-0.7997537911, -1.4254705670,  0.4482704898], dtype=torch.float64)\n",
      "Iter 136; theta =  tensor([-0.7996492622, -1.4254921809,  0.4492546404], dtype=torch.float64)\n",
      "Iter 137; theta =  tensor([-0.7995361759, -1.4254805733,  0.4502762754], dtype=torch.float64)\n",
      "Iter 138; theta =  tensor([-0.7994592083, -1.4255084967,  0.4509992632], dtype=torch.float64)\n",
      "Iter 139; theta =  tensor([-0.7993719347, -1.4255318049,  0.4518023169], dtype=torch.float64)\n",
      "Iter 140; theta =  tensor([-0.7992625011, -1.4255507846,  0.4528013920], dtype=torch.float64)\n",
      "Iter 141; theta =  tensor([-0.7991555218, -1.4255774299,  0.4536833271], dtype=torch.float64)\n",
      "Iter 142; theta =  tensor([-0.7990407150, -1.4255727392,  0.4547199410], dtype=torch.float64)\n",
      "Iter 143; theta =  tensor([-0.7989623818, -1.4256147521,  0.4554306839], dtype=torch.float64)\n",
      "Iter 144; theta =  tensor([-0.7988896596, -1.4256469222,  0.4560880112], dtype=torch.float64)\n",
      "Iter 145; theta =  tensor([-0.7987919345, -1.4256548854,  0.4569651375], dtype=torch.float64)\n",
      "Iter 146; theta =  tensor([-0.7986967829, -1.4256605574,  0.4577871367], dtype=torch.float64)\n",
      "Iter 147; theta =  tensor([-0.7986186627, -1.4256636812,  0.4584691990], dtype=torch.float64)\n",
      "Iter 148; theta =  tensor([-0.7984868821, -1.4256440139,  0.4596541575], dtype=torch.float64)\n",
      "Iter 149; theta =  tensor([-0.7983705901, -1.4256449017,  0.4607319416], dtype=torch.float64)\n",
      "Iter 150; theta =  tensor([-0.7982396130, -1.4256318723,  0.4619762872], dtype=torch.float64)\n",
      "Iter 151; theta =  tensor([-0.7980979840, -1.4255993020,  0.4633039969], dtype=torch.float64)\n",
      "Iter 152; theta =  tensor([-0.7980490487, -1.4256217927,  0.4638101641], dtype=torch.float64)\n",
      "Iter 153; theta =  tensor([-0.7979851371, -1.4256454176,  0.4644078913], dtype=torch.float64)\n",
      "Iter 154; theta =  tensor([-0.7979172283, -1.4256735513,  0.4650541933], dtype=torch.float64)\n",
      "Iter 155; theta =  tensor([-0.7978615819, -1.4257029358,  0.4655905466], dtype=torch.float64)\n",
      "Iter 156; theta =  tensor([-0.7977939642, -1.4257272948,  0.4662123514], dtype=torch.float64)\n",
      "Iter 157; theta =  tensor([-0.7976745857, -1.4257307506,  0.4672601736], dtype=torch.float64)\n",
      "Iter 158; theta =  tensor([-0.7976145074, -1.4257386968,  0.4678215394], dtype=torch.float64)\n",
      "Iter 159; theta =  tensor([-0.7975572055, -1.4257561346,  0.4683805604], dtype=torch.float64)\n",
      "Iter 160; theta =  tensor([-0.7974600684, -1.4257462607,  0.4692552960], dtype=torch.float64)\n",
      "Iter 161; theta =  tensor([-0.7973718229, -1.4257355651,  0.4700797364], dtype=torch.float64)\n",
      "Iter 162; theta =  tensor([-0.7972759814, -1.4257344142,  0.4710035368], dtype=torch.float64)\n",
      "Iter 163; theta =  tensor([-0.7971937199, -1.4257487691,  0.4717969053], dtype=torch.float64)\n",
      "Iter 164; theta =  tensor([-0.7971054466, -1.4257460781,  0.4726191233], dtype=torch.float64)\n",
      "Iter 165; theta =  tensor([-0.7970610905, -1.4257655939,  0.4730503222], dtype=torch.float64)\n",
      "Iter 166; theta =  tensor([-0.7970030666, -1.4257821360,  0.4736429993], dtype=torch.float64)\n",
      "Iter 167; theta =  tensor([-0.7969498017, -1.4257724746,  0.4741288868], dtype=torch.float64)\n",
      "Iter 168; theta =  tensor([-0.7968472414, -1.4257533796,  0.4750352918], dtype=torch.float64)\n",
      "Iter 169; theta =  tensor([-0.7967776495, -1.4257534759,  0.4756930076], dtype=torch.float64)\n",
      "Iter 170; theta =  tensor([-0.7967231190, -1.4257742889,  0.4762073588], dtype=torch.float64)\n",
      "Iter 171; theta =  tensor([-0.7966762698, -1.4258054540,  0.4766476159], dtype=torch.float64)\n",
      "Iter 172; theta =  tensor([-0.7966475084, -1.4258340714,  0.4769295728], dtype=torch.float64)\n",
      "Iter 173; theta =  tensor([-0.7966114114, -1.4258566486,  0.4773065327], dtype=torch.float64)\n",
      "Iter 174; theta =  tensor([-0.7965205466, -1.4258536921,  0.4781023371], dtype=torch.float64)\n",
      "Iter 175; theta =  tensor([-0.7964274047, -1.4258453421,  0.4789702356], dtype=torch.float64)\n",
      "Iter 176; theta =  tensor([-0.7963615787, -1.4258532045,  0.4795781421], dtype=torch.float64)\n",
      "Iter 177; theta =  tensor([-0.7963343993, -1.4258697628,  0.4798532341], dtype=torch.float64)\n",
      "Iter 178; theta =  tensor([-0.7962569432, -1.4258947046,  0.4805763342], dtype=torch.float64)\n",
      "Iter 179; theta =  tensor([-0.7961743955, -1.4258997305,  0.4813061248], dtype=torch.float64)\n",
      "Iter 180; theta =  tensor([-0.7961202714, -1.4259233676,  0.4818356889], dtype=torch.float64)\n",
      "Iter 181; theta =  tensor([-0.7960679862, -1.4259554081,  0.4823497820], dtype=torch.float64)\n",
      "Iter 182; theta =  tensor([-0.7960181781, -1.4259627755,  0.4828266759], dtype=torch.float64)\n",
      "Iter 183; theta =  tensor([-0.7959386561, -1.4259667005,  0.4835567991], dtype=torch.float64)\n",
      "Iter 184; theta =  tensor([-0.7959021379, -1.4260095841,  0.4839142316], dtype=torch.float64)\n",
      "Iter 185; theta =  tensor([-0.7958599082, -1.4260350560,  0.4843435656], dtype=torch.float64)\n",
      "Iter 186; theta =  tensor([-0.7957526130, -1.4260340186,  0.4852849633], dtype=torch.float64)\n",
      "Iter 187; theta =  tensor([-0.7957051330, -1.4260501551,  0.4857635760], dtype=torch.float64)\n",
      "Iter 188; theta =  tensor([-0.7956152208, -1.4260412590,  0.4865572012], dtype=torch.float64)\n",
      "Iter 189; theta =  tensor([-0.7955704559, -1.4260666123,  0.4869827246], dtype=torch.float64)\n",
      "Iter 190; theta =  tensor([-0.7955101578, -1.4260865833,  0.4875727977], dtype=torch.float64)\n",
      "Iter 191; theta =  tensor([-0.7954491683, -1.4261028568,  0.4882028950], dtype=torch.float64)\n",
      "Iter 192; theta =  tensor([-0.7954146217, -1.4261357002,  0.4885602023], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Xn = add_intercept(X)\n",
    "theta = minibatch_gd(derivada_torch_logit, cross_entropy_mean, Xn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47Iaopm_onch",
    "outputId": "083d3a55-287a-4aa1-9bb0-1b69011cae17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_p = logistica_prever(Xn, theta)\n",
    "print((y == y_p.int().double()).double().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_Linear_e_Logistica_Gabarito_vPytorch_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
