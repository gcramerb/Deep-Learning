{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.2 - MLP From Scratch_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WNk10-G4snv0"
      },
      "source": [
        "# Aprendizado Profundo - UFMG\n",
        "\n",
        "## Multi-Layered Perceptron (MLP) from Scratch\n",
        "\n",
        "Esse código é um arcabouço básico (feito usando somente Numpy) para criação de uma rede neural simples, composta de múltiplas camadas de Perceptrons.\n",
        "Tal arcabouço já vem com as seguintes funcionalidades pré-implementadas:\n",
        "    - funções de ativações básicas (como sigmoid e softmax)\n",
        "    - um algoritmo de otimização (Stochastic Gradient Descent -- SGD)\n",
        "    - uma função de perda (cross entropy)\n",
        "    - processo de treinamento e teste da rede neural\n",
        "\n",
        "**Seu objetivo é implementar o processo de forward e backpropagation para a camada.\n",
        "As partes que precisam de implementação estão indicadas ao longo do código com \"TODOs\".**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1s9-JTMRsnv6"
      },
      "source": [
        "### Data Loader\n",
        "\n",
        "A seção abaixo implementa o carregamento de dois datasets:\n",
        "\n",
        "    - MNIST, um dataset de dígitos escritos à mão, e\n",
        "    - SVHN, um dataset de dígitos de imagens do Google Street View\n",
        "\n",
        "Posteriormente, você poderá escolher qual dataset gostaria de testar sua arquitetura."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qptWceCysnv8",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "import scipy.io\n",
        "\n",
        "\n",
        "# carregando MNIST dataset: http://yann.lecun.com/exdb/mnist/\n",
        "def load_mnist(dirpath):\n",
        "    def download():\n",
        "        if not os.path.isdir(dirpath):\n",
        "            os.makedirs(dirpath)\n",
        "\n",
        "        url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "        for file_name in file_names:\n",
        "            if os.path.isfile(os.path.join(dirpath, file_name)):\n",
        "                print('File ' + file_name + ' already exists')\n",
        "                continue\n",
        "\n",
        "            url = (url_base + file_name + '.gz').format(**locals())\n",
        "            print(url)\n",
        "            out_path = os.path.join(dirpath, file_name + '.gz')\n",
        "            cmd = ['curl', url, '-o', out_path]\n",
        "            print('Downloading ', file_name)\n",
        "            subprocess.call(cmd)\n",
        "            cmd = ['gzip', '-d', out_path]\n",
        "            print('Decompressing ', file_name)\n",
        "            subprocess.call(cmd)\n",
        "\n",
        "    def load_images(filename):\n",
        "        \"\"\"\n",
        "        Retorna um array 2d com as imagens do MNIST dataset.\n",
        "        images : array de formato (n_imagens, n_pixels)\n",
        "                 n_pixels = 28*28 = 784\n",
        "        filename: nome do arquivo\n",
        "        \"\"\"\n",
        "        with open(filename, \"r\") as f:\n",
        "            magic = np.fromfile(f, dtype=np.dtype('>i4'), count=1)\n",
        "\n",
        "            n_images = np.fromfile(f, dtype=np.dtype('>i4'), count=1)[0]\n",
        "            rows = np.fromfile(f, dtype=np.dtype('>i4'), count=1)[0]\n",
        "            cols = np.fromfile(f, dtype=np.dtype('>i4'), count=1)[0]\n",
        "\n",
        "            images = np.fromfile(f, dtype=np.ubyte)\n",
        "            images = images.astype(np.float64) / 255\n",
        "            images = images.reshape((n_images, rows, cols, 1))\n",
        "\n",
        "            f.close()\n",
        "\n",
        "        return images\n",
        "\n",
        "    def load_labels(filename):\n",
        "        \"\"\"\n",
        "        Retorna um array com os labels do dataset MNIST dataset.\n",
        "        labels : array de formato (n_labels)\n",
        "        filename: nome do arquivo\n",
        "        \"\"\"\n",
        "        with open(filename, 'r') as f:\n",
        "            magic = np.fromfile(f, dtype=np.dtype('>i4'), count=1)\n",
        "            n_labels = np.fromfile(f, dtype=np.dtype('>i4'), count=1)\n",
        "            labels = np.fromfile(f, dtype=np.uint8)\n",
        "\n",
        "            f.close()\n",
        "\n",
        "            return np.squeeze(np.array([one_hot_coding(lbl) for lbl in labels]).astype(np.uint8))\n",
        "\n",
        "    def one_hot_coding(label):\n",
        "        if label not in labels_to_categorical:\n",
        "            y = np.zeros((10, 1), dtype=np.uint8)\n",
        "            y[label] = 1\n",
        "            labels_to_categorical[label] = y\n",
        "        return labels_to_categorical[label]\n",
        "\n",
        "    labels_to_categorical = dict()\n",
        "\n",
        "    file_names = ['train-images-idx3-ubyte',\n",
        "                  'train-labels-idx1-ubyte',\n",
        "                  't10k-images-idx3-ubyte',\n",
        "                  't10k-labels-idx1-ubyte']\n",
        "\n",
        "    download()\n",
        "\n",
        "    train_data = load_images(os.path.join(dirpath, file_names[0]))\n",
        "    train_labels = load_labels(os.path.join(dirpath, file_names[1]))\n",
        "    test_data = load_images(os.path.join(dirpath, file_names[2]))\n",
        "    test_labels = load_labels(os.path.join(dirpath, file_names[3]))\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "\n",
        "# load SVHN dataset -- http://ufldl.stanford.edu/housenumbers/\n",
        "def load_svhn(dirpath):\n",
        "    def download():\n",
        "        if not os.path.isdir(dirpath):\n",
        "            os.makedirs(dirpath)\n",
        "\n",
        "        url_base = 'http://ufldl.stanford.edu/housenumbers/'\n",
        "        for file_name in file_names:\n",
        "            if os.path.isfile(os.path.join(dirpath, file_name + '.mat')):\n",
        "                print('File ' + file_name + ' already exists')\n",
        "                continue\n",
        "\n",
        "            url = (url_base + file_name + '.mat').format(**locals())\n",
        "            print(url)\n",
        "            out_path = os.path.join(dirpath, file_name + '.mat')\n",
        "            cmd = ['curl', url, '-o', out_path]\n",
        "            print('Downloading ', file_name)\n",
        "            subprocess.call(cmd)\n",
        "\n",
        "    def load_images(filename):\n",
        "        \"\"\"\n",
        "        Return a 2d array of images from MNIST dataset.\n",
        "        images : array, shape (n_images, n_pixels)\n",
        "                 n_pixels = 28*28 = 784\n",
        "        filename: input data file\n",
        "        \"\"\"\n",
        "        mat = scipy.io.loadmat(filename)\n",
        "        data = np.rollaxis(mat['X'], -1, 0)\n",
        "        data = data.astype(np.float64) / 255\n",
        "        labels = np.squeeze(np.array([one_hot_coding(lbl[0] if lbl[0] != 10 else 0)\n",
        "                                      for lbl in mat['y']]).astype(np.uint8))\n",
        "\n",
        "        return data[:, 2:30, 2:30, 0:1], labels  # 28x28 only first band is used\n",
        "\n",
        "    def one_hot_coding(label):\n",
        "        if label not in labels_to_categorical:\n",
        "            y = np.zeros((10, 1), dtype=np.uint8)\n",
        "            y[label] = 1\n",
        "            labels_to_categorical[label] = y\n",
        "        return labels_to_categorical[label]\n",
        "\n",
        "    labels_to_categorical = dict()\n",
        "\n",
        "    file_names = ['train_32x32',\n",
        "                  'test_32x32']\n",
        "\n",
        "    download()\n",
        "\n",
        "    train_data, train_labels = load_images(os.path.join(dirpath, file_names[0]))\n",
        "    test_data, test_labels = load_images(os.path.join(dirpath, file_names[1]))\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cnu2Sf-GsnwM"
      },
      "source": [
        "### Funções Básicas\n",
        "\n",
        "Essa seção de código abaixo implementa as funções de ativação e de custo, além de suas respectivas derivadas.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1NsikEgW2nR335542-gSt5cZI8JRvxddW\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L39SI6sRsnwO",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# inicializacao dos pesos ####################################################\n",
        "\n",
        "def glorot_uniform(shape, num_neurons_in, num_neurons_out):  # tambem conhecida como xavier\n",
        "    scale = np.sqrt(6. / (num_neurons_in + num_neurons_out))\n",
        "    return np.random.uniform(low=-scale, high=scale, size=shape)\n",
        "\n",
        "\n",
        "def zero(shape):\n",
        "    return np.zeros(shape)\n",
        "\n",
        "\n",
        "# ativacoes ################################################################\n",
        "\n",
        "# sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "\n",
        "# derivative sigmoid\n",
        "def der_sigmoid(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1.0 - s)\n",
        "\n",
        "\n",
        "# softmax\n",
        "def softmax(x):\n",
        "    e = np.exp(x - np.amax(x, axis=1, keepdims=True))  # more stable softmax to avoid precision problems\n",
        "    return e / np.sum(e, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "# derivative softmax\n",
        "def der_softmax(x, y=None):\n",
        "    s = softmax(x)\n",
        "    if y is not None:\n",
        "        k = s[np.where(y == 1)]\n",
        "        a = - k * s\n",
        "        a[np.where(y == 1)] = k * (1 - k)\n",
        "        return a\n",
        "    return s * (1 - s)\n",
        "\n",
        "\n",
        "# funcoes objetivos ###########################################################\n",
        "\n",
        "# cross entropy\n",
        "def cross_entropy(a, y):\n",
        "    m = y.shape[0]\n",
        "    return -np.sum(np.sum(y * np.log(a))) / m\n",
        "\n",
        "\n",
        "# derivative cross entropy\n",
        "def der_cross_entropy(a, y):\n",
        "    m = y.shape[0]\n",
        "    grad = softmax(a)\n",
        "    grad[range(m), np.argmax(y, axis=1)] -= 1\n",
        "    grad = grad/m\n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wHtbsF28snwW"
      },
      "source": [
        "### Algoritmo de Otimização\n",
        "\n",
        "Essa seção de código abaixo implementa o algoritmo de otimização, no caso, o SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3MpM8pzsnwY",
        "colab": {}
      },
      "source": [
        "import abc\n",
        "\n",
        "\n",
        "class Optimizer:\n",
        "    __metaclass__ = abc.ABCMeta\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def apply(self, layers, sum_der_w, sum_der_b, batch_len):\n",
        "        raise AssertionError\n",
        "\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def apply(self, layers, sum_der_w, sum_der_b, batch_len):\n",
        "        for i in range(1, len(layers)):\n",
        "            gw = sum_der_w[layers[i]]/batch_len\n",
        "            layers[i].w += -(self.lr*gw)\n",
        "\n",
        "            gb = sum_der_b[layers[i]]/batch_len\n",
        "            layers[i].b += -(self.lr*gb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LT0OCLV4snwe"
      },
      "source": [
        "### Camadas\n",
        "\n",
        "Essa seção de código abaixo implementa as camadas utilizadas para construir as redes neurais.\n",
        "Nesse caso, há uma classe abstrata (class Layer) que implementa o template que todas as camadas devem seguir.\n",
        "Além disso, há a classe que implementa a camada que manipula a entrada dos dados (class InputLayer).\n",
        "Essa camada precisa ser, **obrigatoriamente**, a primeira camada de qualquer rede proposta utilizando esse código, já que ela é responsável por lidas com o dado de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwXpdG8ksnwh",
        "colab": {}
      },
      "source": [
        "import abc\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# camada abstrata\n",
        "# essa classe abstrata sera a classe mae de todas as outras camadas\n",
        "# ela faz com que as outras camadas tenham ao menos duas funcoes (alem da funcao init): feedforward e backpropagation\n",
        "class Layer:\n",
        "    __metaclass__ = abc.ABCMeta\n",
        "\n",
        "    def __init__(self):\n",
        "        self.in_depth = None\n",
        "        self.height = None\n",
        "        self.width = None\n",
        "        self.out_depth = None\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def feedforward(self, prev_layer):\n",
        "        raise AssertionError\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def backpropagate(self, prev_layer, delta):\n",
        "        raise AssertionError\n",
        "\n",
        "\n",
        "# input layer -- essa camada eh responsavel por receber o dado de entrada\n",
        "# ela eh so uma abstracao que transforma o dado em uma camada\n",
        "# PRECISA ser a primeira de qualquer rede criada com esse codigo\n",
        "class InputLayer(Layer):\n",
        "    def __init__(self, input_height, input_width, input_channel):\n",
        "        super(InputLayer, self).__init__()\n",
        "        self.in_depth = input_channel\n",
        "        self.height = input_height\n",
        "        self.width = input_width\n",
        "        self.out_depth = input_channel\n",
        "        self.der_act_func = lambda x: x\n",
        "\n",
        "    def feedforward(self, prev_layer):\n",
        "        raise AssertionError\n",
        "\n",
        "    def backpropagate(self, prev_layer, delta):\n",
        "        raise AssertionError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dATUBGT4snwm"
      },
      "source": [
        "### Camada Fully Connected\n",
        "\n",
        "Essa seção de código abaixo implementa uma camada composta de vários perceptrons.\n",
        "Logo, uma rede neural profunda com várias dessas camadas pode ser vista como uma Multi-Layered Perceptron.\n",
        "\n",
        "A aula prática hoje será feita essencialmente nesse bloco de código, onde alguns *TODO*s marcam e explicam onde e o que deve ser implementado.\n",
        "**Em termos gerais, o objetivo da aula é implementar o processo de forward e backpropagation dessa camada.**\n",
        "\n",
        "**1. Forward**\n",
        "\n",
        "O processo de forward usa os dados de entrada da camada junto com os pesos e o bias para gerar a saída final.\n",
        "Tecnicamente, dado uma entrada $a^{l-1}$ da camada $l-1$ anterior, e os pesos $w$ e bias $b$ para uma camada $l$ atual, o forward tem dois passos básicos:\n",
        "\n",
        "   1. Multiplicação dos pesos e entrada e soma do bias: $z^l = (\\sum_i w^l_i*a^{l-1}_i) + b^l$\n",
        "\n",
        "   2. Atiação via função não linear: $a^l = f(z^l)$\n",
        "\n",
        "onde $z^l$ é uma variável temporária, $a^l$ é a ativação final da camada, e $f(\\cdot)$ é uma função de ativação.\n",
        "\n",
        "**2. Backpropagation**\n",
        "\n",
        "O processo de backpropagation recebe o erro provindo da camada posterior e os usa para calcular a derivada dos pesos e bias da camada atual e calcular o erro da camada anterior.\n",
        "Tecnicamente, suponha que $\\delta^l$ seja o erro dessa cama, que vem sendo calculado (via função de custo) e propagado desde a última camada.\n",
        "Logo, o processo de backpropagation entre as camadas $l$ e $l-1$ pode ser dividido em três passos:\n",
        "\n",
        "   1. Calcula derivada dos pesos $w^l$: $der^l_w = a^{l-1} * \\delta^l$\n",
        "\n",
        "   2. Calcula derivada do bias $b^l$: $der^l_b = mean(\\delta^l)$\n",
        "\n",
        "   3. Calcula erro $\\delta^{l-1}$ para a camada anterior: $\\delta^{l-1} = \\delta^l * w^l * f'(z^{l-1})$\n",
        "\n",
        "onde $der_w$ e $der_b$ são variáveis para armazenar as derivadas do peso e do bias respetivamente, $\\delta^{l-1}$ é o erro para a camada anterior, e $f'(\\cdot)$ é a derivada da função de ativação utilizada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aa7cbb0Asnwq",
        "colab": {}
      },
      "source": [
        "class PerceptronLayer(Layer):\n",
        "    def __init__(self, num_inputs, num_outputs, act_func, der_act_funt):\n",
        "        super(PerceptronLayer, self).__init__()\n",
        "        self.in_depth = num_inputs\n",
        "        self.height = 1\n",
        "        self.width = 1\n",
        "        self.out_depth = num_outputs\n",
        "        self.act_func = act_func\n",
        "        self.der_act_func = der_act_funt\n",
        "\n",
        "        self.w = glorot_uniform((self.in_depth, self.out_depth), self.in_depth, self.out_depth)\n",
        "        self.b = zero(self.out_depth)\n",
        "\n",
        "    def feedforward(self, prev_layer):\n",
        "        \"\"\"\n",
        "        Feedforward\n",
        "\n",
        "        :param prev_layer: a camada anterior\n",
        "        \"\"\"\n",
        "        \n",
        "        # definindo o prev_a -> saida da camada anterior!\n",
        "        if prev_layer.a.ndim > 2:\n",
        "            prev_a = prev_layer.a.reshape((-1, prev_layer.a.shape[1]*prev_layer.a.shape[2]*prev_layer.a.shape[3]))\n",
        "        else:\n",
        "            prev_a = prev_layer.a\n",
        "\n",
        "        # TODO: implemente aqui a processo de forward dessa camada\n",
        "        # Relembrando da ativacao basica de redes neurais, voce deve implementar duas funções:\n",
        "        # 1) uma para multiplar a saida da camada anterior pelo peso dessa camada (e somar o bias): z = sum(prev_a * w) + b\n",
        "        # 2) e outra para ativar a saida: a = act_func(z)\n",
        "\n",
        "        \n",
        "        # criando os atributos \"a\" e \"z\" da classe em questao ? \n",
        "        self.z = (prev_a.dot(self.w)) + self.b\n",
        "\n",
        "        self.a = self.act_func(self.z)\n",
        "        \n",
        "        \n",
        "        # No final, as variáveis a e z devem ter o mesmo tamanho\n",
        "        assert self.z.shape == self.a.shape\n",
        "\n",
        "    def backpropagate(self, prev_layer, delta):\n",
        "        \"\"\"\n",
        "        Backpropagate\n",
        "\n",
        "        :param prev_layer: a camada anterior no fluxo do backpropagatiom\n",
        "        :param delta: o erro a ser propagado para a proxima camada\n",
        "        :returns: a quantidade de alteração dos pesos de entrada dessa camada, a quantidade de alteração dos bias \n",
        "        dessa camada, e o erro propagado por essa camada\n",
        "        \"\"\"\n",
        "        assert delta.shape == self.z.shape == self.a.shape\n",
        "\n",
        "        if prev_layer.a.ndim > 2:\n",
        "            prev_a = prev_layer.a.reshape((-1, prev_layer.a.shape[1]*prev_layer.a.shape[2]*prev_layer.a.shape[3]))\n",
        "        else:\n",
        "            prev_a = prev_layer.a\n",
        "\n",
        "        # TODO: implemente aqui o processo de backpropagation dessa camada\n",
        "        # Relembrando do processo basico de backpropagation, voce deve implementar tres funções:\n",
        "        # 1) uma para calcular o erro em relacao ao peso w: _w = a * delta\n",
        "        der_w = prev_a.T.dot(delta)\n",
        "        \n",
        "\n",
        "\n",
        "        # 2) outra para calcular o erro para o bias: _b = mean(delta)\n",
        "        der_b = np.mean(delta, axis=0)\n",
        "        # 3) e a ultima para calcular o erro a ser propagado por essa camada: _delta = delta * w * der_act(z)\n",
        "        prev_delta = (delta.dot(self.w.T)).reshape(prev_layer.z.shape) * prev_layer.der_act_func(prev_layer.z)\n",
        "\n",
        "        return der_w, der_b, prev_delta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XZfEHV-tsnwv"
      },
      "source": [
        "### Rede Neural\n",
        "\n",
        "Essa seção de código abaixo implementa a classe que encapsula o processamento da rede neural.\n",
        "Especificamente, essa classe realiza todo processamento (tanto forward quanto backpropagation) da rede dado um batch de entrada.\n",
        "Ela ainda implementa funções auxiliares como para salvar e carregar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZhMKY7Osnwy",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, net, loss):\n",
        "\n",
        "        assert isinstance(net[0], InputLayer)\n",
        "        self.input_layer = net[0]\n",
        "\n",
        "        assert isinstance(net[-1], PerceptronLayer)\n",
        "        self.output_layer = net[-1]\n",
        "\n",
        "        self.loss_func = loss\n",
        "        self.net = net\n",
        "\n",
        "    def save_model(self, path):\n",
        "        dict_model = {}\n",
        "        for i in range(1, len(self.net)):\n",
        "            dict_model[i, 'w'] = self.net[i].w\n",
        "            dict_model[i, 'b'] = self.net[i].b\n",
        "        with open(path, 'wb') as ff:\n",
        "            pickle.dump(dict_model, ff, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        with open(path, 'rb') as ff:\n",
        "            dict_model = pickle.load(ff)\n",
        "            for i in range(1, len(self.net)):\n",
        "                self.net[i].w = dict_model[i, 'w']\n",
        "                self.net[i].b = dict_model[i, 'b']\n",
        "\n",
        "    def feedforward(self, x, y):\n",
        "        self.input_layer.z = x\n",
        "        self.input_layer.a = x\n",
        "\n",
        "        for i in range(len(self.net)-1):\n",
        "            self.net[i+1].feedforward(self.net[i])\n",
        "\n",
        "        self.currrent_loss = self.loss_func(self.output_layer.a, y)\n",
        "        return self.currrent_loss\n",
        "\n",
        "    def backpropagate(self, optimizer, y):\n",
        "        sum_der_w = {layer: np.zeros_like(layer.w) for layer in self.net}\n",
        "        sum_der_b = {layer: np.zeros_like(layer.b) for layer in self.net}\n",
        "\n",
        "        # propaga o erro\n",
        "        delta = der_cross_entropy(self.output_layer.z, y)\n",
        "        for i in range(len(self.net)-1, 0, -1):\n",
        "            der_w, der_b, prev_delta = self.net[i].backpropagate(self.net[i - 1], delta)\n",
        "            sum_der_w[self.net[i]] += der_w\n",
        "            sum_der_b[self.net[i]] += der_b\n",
        "            delta = prev_delta\n",
        "\n",
        "        # atualiza os pesos e bias\n",
        "        optimizer.apply(self.net, sum_der_w, sum_der_b, len(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gjhowkoPsnw5"
      },
      "source": [
        "### Main\n",
        "\n",
        "Essa seção de código abaixo implementa:\n",
        "\n",
        "    - a rede neural proposta (no caso do exemplo, somente com duas camadas)\n",
        "    - uma rotina de treino e outro de teste\n",
        "    - a função main que encapsula tudo\n",
        "    \n",
        "Com a arquitetura implementada, usando 100 epochs no dataset todo do MNIST, o resultado obtido foi 89.01% de acurácia na validação em aproximadamente 10 minutos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y5qLoSPTsnw6",
        "outputId": "12702bdd-0cb5-451d-d259-fe2408214fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "import argparse\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "def bar(now, end):\n",
        "    return \"[%-10s]\" % (\"=\" * int(10 * now / end))\n",
        "\n",
        "\n",
        "def mlp():\n",
        "    input_layer = InputLayer(input_height=28, input_width=28, input_channel=1)\n",
        "    fc1 = PerceptronLayer(num_inputs=28 * 28, num_outputs=100, act_func=sigmoid, der_act_funt=der_sigmoid)\n",
        "    fc2 = PerceptronLayer(num_inputs=100, num_outputs=100, act_func=sigmoid, der_act_funt=der_sigmoid)\n",
        "    fc3 = PerceptronLayer(num_inputs=100, num_outputs=10, act_func=softmax, der_act_funt=der_softmax)\n",
        "\n",
        "    return [input_layer, fc1, fc2,fc3]\n",
        "\n",
        "\n",
        "def training(train_data, train_labels, test_data, test_labels, net, dataset, optimizer, batch_size, output_path, num_epochs):\n",
        "    start_time = datetime.datetime.now()\n",
        "    print(\"Inicio Treino::\" + str(start_time.time()))\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        shuffle = np.asarray(random.sample(range(len(train_data)), len(train_data)))\n",
        "\n",
        "        inputs_done = 0\n",
        "        for batch in range(0, int(math.ceil(len(train_data) / float(batch_size)))):\n",
        "            batch_x = train_data[shuffle[batch * batch_size:min(batch * batch_size + batch_size, len(train_data))]]\n",
        "            batch_y = train_labels[shuffle[batch * batch_size:min(batch * batch_size + batch_size, len(train_data))]]\n",
        "\n",
        "            batch_loss = net.feedforward(batch_x, batch_y)\n",
        "            net.backpropagate(optimizer, batch_y)\n",
        "\n",
        "            inputs_done += min(batch * batch_size + batch_size, len(train_data)) - batch * batch_size\n",
        "            print(\"Epoch %02d %s [%d/%d] > Loss: %04f\" %\n",
        "                  (epoch, bar(inputs_done, len(train_data)), inputs_done, len(train_data), batch_loss))\n",
        "\n",
        "        # salva modelo atual\n",
        "        net.save_model(os.path.join(output_path, dataset + '_model_epoch' + str(epoch) + '.pkl'))\n",
        "        # testa a acuracia da rede no final de um epoch\n",
        "        testing(test_data, test_labels, net, batch_size, epoch)\n",
        "    end_time = datetime.datetime.now()\n",
        "    print(\"Final Treino::\" + str(end_time.time()))\n",
        "    print(\"Tempo de treino: %s segundos\" % str((end_time - start_time).total_seconds()))\n",
        "\n",
        "\n",
        "def testing(test_data, test_labels, net, batch_size, epoch):\n",
        "    accuracy = 0.0\n",
        "    for batch in range(0, int(math.ceil(len(test_data) / float(batch_size)))):\n",
        "        batch_x = test_data[batch * batch_size:min(batch * batch_size + batch_size, len(test_data))]\n",
        "        batch_y = test_labels[batch * batch_size:min(batch * batch_size + batch_size, len(test_data))]\n",
        "\n",
        "        net.feedforward(batch_x, batch_y)\n",
        "        accuracy += sum(np.argmax(net.output_layer.a, axis=1) == np.argmax(batch_y, axis=1))\n",
        "    accuracy /= float(len(test_data))\n",
        "    print(\"Epoch %02d %s [%d/%d] Time %s > Acuracia Validacao: %0.2f%%\" %\n",
        "          (epoch, bar(len(test_data), len(test_data)), len(test_data), len(test_data),\n",
        "           str(datetime.datetime.now().time()), accuracy * 100))\n",
        "\n",
        "\n",
        "def feature_extraction(data, labels, net, batch_size, layer):\n",
        "    features = []\n",
        "    for batch in range(0, int(math.ceil(len(data) / float(batch_size)))):\n",
        "        batch_x = data[batch * batch_size:min(batch * batch_size + batch_size, len(data))]\n",
        "        batch_y = labels[batch * batch_size:min(batch * batch_size + batch_size, len(labels))]\n",
        "\n",
        "        net.feedforward(batch_x, batch_y)\n",
        "        features.append(net.net[layer].a)\n",
        "\n",
        "    return np.asarray(features).reshape(data.shape[0], -1)\n",
        "\n",
        "\n",
        "def main():\n",
        "    ##########################################################################\n",
        "    # opcoes gerais\n",
        "    dirpath = os.path.join(os.getcwd(), 'datasets')  # caminho para os datasets\n",
        "    output_path = os.path.join(os.getcwd(), 'output_folder')  # caminho para salvar os modelos\n",
        "    operation = 'training'  # operacao [opcoes: training | finetuning | feature_extraction | testing]\n",
        "\n",
        "    # opcoes de dataset\n",
        "    dataset = 'mnist'  # qual dataset será usado [opcoes: mnist | svhn]\n",
        "    subset = False  # flag que define que usada um sub conjunto do dataset\n",
        "\n",
        "    # opcoes da rede neural\n",
        "    model = None  # caminho para um modelo ja treinado (requerido para se continuar um processo de treino OU para os seguintes processos: testing, finetuning and feature_extraction)\n",
        "    learning_rate = 0.5  # Learning rate/taxa de aprendizado para o SGD\n",
        "    batch_size = 100  # tamanho do batch\n",
        "    num_epochs = 100  # numero de epochs\n",
        "\n",
        "    # validacoes iniciais\n",
        "    if not os.path.isdir(output_path):\n",
        "        os.mkdir(output_path)\n",
        "\n",
        "    if (operation == 'feature_extraction' or operation == 'finetuning' or operation == 'testing') \\\n",
        "            and model is None:\n",
        "        print('Pre-trained model must be provided for operation ', operation)\n",
        "        raise AssertionError\n",
        "\n",
        "    # carrega o dataset especificado\n",
        "    if dataset == 'mnist':\n",
        "        train_data, train_labels, test_data, test_labels = load_mnist(os.path.join(dirpath, 'mnist'))\n",
        "    elif dataset == 'svhn':\n",
        "        train_data, train_labels, test_data, test_labels = load_svhn(os.path.join(dirpath, 'svhn'))\n",
        "    else:\n",
        "        print('Dataset not found ', dataset)\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # essa condicao abaixo faz com que a rede seja treinada somente com\n",
        "    # as 1000 primeiras amostras\n",
        "    # isso acelera o treinamento e pode ser usado durante a implementacao\n",
        "    # de alguma nova funcao ou debug\n",
        "    # NAO DEVE SER USADO qdo se esta treinando para obter bons resultados\n",
        "    if subset is True:\n",
        "        train_data = train_data[:1000, :, :, :]\n",
        "        train_labels = train_labels[:1000, :]\n",
        "    ##########################################################################\n",
        "\n",
        "    net = NeuralNetwork(mlp(), cross_entropy)\n",
        "\n",
        "    if operation == 'training':\n",
        "        if model is not None:\n",
        "            net.load_model(model)\n",
        "        training(train_data, train_labels, test_data, test_labels, net, dataset,\n",
        "                 optimizer=SGD(learning_rate),\n",
        "                 batch_size=batch_size,\n",
        "                 output_path=output_path,\n",
        "                 num_epochs=num_epochs)\n",
        "    elif operation == 'testing':\n",
        "        net.load_model(model)\n",
        "        testing(test_data, test_labels, net,\n",
        "                batch_size=batch_size,\n",
        "                epoch=1000)\n",
        "    elif operation == 'finetuning':\n",
        "        net.load_model(model)\n",
        "        training(train_data, train_labels, test_data, test_labels, net,\n",
        "                 optimizer=SGD(learning_rate),\n",
        "                 batch_size=batch_size,\n",
        "                 output_path=output_path,\n",
        "                 num_epochs=num_epochs)\n",
        "    elif operation == 'feature_extraction':\n",
        "        net.load_model(model)\n",
        "        train_features = feature_extraction(train_data, train_labels, net,\n",
        "                                            batch_size=batch_size,\n",
        "                                            layer=1)\n",
        "        test_features = feature_extraction(test_data, test_labels, net,\n",
        "                                           batch_size=batch_size,\n",
        "                                           layer=1)\n",
        "        # features sao salvas em formatos de numpy array (.npy)\n",
        "        # agora, elas podem ser usadas para treinar/testar um modelo shallow como: svm, random forest, ...\n",
        "        np.save(os.path.join(output_path, dataset, '_train_features.npy'), train_features)\n",
        "        np.save(os.path.join(output_path, dataset, '_test_features.npy'), test_features)\n",
        "    else:\n",
        "        print('Operation not found ', operation)\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File train-images-idx3-ubyte already exists\n",
            "File train-labels-idx1-ubyte already exists\n",
            "File t10k-images-idx3-ubyte already exists\n",
            "File t10k-labels-idx1-ubyte already exists\n",
            "Inicio Treino::17:43:26.279715\n",
            "Epoch 01 [          ] [100/60000] > Loss: 2.546561\n",
            "Epoch 01 [          ] [200/60000] > Loss: 2.322064\n",
            "Epoch 01 [          ] [300/60000] > Loss: 2.505487\n",
            "Epoch 01 [          ] [400/60000] > Loss: 2.490687\n",
            "Epoch 01 [          ] [500/60000] > Loss: 2.508017\n",
            "Epoch 01 [          ] [600/60000] > Loss: 2.443030\n",
            "Epoch 01 [          ] [700/60000] > Loss: 2.498110\n",
            "Epoch 01 [          ] [800/60000] > Loss: 2.466985\n",
            "Epoch 01 [          ] [900/60000] > Loss: 2.442769\n",
            "Epoch 01 [          ] [1000/60000] > Loss: 2.471753\n",
            "Epoch 01 [          ] [1100/60000] > Loss: 2.372837\n",
            "Epoch 01 [          ] [1200/60000] > Loss: 2.403066\n",
            "Epoch 01 [          ] [1300/60000] > Loss: 2.380166\n",
            "Epoch 01 [          ] [1400/60000] > Loss: 2.331744\n",
            "Epoch 01 [          ] [1500/60000] > Loss: 2.445904\n",
            "Epoch 01 [          ] [1600/60000] > Loss: 2.445900\n",
            "Epoch 01 [          ] [1700/60000] > Loss: 2.411293\n",
            "Epoch 01 [          ] [1800/60000] > Loss: 2.456764\n",
            "Epoch 01 [          ] [1900/60000] > Loss: 2.484288\n",
            "Epoch 01 [          ] [2000/60000] > Loss: 2.350405\n",
            "Epoch 01 [          ] [2100/60000] > Loss: 2.373084\n",
            "Epoch 01 [          ] [2200/60000] > Loss: 2.446831\n",
            "Epoch 01 [          ] [2300/60000] > Loss: 2.308193\n",
            "Epoch 01 [          ] [2400/60000] > Loss: 2.364222\n",
            "Epoch 01 [          ] [2500/60000] > Loss: 2.346621\n",
            "Epoch 01 [          ] [2600/60000] > Loss: 2.349391\n",
            "Epoch 01 [          ] [2700/60000] > Loss: 2.404860\n",
            "Epoch 01 [          ] [2800/60000] > Loss: 2.373676\n",
            "Epoch 01 [          ] [2900/60000] > Loss: 2.367031\n",
            "Epoch 01 [          ] [3000/60000] > Loss: 2.429950\n",
            "Epoch 01 [          ] [3100/60000] > Loss: 2.340609\n",
            "Epoch 01 [          ] [3200/60000] > Loss: 2.375369\n",
            "Epoch 01 [          ] [3300/60000] > Loss: 2.343052\n",
            "Epoch 01 [          ] [3400/60000] > Loss: 2.392018\n",
            "Epoch 01 [          ] [3500/60000] > Loss: 2.376942\n",
            "Epoch 01 [          ] [3600/60000] > Loss: 2.308822\n",
            "Epoch 01 [          ] [3700/60000] > Loss: 2.364667\n",
            "Epoch 01 [          ] [3800/60000] > Loss: 2.376947\n",
            "Epoch 01 [          ] [3900/60000] > Loss: 2.398380\n",
            "Epoch 01 [          ] [4000/60000] > Loss: 2.408116\n",
            "Epoch 01 [          ] [4100/60000] > Loss: 2.352978\n",
            "Epoch 01 [          ] [4200/60000] > Loss: 2.386489\n",
            "Epoch 01 [          ] [4300/60000] > Loss: 2.370811\n",
            "Epoch 01 [          ] [4400/60000] > Loss: 2.284780\n",
            "Epoch 01 [          ] [4500/60000] > Loss: 2.369471\n",
            "Epoch 01 [          ] [4600/60000] > Loss: 2.333156\n",
            "Epoch 01 [          ] [4700/60000] > Loss: 2.418342\n",
            "Epoch 01 [          ] [4800/60000] > Loss: 2.338971\n",
            "Epoch 01 [          ] [4900/60000] > Loss: 2.349906\n",
            "Epoch 01 [          ] [5000/60000] > Loss: 2.358205\n",
            "Epoch 01 [          ] [5100/60000] > Loss: 2.340008\n",
            "Epoch 01 [          ] [5200/60000] > Loss: 2.372135\n",
            "Epoch 01 [          ] [5300/60000] > Loss: 2.294694\n",
            "Epoch 01 [          ] [5400/60000] > Loss: 2.305680\n",
            "Epoch 01 [          ] [5500/60000] > Loss: 2.314359\n",
            "Epoch 01 [          ] [5600/60000] > Loss: 2.338406\n",
            "Epoch 01 [          ] [5700/60000] > Loss: 2.317182\n",
            "Epoch 01 [          ] [5800/60000] > Loss: 2.379486\n",
            "Epoch 01 [          ] [5900/60000] > Loss: 2.326946\n",
            "Epoch 01 [=         ] [6000/60000] > Loss: 2.268410\n",
            "Epoch 01 [=         ] [6100/60000] > Loss: 2.349155\n",
            "Epoch 01 [=         ] [6200/60000] > Loss: 2.321071\n",
            "Epoch 01 [=         ] [6300/60000] > Loss: 2.333449\n",
            "Epoch 01 [=         ] [6400/60000] > Loss: 2.348064\n",
            "Epoch 01 [=         ] [6500/60000] > Loss: 2.348253\n",
            "Epoch 01 [=         ] [6600/60000] > Loss: 2.330358\n",
            "Epoch 01 [=         ] [6700/60000] > Loss: 2.358170\n",
            "Epoch 01 [=         ] [6800/60000] > Loss: 2.310022\n",
            "Epoch 01 [=         ] [6900/60000] > Loss: 2.345501\n",
            "Epoch 01 [=         ] [7000/60000] > Loss: 2.325664\n",
            "Epoch 01 [=         ] [7100/60000] > Loss: 2.337494\n",
            "Epoch 01 [=         ] [7200/60000] > Loss: 2.314416\n",
            "Epoch 01 [=         ] [7300/60000] > Loss: 2.345743\n",
            "Epoch 01 [=         ] [7400/60000] > Loss: 2.318520\n",
            "Epoch 01 [=         ] [7500/60000] > Loss: 2.324010\n",
            "Epoch 01 [=         ] [7600/60000] > Loss: 2.343175\n",
            "Epoch 01 [=         ] [7700/60000] > Loss: 2.286848\n",
            "Epoch 01 [=         ] [7800/60000] > Loss: 2.301214\n",
            "Epoch 01 [=         ] [7900/60000] > Loss: 2.319958\n",
            "Epoch 01 [=         ] [8000/60000] > Loss: 2.332678\n",
            "Epoch 01 [=         ] [8100/60000] > Loss: 2.319483\n",
            "Epoch 01 [=         ] [8200/60000] > Loss: 2.328229\n",
            "Epoch 01 [=         ] [8300/60000] > Loss: 2.325733\n",
            "Epoch 01 [=         ] [8400/60000] > Loss: 2.306077\n",
            "Epoch 01 [=         ] [8500/60000] > Loss: 2.351166\n",
            "Epoch 01 [=         ] [8600/60000] > Loss: 2.302326\n",
            "Epoch 01 [=         ] [8700/60000] > Loss: 2.292051\n",
            "Epoch 01 [=         ] [8800/60000] > Loss: 2.284096\n",
            "Epoch 01 [=         ] [8900/60000] > Loss: 2.298276\n",
            "Epoch 01 [=         ] [9000/60000] > Loss: 2.336319\n",
            "Epoch 01 [=         ] [9100/60000] > Loss: 2.324598\n",
            "Epoch 01 [=         ] [9200/60000] > Loss: 2.291934\n",
            "Epoch 01 [=         ] [9300/60000] > Loss: 2.298638\n",
            "Epoch 01 [=         ] [9400/60000] > Loss: 2.292524\n",
            "Epoch 01 [=         ] [9500/60000] > Loss: 2.315873\n",
            "Epoch 01 [=         ] [9600/60000] > Loss: 2.302632\n",
            "Epoch 01 [=         ] [9700/60000] > Loss: 2.306515\n",
            "Epoch 01 [=         ] [9800/60000] > Loss: 2.317980\n",
            "Epoch 01 [=         ] [9900/60000] > Loss: 2.312149\n",
            "Epoch 01 [=         ] [10000/60000] > Loss: 2.315862\n",
            "Epoch 01 [=         ] [10100/60000] > Loss: 2.316611\n",
            "Epoch 01 [=         ] [10200/60000] > Loss: 2.302352\n",
            "Epoch 01 [=         ] [10300/60000] > Loss: 2.338586\n",
            "Epoch 01 [=         ] [10400/60000] > Loss: 2.289173\n",
            "Epoch 01 [=         ] [10500/60000] > Loss: 2.342388\n",
            "Epoch 01 [=         ] [10600/60000] > Loss: 2.316700\n",
            "Epoch 01 [=         ] [10700/60000] > Loss: 2.307379\n",
            "Epoch 01 [=         ] [10800/60000] > Loss: 2.333716\n",
            "Epoch 01 [=         ] [10900/60000] > Loss: 2.297775\n",
            "Epoch 01 [=         ] [11000/60000] > Loss: 2.301011\n",
            "Epoch 01 [=         ] [11100/60000] > Loss: 2.302383\n",
            "Epoch 01 [=         ] [11200/60000] > Loss: 2.299902\n",
            "Epoch 01 [=         ] [11300/60000] > Loss: 2.282669\n",
            "Epoch 01 [=         ] [11400/60000] > Loss: 2.305510\n",
            "Epoch 01 [=         ] [11500/60000] > Loss: 2.300866\n",
            "Epoch 01 [=         ] [11600/60000] > Loss: 2.323118\n",
            "Epoch 01 [=         ] [11700/60000] > Loss: 2.315592\n",
            "Epoch 01 [=         ] [11800/60000] > Loss: 2.299912\n",
            "Epoch 01 [=         ] [11900/60000] > Loss: 2.292119\n",
            "Epoch 01 [==        ] [12000/60000] > Loss: 2.315268\n",
            "Epoch 01 [==        ] [12100/60000] > Loss: 2.328400\n",
            "Epoch 01 [==        ] [12200/60000] > Loss: 2.302557\n",
            "Epoch 01 [==        ] [12300/60000] > Loss: 2.320896\n",
            "Epoch 01 [==        ] [12400/60000] > Loss: 2.299577\n",
            "Epoch 01 [==        ] [12500/60000] > Loss: 2.293695\n",
            "Epoch 01 [==        ] [12600/60000] > Loss: 2.297538\n",
            "Epoch 01 [==        ] [12700/60000] > Loss: 2.310942\n",
            "Epoch 01 [==        ] [12800/60000] > Loss: 2.304803\n",
            "Epoch 01 [==        ] [12900/60000] > Loss: 2.316218\n",
            "Epoch 01 [==        ] [13000/60000] > Loss: 2.306523\n",
            "Epoch 01 [==        ] [13100/60000] > Loss: 2.303795\n",
            "Epoch 01 [==        ] [13200/60000] > Loss: 2.301725\n",
            "Epoch 01 [==        ] [13300/60000] > Loss: 2.300927\n",
            "Epoch 01 [==        ] [13400/60000] > Loss: 2.302582\n",
            "Epoch 01 [==        ] [13500/60000] > Loss: 2.302927\n",
            "Epoch 01 [==        ] [13600/60000] > Loss: 2.302752\n",
            "Epoch 01 [==        ] [13700/60000] > Loss: 2.298243\n",
            "Epoch 01 [==        ] [13800/60000] > Loss: 2.310033\n",
            "Epoch 01 [==        ] [13900/60000] > Loss: 2.296253\n",
            "Epoch 01 [==        ] [14000/60000] > Loss: 2.289473\n",
            "Epoch 01 [==        ] [14100/60000] > Loss: 2.291844\n",
            "Epoch 01 [==        ] [14200/60000] > Loss: 2.297626\n",
            "Epoch 01 [==        ] [14300/60000] > Loss: 2.293909\n",
            "Epoch 01 [==        ] [14400/60000] > Loss: 2.300458\n",
            "Epoch 01 [==        ] [14500/60000] > Loss: 2.300722\n",
            "Epoch 01 [==        ] [14600/60000] > Loss: 2.294175\n",
            "Epoch 01 [==        ] [14700/60000] > Loss: 2.302949\n",
            "Epoch 01 [==        ] [14800/60000] > Loss: 2.299043\n",
            "Epoch 01 [==        ] [14900/60000] > Loss: 2.301471\n",
            "Epoch 01 [==        ] [15000/60000] > Loss: 2.301615\n",
            "Epoch 01 [==        ] [15100/60000] > Loss: 2.299200\n",
            "Epoch 01 [==        ] [15200/60000] > Loss: 2.293109\n",
            "Epoch 01 [==        ] [15300/60000] > Loss: 2.307409\n",
            "Epoch 01 [==        ] [15400/60000] > Loss: 2.307678\n",
            "Epoch 01 [==        ] [15500/60000] > Loss: 2.296648\n",
            "Epoch 01 [==        ] [15600/60000] > Loss: 2.294513\n",
            "Epoch 01 [==        ] [15700/60000] > Loss: 2.282189\n",
            "Epoch 01 [==        ] [15800/60000] > Loss: 2.294974\n",
            "Epoch 01 [==        ] [15900/60000] > Loss: 2.293543\n",
            "Epoch 01 [==        ] [16000/60000] > Loss: 2.295633\n",
            "Epoch 01 [==        ] [16100/60000] > Loss: 2.291682\n",
            "Epoch 01 [==        ] [16200/60000] > Loss: 2.294540\n",
            "Epoch 01 [==        ] [16300/60000] > Loss: 2.300572\n",
            "Epoch 01 [==        ] [16400/60000] > Loss: 2.300053\n",
            "Epoch 01 [==        ] [16500/60000] > Loss: 2.297372\n",
            "Epoch 01 [==        ] [16600/60000] > Loss: 2.297671\n",
            "Epoch 01 [==        ] [16700/60000] > Loss: 2.290917\n",
            "Epoch 01 [==        ] [16800/60000] > Loss: 2.284840\n",
            "Epoch 01 [==        ] [16900/60000] > Loss: 2.280443\n",
            "Epoch 01 [==        ] [17000/60000] > Loss: 2.297640\n",
            "Epoch 01 [==        ] [17100/60000] > Loss: 2.297553\n",
            "Epoch 01 [==        ] [17200/60000] > Loss: 2.286782\n",
            "Epoch 01 [==        ] [17300/60000] > Loss: 2.287863\n",
            "Epoch 01 [==        ] [17400/60000] > Loss: 2.293851\n",
            "Epoch 01 [==        ] [17500/60000] > Loss: 2.290788\n",
            "Epoch 01 [==        ] [17600/60000] > Loss: 2.300834\n",
            "Epoch 01 [==        ] [17700/60000] > Loss: 2.299534\n",
            "Epoch 01 [==        ] [17800/60000] > Loss: 2.295787\n",
            "Epoch 01 [==        ] [17900/60000] > Loss: 2.289966\n",
            "Epoch 01 [===       ] [18000/60000] > Loss: 2.286931\n",
            "Epoch 01 [===       ] [18100/60000] > Loss: 2.283632\n",
            "Epoch 01 [===       ] [18200/60000] > Loss: 2.298845\n",
            "Epoch 01 [===       ] [18300/60000] > Loss: 2.286482\n",
            "Epoch 01 [===       ] [18400/60000] > Loss: 2.282525\n",
            "Epoch 01 [===       ] [18500/60000] > Loss: 2.286904\n",
            "Epoch 01 [===       ] [18600/60000] > Loss: 2.283074\n",
            "Epoch 01 [===       ] [18700/60000] > Loss: 2.292688\n",
            "Epoch 01 [===       ] [18800/60000] > Loss: 2.288149\n",
            "Epoch 01 [===       ] [18900/60000] > Loss: 2.287520\n",
            "Epoch 01 [===       ] [19000/60000] > Loss: 2.286315\n",
            "Epoch 01 [===       ] [19100/60000] > Loss: 2.299218\n",
            "Epoch 01 [===       ] [19200/60000] > Loss: 2.275702\n",
            "Epoch 01 [===       ] [19300/60000] > Loss: 2.288527\n",
            "Epoch 01 [===       ] [19400/60000] > Loss: 2.302799\n",
            "Epoch 01 [===       ] [19500/60000] > Loss: 2.298949\n",
            "Epoch 01 [===       ] [19600/60000] > Loss: 2.294109\n",
            "Epoch 01 [===       ] [19700/60000] > Loss: 2.299662\n",
            "Epoch 01 [===       ] [19800/60000] > Loss: 2.298907\n",
            "Epoch 01 [===       ] [19900/60000] > Loss: 2.291489\n",
            "Epoch 01 [===       ] [20000/60000] > Loss: 2.293228\n",
            "Epoch 01 [===       ] [20100/60000] > Loss: 2.273098\n",
            "Epoch 01 [===       ] [20200/60000] > Loss: 2.298501\n",
            "Epoch 01 [===       ] [20300/60000] > Loss: 2.280096\n",
            "Epoch 01 [===       ] [20400/60000] > Loss: 2.297743\n",
            "Epoch 01 [===       ] [20500/60000] > Loss: 2.288132\n",
            "Epoch 01 [===       ] [20600/60000] > Loss: 2.288309\n",
            "Epoch 01 [===       ] [20700/60000] > Loss: 2.287934\n",
            "Epoch 01 [===       ] [20800/60000] > Loss: 2.301816\n",
            "Epoch 01 [===       ] [20900/60000] > Loss: 2.287663\n",
            "Epoch 01 [===       ] [21000/60000] > Loss: 2.285199\n",
            "Epoch 01 [===       ] [21100/60000] > Loss: 2.310303\n",
            "Epoch 01 [===       ] [21200/60000] > Loss: 2.281449\n",
            "Epoch 01 [===       ] [21300/60000] > Loss: 2.282158\n",
            "Epoch 01 [===       ] [21400/60000] > Loss: 2.278378\n",
            "Epoch 01 [===       ] [21500/60000] > Loss: 2.300277\n",
            "Epoch 01 [===       ] [21600/60000] > Loss: 2.298146\n",
            "Epoch 01 [===       ] [21700/60000] > Loss: 2.293992\n",
            "Epoch 01 [===       ] [21800/60000] > Loss: 2.300810\n",
            "Epoch 01 [===       ] [21900/60000] > Loss: 2.298774\n",
            "Epoch 01 [===       ] [22000/60000] > Loss: 2.293117\n",
            "Epoch 01 [===       ] [22100/60000] > Loss: 2.295037\n",
            "Epoch 01 [===       ] [22200/60000] > Loss: 2.293500\n",
            "Epoch 01 [===       ] [22300/60000] > Loss: 2.294566\n",
            "Epoch 01 [===       ] [22400/60000] > Loss: 2.288997\n",
            "Epoch 01 [===       ] [22500/60000] > Loss: 2.301464\n",
            "Epoch 01 [===       ] [22600/60000] > Loss: 2.293262\n",
            "Epoch 01 [===       ] [22700/60000] > Loss: 2.283148\n",
            "Epoch 01 [===       ] [22800/60000] > Loss: 2.297197\n",
            "Epoch 01 [===       ] [22900/60000] > Loss: 2.300996\n",
            "Epoch 01 [===       ] [23000/60000] > Loss: 2.289006\n",
            "Epoch 01 [===       ] [23100/60000] > Loss: 2.275324\n",
            "Epoch 01 [===       ] [23200/60000] > Loss: 2.303292\n",
            "Epoch 01 [===       ] [23300/60000] > Loss: 2.287122\n",
            "Epoch 01 [===       ] [23400/60000] > Loss: 2.289914\n",
            "Epoch 01 [===       ] [23500/60000] > Loss: 2.299681\n",
            "Epoch 01 [===       ] [23600/60000] > Loss: 2.287296\n",
            "Epoch 01 [===       ] [23700/60000] > Loss: 2.294156\n",
            "Epoch 01 [===       ] [23800/60000] > Loss: 2.298916\n",
            "Epoch 01 [===       ] [23900/60000] > Loss: 2.283723\n",
            "Epoch 01 [====      ] [24000/60000] > Loss: 2.291715\n",
            "Epoch 01 [====      ] [24100/60000] > Loss: 2.293640\n",
            "Epoch 01 [====      ] [24200/60000] > Loss: 2.294075\n",
            "Epoch 01 [====      ] [24300/60000] > Loss: 2.292311\n",
            "Epoch 01 [====      ] [24400/60000] > Loss: 2.278689\n",
            "Epoch 01 [====      ] [24500/60000] > Loss: 2.297043\n",
            "Epoch 01 [====      ] [24600/60000] > Loss: 2.294349\n",
            "Epoch 01 [====      ] [24700/60000] > Loss: 2.281987\n",
            "Epoch 01 [====      ] [24800/60000] > Loss: 2.287820\n",
            "Epoch 01 [====      ] [24900/60000] > Loss: 2.293243\n",
            "Epoch 01 [====      ] [25000/60000] > Loss: 2.280632\n",
            "Epoch 01 [====      ] [25100/60000] > Loss: 2.288186\n",
            "Epoch 01 [====      ] [25200/60000] > Loss: 2.291366\n",
            "Epoch 01 [====      ] [25300/60000] > Loss: 2.291961\n",
            "Epoch 01 [====      ] [25400/60000] > Loss: 2.288848\n",
            "Epoch 01 [====      ] [25500/60000] > Loss: 2.283251\n",
            "Epoch 01 [====      ] [25600/60000] > Loss: 2.290579\n",
            "Epoch 01 [====      ] [25700/60000] > Loss: 2.297751\n",
            "Epoch 01 [====      ] [25800/60000] > Loss: 2.289786\n",
            "Epoch 01 [====      ] [25900/60000] > Loss: 2.292839\n",
            "Epoch 01 [====      ] [26000/60000] > Loss: 2.276918\n",
            "Epoch 01 [====      ] [26100/60000] > Loss: 2.290607\n",
            "Epoch 01 [====      ] [26200/60000] > Loss: 2.285224\n",
            "Epoch 01 [====      ] [26300/60000] > Loss: 2.293684\n",
            "Epoch 01 [====      ] [26400/60000] > Loss: 2.287293\n",
            "Epoch 01 [====      ] [26500/60000] > Loss: 2.293419\n",
            "Epoch 01 [====      ] [26600/60000] > Loss: 2.291757\n",
            "Epoch 01 [====      ] [26700/60000] > Loss: 2.291563\n",
            "Epoch 01 [====      ] [26800/60000] > Loss: 2.298468\n",
            "Epoch 01 [====      ] [26900/60000] > Loss: 2.297142\n",
            "Epoch 01 [====      ] [27000/60000] > Loss: 2.275686\n",
            "Epoch 01 [====      ] [27100/60000] > Loss: 2.290197\n",
            "Epoch 01 [====      ] [27200/60000] > Loss: 2.279847\n",
            "Epoch 01 [====      ] [27300/60000] > Loss: 2.294756\n",
            "Epoch 01 [====      ] [27400/60000] > Loss: 2.296487\n",
            "Epoch 01 [====      ] [27500/60000] > Loss: 2.292349\n",
            "Epoch 01 [====      ] [27600/60000] > Loss: 2.282966\n",
            "Epoch 01 [====      ] [27700/60000] > Loss: 2.300550\n",
            "Epoch 01 [====      ] [27800/60000] > Loss: 2.288995\n",
            "Epoch 01 [====      ] [27900/60000] > Loss: 2.292941\n",
            "Epoch 01 [====      ] [28000/60000] > Loss: 2.288134\n",
            "Epoch 01 [====      ] [28100/60000] > Loss: 2.290740\n",
            "Epoch 01 [====      ] [28200/60000] > Loss: 2.285849\n",
            "Epoch 01 [====      ] [28300/60000] > Loss: 2.290491\n",
            "Epoch 01 [====      ] [28400/60000] > Loss: 2.294852\n",
            "Epoch 01 [====      ] [28500/60000] > Loss: 2.290513\n",
            "Epoch 01 [====      ] [28600/60000] > Loss: 2.295783\n",
            "Epoch 01 [====      ] [28700/60000] > Loss: 2.290789\n",
            "Epoch 01 [====      ] [28800/60000] > Loss: 2.294224\n",
            "Epoch 01 [====      ] [28900/60000] > Loss: 2.292935\n",
            "Epoch 01 [====      ] [29000/60000] > Loss: 2.283317\n",
            "Epoch 01 [====      ] [29100/60000] > Loss: 2.291556\n",
            "Epoch 01 [====      ] [29200/60000] > Loss: 2.290766\n",
            "Epoch 01 [====      ] [29300/60000] > Loss: 2.295256\n",
            "Epoch 01 [====      ] [29400/60000] > Loss: 2.281335\n",
            "Epoch 01 [====      ] [29500/60000] > Loss: 2.279104\n",
            "Epoch 01 [====      ] [29600/60000] > Loss: 2.292421\n",
            "Epoch 01 [====      ] [29700/60000] > Loss: 2.296941\n",
            "Epoch 01 [====      ] [29800/60000] > Loss: 2.296122\n",
            "Epoch 01 [====      ] [29900/60000] > Loss: 2.280615\n",
            "Epoch 01 [=====     ] [30000/60000] > Loss: 2.283051\n",
            "Epoch 01 [=====     ] [30100/60000] > Loss: 2.292525\n",
            "Epoch 01 [=====     ] [30200/60000] > Loss: 2.284067\n",
            "Epoch 01 [=====     ] [30300/60000] > Loss: 2.291254\n",
            "Epoch 01 [=====     ] [30400/60000] > Loss: 2.284587\n",
            "Epoch 01 [=====     ] [30500/60000] > Loss: 2.285886\n",
            "Epoch 01 [=====     ] [30600/60000] > Loss: 2.289870\n",
            "Epoch 01 [=====     ] [30700/60000] > Loss: 2.286995\n",
            "Epoch 01 [=====     ] [30800/60000] > Loss: 2.291491\n",
            "Epoch 01 [=====     ] [30900/60000] > Loss: 2.290259\n",
            "Epoch 01 [=====     ] [31000/60000] > Loss: 2.295492\n",
            "Epoch 01 [=====     ] [31100/60000] > Loss: 2.293851\n",
            "Epoch 01 [=====     ] [31200/60000] > Loss: 2.286123\n",
            "Epoch 01 [=====     ] [31300/60000] > Loss: 2.288476\n",
            "Epoch 01 [=====     ] [31400/60000] > Loss: 2.295594\n",
            "Epoch 01 [=====     ] [31500/60000] > Loss: 2.295812\n",
            "Epoch 01 [=====     ] [31600/60000] > Loss: 2.288715\n",
            "Epoch 01 [=====     ] [31700/60000] > Loss: 2.291127\n",
            "Epoch 01 [=====     ] [31800/60000] > Loss: 2.280108\n",
            "Epoch 01 [=====     ] [31900/60000] > Loss: 2.277135\n",
            "Epoch 01 [=====     ] [32000/60000] > Loss: 2.286541\n",
            "Epoch 01 [=====     ] [32100/60000] > Loss: 2.282811\n",
            "Epoch 01 [=====     ] [32200/60000] > Loss: 2.279628\n",
            "Epoch 01 [=====     ] [32300/60000] > Loss: 2.282771\n",
            "Epoch 01 [=====     ] [32400/60000] > Loss: 2.283295\n",
            "Epoch 01 [=====     ] [32500/60000] > Loss: 2.289996\n",
            "Epoch 01 [=====     ] [32600/60000] > Loss: 2.289064\n",
            "Epoch 01 [=====     ] [32700/60000] > Loss: 2.283311\n",
            "Epoch 01 [=====     ] [32800/60000] > Loss: 2.283495\n",
            "Epoch 01 [=====     ] [32900/60000] > Loss: 2.284639\n",
            "Epoch 01 [=====     ] [33000/60000] > Loss: 2.288049\n",
            "Epoch 01 [=====     ] [33100/60000] > Loss: 2.291256\n",
            "Epoch 01 [=====     ] [33200/60000] > Loss: 2.284585\n",
            "Epoch 01 [=====     ] [33300/60000] > Loss: 2.281239\n",
            "Epoch 01 [=====     ] [33400/60000] > Loss: 2.283826\n",
            "Epoch 01 [=====     ] [33500/60000] > Loss: 2.283224\n",
            "Epoch 01 [=====     ] [33600/60000] > Loss: 2.282463\n",
            "Epoch 01 [=====     ] [33700/60000] > Loss: 2.288199\n",
            "Epoch 01 [=====     ] [33800/60000] > Loss: 2.285700\n",
            "Epoch 01 [=====     ] [33900/60000] > Loss: 2.288646\n",
            "Epoch 01 [=====     ] [34000/60000] > Loss: 2.287449\n",
            "Epoch 01 [=====     ] [34100/60000] > Loss: 2.286660\n",
            "Epoch 01 [=====     ] [34200/60000] > Loss: 2.279645\n",
            "Epoch 01 [=====     ] [34300/60000] > Loss: 2.288760\n",
            "Epoch 01 [=====     ] [34400/60000] > Loss: 2.295171\n",
            "Epoch 01 [=====     ] [34500/60000] > Loss: 2.291218\n",
            "Epoch 01 [=====     ] [34600/60000] > Loss: 2.282360\n",
            "Epoch 01 [=====     ] [34700/60000] > Loss: 2.277029\n",
            "Epoch 01 [=====     ] [34800/60000] > Loss: 2.291225\n",
            "Epoch 01 [=====     ] [34900/60000] > Loss: 2.297526\n",
            "Epoch 01 [=====     ] [35000/60000] > Loss: 2.279905\n",
            "Epoch 01 [=====     ] [35100/60000] > Loss: 2.293426\n",
            "Epoch 01 [=====     ] [35200/60000] > Loss: 2.285253\n",
            "Epoch 01 [=====     ] [35300/60000] > Loss: 2.287235\n",
            "Epoch 01 [=====     ] [35400/60000] > Loss: 2.289549\n",
            "Epoch 01 [=====     ] [35500/60000] > Loss: 2.276807\n",
            "Epoch 01 [=====     ] [35600/60000] > Loss: 2.289131\n",
            "Epoch 01 [=====     ] [35700/60000] > Loss: 2.278675\n",
            "Epoch 01 [=====     ] [35800/60000] > Loss: 2.284930\n",
            "Epoch 01 [=====     ] [35900/60000] > Loss: 2.290048\n",
            "Epoch 01 [======    ] [36000/60000] > Loss: 2.285415\n",
            "Epoch 01 [======    ] [36100/60000] > Loss: 2.279767\n",
            "Epoch 01 [======    ] [36200/60000] > Loss: 2.295798\n",
            "Epoch 01 [======    ] [36300/60000] > Loss: 2.286550\n",
            "Epoch 01 [======    ] [36400/60000] > Loss: 2.291144\n",
            "Epoch 01 [======    ] [36500/60000] > Loss: 2.301781\n",
            "Epoch 01 [======    ] [36600/60000] > Loss: 2.280192\n",
            "Epoch 01 [======    ] [36700/60000] > Loss: 2.281648\n",
            "Epoch 01 [======    ] [36800/60000] > Loss: 2.286250\n",
            "Epoch 01 [======    ] [36900/60000] > Loss: 2.279556\n",
            "Epoch 01 [======    ] [37000/60000] > Loss: 2.286229\n",
            "Epoch 01 [======    ] [37100/60000] > Loss: 2.288828\n",
            "Epoch 01 [======    ] [37200/60000] > Loss: 2.288571\n",
            "Epoch 01 [======    ] [37300/60000] > Loss: 2.294310\n",
            "Epoch 01 [======    ] [37400/60000] > Loss: 2.285517\n",
            "Epoch 01 [======    ] [37500/60000] > Loss: 2.275176\n",
            "Epoch 01 [======    ] [37600/60000] > Loss: 2.290426\n",
            "Epoch 01 [======    ] [37700/60000] > Loss: 2.271130\n",
            "Epoch 01 [======    ] [37800/60000] > Loss: 2.285294\n",
            "Epoch 01 [======    ] [37900/60000] > Loss: 2.295006\n",
            "Epoch 01 [======    ] [38000/60000] > Loss: 2.277912\n",
            "Epoch 01 [======    ] [38100/60000] > Loss: 2.276662\n",
            "Epoch 01 [======    ] [38200/60000] > Loss: 2.288959\n",
            "Epoch 01 [======    ] [38300/60000] > Loss: 2.286697\n",
            "Epoch 01 [======    ] [38400/60000] > Loss: 2.286840\n",
            "Epoch 01 [======    ] [38500/60000] > Loss: 2.285977\n",
            "Epoch 01 [======    ] [38600/60000] > Loss: 2.281793\n",
            "Epoch 01 [======    ] [38700/60000] > Loss: 2.296315\n",
            "Epoch 01 [======    ] [38800/60000] > Loss: 2.282144\n",
            "Epoch 01 [======    ] [38900/60000] > Loss: 2.284613\n",
            "Epoch 01 [======    ] [39000/60000] > Loss: 2.291837\n",
            "Epoch 01 [======    ] [39100/60000] > Loss: 2.283757\n",
            "Epoch 01 [======    ] [39200/60000] > Loss: 2.286865\n",
            "Epoch 01 [======    ] [39300/60000] > Loss: 2.278567\n",
            "Epoch 01 [======    ] [39400/60000] > Loss: 2.278759\n",
            "Epoch 01 [======    ] [39500/60000] > Loss: 2.286693\n",
            "Epoch 01 [======    ] [39600/60000] > Loss: 2.285696\n",
            "Epoch 01 [======    ] [39700/60000] > Loss: 2.280139\n",
            "Epoch 01 [======    ] [39800/60000] > Loss: 2.276433\n",
            "Epoch 01 [======    ] [39900/60000] > Loss: 2.276371\n",
            "Epoch 01 [======    ] [40000/60000] > Loss: 2.272272\n",
            "Epoch 01 [======    ] [40100/60000] > Loss: 2.289913\n",
            "Epoch 01 [======    ] [40200/60000] > Loss: 2.287327\n",
            "Epoch 01 [======    ] [40300/60000] > Loss: 2.273360\n",
            "Epoch 01 [======    ] [40400/60000] > Loss: 2.284207\n",
            "Epoch 01 [======    ] [40500/60000] > Loss: 2.272982\n",
            "Epoch 01 [======    ] [40600/60000] > Loss: 2.290898\n",
            "Epoch 01 [======    ] [40700/60000] > Loss: 2.283111\n",
            "Epoch 01 [======    ] [40800/60000] > Loss: 2.286330\n",
            "Epoch 01 [======    ] [40900/60000] > Loss: 2.296022\n",
            "Epoch 01 [======    ] [41000/60000] > Loss: 2.284314\n",
            "Epoch 01 [======    ] [41100/60000] > Loss: 2.278404\n",
            "Epoch 01 [======    ] [41200/60000] > Loss: 2.275282\n",
            "Epoch 01 [======    ] [41300/60000] > Loss: 2.280828\n",
            "Epoch 01 [======    ] [41400/60000] > Loss: 2.290397\n",
            "Epoch 01 [======    ] [41500/60000] > Loss: 2.278207\n",
            "Epoch 01 [======    ] [41600/60000] > Loss: 2.276564\n",
            "Epoch 01 [======    ] [41700/60000] > Loss: 2.284737\n",
            "Epoch 01 [======    ] [41800/60000] > Loss: 2.278731\n",
            "Epoch 01 [======    ] [41900/60000] > Loss: 2.270873\n",
            "Epoch 01 [=======   ] [42000/60000] > Loss: 2.274150\n",
            "Epoch 01 [=======   ] [42100/60000] > Loss: 2.282995\n",
            "Epoch 01 [=======   ] [42200/60000] > Loss: 2.291554\n",
            "Epoch 01 [=======   ] [42300/60000] > Loss: 2.278969\n",
            "Epoch 01 [=======   ] [42400/60000] > Loss: 2.279553\n",
            "Epoch 01 [=======   ] [42500/60000] > Loss: 2.280660\n",
            "Epoch 01 [=======   ] [42600/60000] > Loss: 2.277858\n",
            "Epoch 01 [=======   ] [42700/60000] > Loss: 2.272036\n",
            "Epoch 01 [=======   ] [42800/60000] > Loss: 2.296315\n",
            "Epoch 01 [=======   ] [42900/60000] > Loss: 2.277235\n",
            "Epoch 01 [=======   ] [43000/60000] > Loss: 2.281625\n",
            "Epoch 01 [=======   ] [43100/60000] > Loss: 2.282459\n",
            "Epoch 01 [=======   ] [43200/60000] > Loss: 2.271479\n",
            "Epoch 01 [=======   ] [43300/60000] > Loss: 2.294373\n",
            "Epoch 01 [=======   ] [43400/60000] > Loss: 2.274199\n",
            "Epoch 01 [=======   ] [43500/60000] > Loss: 2.290877\n",
            "Epoch 01 [=======   ] [43600/60000] > Loss: 2.281510\n",
            "Epoch 01 [=======   ] [43700/60000] > Loss: 2.287272\n",
            "Epoch 01 [=======   ] [43800/60000] > Loss: 2.272515\n",
            "Epoch 01 [=======   ] [43900/60000] > Loss: 2.281802\n",
            "Epoch 01 [=======   ] [44000/60000] > Loss: 2.301258\n",
            "Epoch 01 [=======   ] [44100/60000] > Loss: 2.293451\n",
            "Epoch 01 [=======   ] [44200/60000] > Loss: 2.288271\n",
            "Epoch 01 [=======   ] [44300/60000] > Loss: 2.291625\n",
            "Epoch 01 [=======   ] [44400/60000] > Loss: 2.280235\n",
            "Epoch 01 [=======   ] [44500/60000] > Loss: 2.278111\n",
            "Epoch 01 [=======   ] [44600/60000] > Loss: 2.283543\n",
            "Epoch 01 [=======   ] [44700/60000] > Loss: 2.295259\n",
            "Epoch 01 [=======   ] [44800/60000] > Loss: 2.281738\n",
            "Epoch 01 [=======   ] [44900/60000] > Loss: 2.267433\n",
            "Epoch 01 [=======   ] [45000/60000] > Loss: 2.272851\n",
            "Epoch 01 [=======   ] [45100/60000] > Loss: 2.286164\n",
            "Epoch 01 [=======   ] [45200/60000] > Loss: 2.287930\n",
            "Epoch 01 [=======   ] [45300/60000] > Loss: 2.281405\n",
            "Epoch 01 [=======   ] [45400/60000] > Loss: 2.272643\n",
            "Epoch 01 [=======   ] [45500/60000] > Loss: 2.278770\n",
            "Epoch 01 [=======   ] [45600/60000] > Loss: 2.272509\n",
            "Epoch 01 [=======   ] [45700/60000] > Loss: 2.272404\n",
            "Epoch 01 [=======   ] [45800/60000] > Loss: 2.274183\n",
            "Epoch 01 [=======   ] [45900/60000] > Loss: 2.275391\n",
            "Epoch 01 [=======   ] [46000/60000] > Loss: 2.289533\n",
            "Epoch 01 [=======   ] [46100/60000] > Loss: 2.278464\n",
            "Epoch 01 [=======   ] [46200/60000] > Loss: 2.301100\n",
            "Epoch 01 [=======   ] [46300/60000] > Loss: 2.273356\n",
            "Epoch 01 [=======   ] [46400/60000] > Loss: 2.279764\n",
            "Epoch 01 [=======   ] [46500/60000] > Loss: 2.268058\n",
            "Epoch 01 [=======   ] [46600/60000] > Loss: 2.273949\n",
            "Epoch 01 [=======   ] [46700/60000] > Loss: 2.273984\n",
            "Epoch 01 [=======   ] [46800/60000] > Loss: 2.286591\n",
            "Epoch 01 [=======   ] [46900/60000] > Loss: 2.276700\n",
            "Epoch 01 [=======   ] [47000/60000] > Loss: 2.304580\n",
            "Epoch 01 [=======   ] [47100/60000] > Loss: 2.298199\n",
            "Epoch 01 [=======   ] [47200/60000] > Loss: 2.288603\n",
            "Epoch 01 [=======   ] [47300/60000] > Loss: 2.277638\n",
            "Epoch 01 [=======   ] [47400/60000] > Loss: 2.275924\n",
            "Epoch 01 [=======   ] [47500/60000] > Loss: 2.279898\n",
            "Epoch 01 [=======   ] [47600/60000] > Loss: 2.268200\n",
            "Epoch 01 [=======   ] [47700/60000] > Loss: 2.268613\n",
            "Epoch 01 [=======   ] [47800/60000] > Loss: 2.287142\n",
            "Epoch 01 [=======   ] [47900/60000] > Loss: 2.274004\n",
            "Epoch 01 [========  ] [48000/60000] > Loss: 2.288839\n",
            "Epoch 01 [========  ] [48100/60000] > Loss: 2.284083\n",
            "Epoch 01 [========  ] [48200/60000] > Loss: 2.276804\n",
            "Epoch 01 [========  ] [48300/60000] > Loss: 2.276104\n",
            "Epoch 01 [========  ] [48400/60000] > Loss: 2.267675\n",
            "Epoch 01 [========  ] [48500/60000] > Loss: 2.291962\n",
            "Epoch 01 [========  ] [48600/60000] > Loss: 2.271747\n",
            "Epoch 01 [========  ] [48700/60000] > Loss: 2.277581\n",
            "Epoch 01 [========  ] [48800/60000] > Loss: 2.281695\n",
            "Epoch 01 [========  ] [48900/60000] > Loss: 2.278392\n",
            "Epoch 01 [========  ] [49000/60000] > Loss: 2.295025\n",
            "Epoch 01 [========  ] [49100/60000] > Loss: 2.263784\n",
            "Epoch 01 [========  ] [49200/60000] > Loss: 2.284825\n",
            "Epoch 01 [========  ] [49300/60000] > Loss: 2.280678\n",
            "Epoch 01 [========  ] [49400/60000] > Loss: 2.270414\n",
            "Epoch 01 [========  ] [49500/60000] > Loss: 2.278518\n",
            "Epoch 01 [========  ] [49600/60000] > Loss: 2.281681\n",
            "Epoch 01 [========  ] [49700/60000] > Loss: 2.268858\n",
            "Epoch 01 [========  ] [49800/60000] > Loss: 2.285679\n",
            "Epoch 01 [========  ] [49900/60000] > Loss: 2.285721\n",
            "Epoch 01 [========  ] [50000/60000] > Loss: 2.279853\n",
            "Epoch 01 [========  ] [50100/60000] > Loss: 2.284375\n",
            "Epoch 01 [========  ] [50200/60000] > Loss: 2.276990\n",
            "Epoch 01 [========  ] [50300/60000] > Loss: 2.287302\n",
            "Epoch 01 [========  ] [50400/60000] > Loss: 2.274225\n",
            "Epoch 01 [========  ] [50500/60000] > Loss: 2.280952\n",
            "Epoch 01 [========  ] [50600/60000] > Loss: 2.283972\n",
            "Epoch 01 [========  ] [50700/60000] > Loss: 2.284980\n",
            "Epoch 01 [========  ] [50800/60000] > Loss: 2.280097\n",
            "Epoch 01 [========  ] [50900/60000] > Loss: 2.285285\n",
            "Epoch 01 [========  ] [51000/60000] > Loss: 2.279048\n",
            "Epoch 01 [========  ] [51100/60000] > Loss: 2.280668\n",
            "Epoch 01 [========  ] [51200/60000] > Loss: 2.285794\n",
            "Epoch 01 [========  ] [51300/60000] > Loss: 2.282138\n",
            "Epoch 01 [========  ] [51400/60000] > Loss: 2.278059\n",
            "Epoch 01 [========  ] [51500/60000] > Loss: 2.276671\n",
            "Epoch 01 [========  ] [51600/60000] > Loss: 2.285569\n",
            "Epoch 01 [========  ] [51700/60000] > Loss: 2.276072\n",
            "Epoch 01 [========  ] [51800/60000] > Loss: 2.288118\n",
            "Epoch 01 [========  ] [51900/60000] > Loss: 2.276369\n",
            "Epoch 01 [========  ] [52000/60000] > Loss: 2.283702\n",
            "Epoch 01 [========  ] [52100/60000] > Loss: 2.270557\n",
            "Epoch 01 [========  ] [52200/60000] > Loss: 2.279482\n",
            "Epoch 01 [========  ] [52300/60000] > Loss: 2.270655\n",
            "Epoch 01 [========  ] [52400/60000] > Loss: 2.282910\n",
            "Epoch 01 [========  ] [52500/60000] > Loss: 2.269412\n",
            "Epoch 01 [========  ] [52600/60000] > Loss: 2.279132\n",
            "Epoch 01 [========  ] [52700/60000] > Loss: 2.282386\n",
            "Epoch 01 [========  ] [52800/60000] > Loss: 2.274863\n",
            "Epoch 01 [========  ] [52900/60000] > Loss: 2.291513\n",
            "Epoch 01 [========  ] [53000/60000] > Loss: 2.282252\n",
            "Epoch 01 [========  ] [53100/60000] > Loss: 2.281214\n",
            "Epoch 01 [========  ] [53200/60000] > Loss: 2.262833\n",
            "Epoch 01 [========  ] [53300/60000] > Loss: 2.272579\n",
            "Epoch 01 [========  ] [53400/60000] > Loss: 2.282129\n",
            "Epoch 01 [========  ] [53500/60000] > Loss: 2.275179\n",
            "Epoch 01 [========  ] [53600/60000] > Loss: 2.275586\n",
            "Epoch 01 [========  ] [53700/60000] > Loss: 2.282569\n",
            "Epoch 01 [========  ] [53800/60000] > Loss: 2.275520\n",
            "Epoch 01 [========  ] [53900/60000] > Loss: 2.283723\n",
            "Epoch 01 [========= ] [54000/60000] > Loss: 2.275509\n",
            "Epoch 01 [========= ] [54100/60000] > Loss: 2.290126\n",
            "Epoch 01 [========= ] [54200/60000] > Loss: 2.283268\n",
            "Epoch 01 [========= ] [54300/60000] > Loss: 2.276001\n",
            "Epoch 01 [========= ] [54400/60000] > Loss: 2.272479\n",
            "Epoch 01 [========= ] [54500/60000] > Loss: 2.276264\n",
            "Epoch 01 [========= ] [54600/60000] > Loss: 2.281047\n",
            "Epoch 01 [========= ] [54700/60000] > Loss: 2.279650\n",
            "Epoch 01 [========= ] [54800/60000] > Loss: 2.275243\n",
            "Epoch 01 [========= ] [54900/60000] > Loss: 2.262007\n",
            "Epoch 01 [========= ] [55000/60000] > Loss: 2.279135\n",
            "Epoch 01 [========= ] [55100/60000] > Loss: 2.279606\n",
            "Epoch 01 [========= ] [55200/60000] > Loss: 2.281024\n",
            "Epoch 01 [========= ] [55300/60000] > Loss: 2.276614\n",
            "Epoch 01 [========= ] [55400/60000] > Loss: 2.277791\n",
            "Epoch 01 [========= ] [55500/60000] > Loss: 2.274185\n",
            "Epoch 01 [========= ] [55600/60000] > Loss: 2.278856\n",
            "Epoch 01 [========= ] [55700/60000] > Loss: 2.279657\n",
            "Epoch 01 [========= ] [55800/60000] > Loss: 2.272556\n",
            "Epoch 01 [========= ] [55900/60000] > Loss: 2.272358\n",
            "Epoch 01 [========= ] [56000/60000] > Loss: 2.267388\n",
            "Epoch 01 [========= ] [56100/60000] > Loss: 2.274777\n",
            "Epoch 01 [========= ] [56200/60000] > Loss: 2.280587\n",
            "Epoch 01 [========= ] [56300/60000] > Loss: 2.280901\n",
            "Epoch 01 [========= ] [56400/60000] > Loss: 2.269025\n",
            "Epoch 01 [========= ] [56500/60000] > Loss: 2.285160\n",
            "Epoch 01 [========= ] [56600/60000] > Loss: 2.280117\n",
            "Epoch 01 [========= ] [56700/60000] > Loss: 2.279554\n",
            "Epoch 01 [========= ] [56800/60000] > Loss: 2.288268\n",
            "Epoch 01 [========= ] [56900/60000] > Loss: 2.285440\n",
            "Epoch 01 [========= ] [57000/60000] > Loss: 2.287013\n",
            "Epoch 01 [========= ] [57100/60000] > Loss: 2.272747\n",
            "Epoch 01 [========= ] [57200/60000] > Loss: 2.278277\n",
            "Epoch 01 [========= ] [57300/60000] > Loss: 2.272713\n",
            "Epoch 01 [========= ] [57400/60000] > Loss: 2.280107\n",
            "Epoch 01 [========= ] [57500/60000] > Loss: 2.275080\n",
            "Epoch 01 [========= ] [57600/60000] > Loss: 2.286489\n",
            "Epoch 01 [========= ] [57700/60000] > Loss: 2.278329\n",
            "Epoch 01 [========= ] [57800/60000] > Loss: 2.278951\n",
            "Epoch 01 [========= ] [57900/60000] > Loss: 2.279949\n",
            "Epoch 01 [========= ] [58000/60000] > Loss: 2.272795\n",
            "Epoch 01 [========= ] [58100/60000] > Loss: 2.275027\n",
            "Epoch 01 [========= ] [58200/60000] > Loss: 2.276630\n",
            "Epoch 01 [========= ] [58300/60000] > Loss: 2.267756\n",
            "Epoch 01 [========= ] [58400/60000] > Loss: 2.276138\n",
            "Epoch 01 [========= ] [58500/60000] > Loss: 2.283842\n",
            "Epoch 01 [========= ] [58600/60000] > Loss: 2.263511\n",
            "Epoch 01 [========= ] [58700/60000] > Loss: 2.279395\n",
            "Epoch 01 [========= ] [58800/60000] > Loss: 2.270171\n",
            "Epoch 01 [========= ] [58900/60000] > Loss: 2.278042\n",
            "Epoch 01 [========= ] [59000/60000] > Loss: 2.276956\n",
            "Epoch 01 [========= ] [59100/60000] > Loss: 2.272329\n",
            "Epoch 01 [========= ] [59200/60000] > Loss: 2.289724\n",
            "Epoch 01 [========= ] [59300/60000] > Loss: 2.285165\n",
            "Epoch 01 [========= ] [59400/60000] > Loss: 2.272895\n",
            "Epoch 01 [========= ] [59500/60000] > Loss: 2.283281\n",
            "Epoch 01 [========= ] [59600/60000] > Loss: 2.285462\n",
            "Epoch 01 [========= ] [59700/60000] > Loss: 2.277105\n",
            "Epoch 01 [========= ] [59800/60000] > Loss: 2.274628\n",
            "Epoch 01 [========= ] [59900/60000] > Loss: 2.269493\n",
            "Epoch 01 [==========] [60000/60000] > Loss: 2.285352\n",
            "Epoch 01 [==========] [10000/10000] Time 17:43:31.278998 > Acuracia Validacao: 17.19%\n",
            "Epoch 02 [          ] [100/60000] > Loss: 2.260710\n",
            "Epoch 02 [          ] [200/60000] > Loss: 2.276912\n",
            "Epoch 02 [          ] [300/60000] > Loss: 2.273626\n",
            "Epoch 02 [          ] [400/60000] > Loss: 2.271980\n",
            "Epoch 02 [          ] [500/60000] > Loss: 2.281334\n",
            "Epoch 02 [          ] [600/60000] > Loss: 2.275830\n",
            "Epoch 02 [          ] [700/60000] > Loss: 2.265783\n",
            "Epoch 02 [          ] [800/60000] > Loss: 2.272713\n",
            "Epoch 02 [          ] [900/60000] > Loss: 2.270081\n",
            "Epoch 02 [          ] [1000/60000] > Loss: 2.271581\n",
            "Epoch 02 [          ] [1100/60000] > Loss: 2.267309\n",
            "Epoch 02 [          ] [1200/60000] > Loss: 2.278895\n",
            "Epoch 02 [          ] [1300/60000] > Loss: 2.277103\n",
            "Epoch 02 [          ] [1400/60000] > Loss: 2.280645\n",
            "Epoch 02 [          ] [1500/60000] > Loss: 2.275428\n",
            "Epoch 02 [          ] [1600/60000] > Loss: 2.283793\n",
            "Epoch 02 [          ] [1700/60000] > Loss: 2.277632\n",
            "Epoch 02 [          ] [1800/60000] > Loss: 2.270921\n",
            "Epoch 02 [          ] [1900/60000] > Loss: 2.272525\n",
            "Epoch 02 [          ] [2000/60000] > Loss: 2.271807\n",
            "Epoch 02 [          ] [2100/60000] > Loss: 2.269051\n",
            "Epoch 02 [          ] [2200/60000] > Loss: 2.265110\n",
            "Epoch 02 [          ] [2300/60000] > Loss: 2.264392\n",
            "Epoch 02 [          ] [2400/60000] > Loss: 2.259517\n",
            "Epoch 02 [          ] [2500/60000] > Loss: 2.278840\n",
            "Epoch 02 [          ] [2600/60000] > Loss: 2.267567\n",
            "Epoch 02 [          ] [2700/60000] > Loss: 2.279211\n",
            "Epoch 02 [          ] [2800/60000] > Loss: 2.275278\n",
            "Epoch 02 [          ] [2900/60000] > Loss: 2.276470\n",
            "Epoch 02 [          ] [3000/60000] > Loss: 2.267312\n",
            "Epoch 02 [          ] [3100/60000] > Loss: 2.259207\n",
            "Epoch 02 [          ] [3200/60000] > Loss: 2.278605\n",
            "Epoch 02 [          ] [3300/60000] > Loss: 2.284880\n",
            "Epoch 02 [          ] [3400/60000] > Loss: 2.273935\n",
            "Epoch 02 [          ] [3500/60000] > Loss: 2.266067\n",
            "Epoch 02 [          ] [3600/60000] > Loss: 2.275867\n",
            "Epoch 02 [          ] [3700/60000] > Loss: 2.278596\n",
            "Epoch 02 [          ] [3800/60000] > Loss: 2.265100\n",
            "Epoch 02 [          ] [3900/60000] > Loss: 2.280316\n",
            "Epoch 02 [          ] [4000/60000] > Loss: 2.280722\n",
            "Epoch 02 [          ] [4100/60000] > Loss: 2.284357\n",
            "Epoch 02 [          ] [4200/60000] > Loss: 2.270782\n",
            "Epoch 02 [          ] [4300/60000] > Loss: 2.271604\n",
            "Epoch 02 [          ] [4400/60000] > Loss: 2.260082\n",
            "Epoch 02 [          ] [4500/60000] > Loss: 2.281980\n",
            "Epoch 02 [          ] [4600/60000] > Loss: 2.280472\n",
            "Epoch 02 [          ] [4700/60000] > Loss: 2.288081\n",
            "Epoch 02 [          ] [4800/60000] > Loss: 2.267169\n",
            "Epoch 02 [          ] [4900/60000] > Loss: 2.275009\n",
            "Epoch 02 [          ] [5000/60000] > Loss: 2.276350\n",
            "Epoch 02 [          ] [5100/60000] > Loss: 2.273030\n",
            "Epoch 02 [          ] [5200/60000] > Loss: 2.282104\n",
            "Epoch 02 [          ] [5300/60000] > Loss: 2.253175\n",
            "Epoch 02 [          ] [5400/60000] > Loss: 2.272331\n",
            "Epoch 02 [          ] [5500/60000] > Loss: 2.272831\n",
            "Epoch 02 [          ] [5600/60000] > Loss: 2.271755\n",
            "Epoch 02 [          ] [5700/60000] > Loss: 2.275343\n",
            "Epoch 02 [          ] [5800/60000] > Loss: 2.273685\n",
            "Epoch 02 [          ] [5900/60000] > Loss: 2.275936\n",
            "Epoch 02 [=         ] [6000/60000] > Loss: 2.269904\n",
            "Epoch 02 [=         ] [6100/60000] > Loss: 2.268523\n",
            "Epoch 02 [=         ] [6200/60000] > Loss: 2.276715\n",
            "Epoch 02 [=         ] [6300/60000] > Loss: 2.269451\n",
            "Epoch 02 [=         ] [6400/60000] > Loss: 2.286535\n",
            "Epoch 02 [=         ] [6500/60000] > Loss: 2.277163\n",
            "Epoch 02 [=         ] [6600/60000] > Loss: 2.275801\n",
            "Epoch 02 [=         ] [6700/60000] > Loss: 2.274381\n",
            "Epoch 02 [=         ] [6800/60000] > Loss: 2.274812\n",
            "Epoch 02 [=         ] [6900/60000] > Loss: 2.263138\n",
            "Epoch 02 [=         ] [7000/60000] > Loss: 2.271514\n",
            "Epoch 02 [=         ] [7100/60000] > Loss: 2.281526\n",
            "Epoch 02 [=         ] [7200/60000] > Loss: 2.272322\n",
            "Epoch 02 [=         ] [7300/60000] > Loss: 2.265595\n",
            "Epoch 02 [=         ] [7400/60000] > Loss: 2.266862\n",
            "Epoch 02 [=         ] [7500/60000] > Loss: 2.276460\n",
            "Epoch 02 [=         ] [7600/60000] > Loss: 2.267034\n",
            "Epoch 02 [=         ] [7700/60000] > Loss: 2.278999\n",
            "Epoch 02 [=         ] [7800/60000] > Loss: 2.274372\n",
            "Epoch 02 [=         ] [7900/60000] > Loss: 2.279078\n",
            "Epoch 02 [=         ] [8000/60000] > Loss: 2.272528\n",
            "Epoch 02 [=         ] [8100/60000] > Loss: 2.280394\n",
            "Epoch 02 [=         ] [8200/60000] > Loss: 2.278395\n",
            "Epoch 02 [=         ] [8300/60000] > Loss: 2.267136\n",
            "Epoch 02 [=         ] [8400/60000] > Loss: 2.271064\n",
            "Epoch 02 [=         ] [8500/60000] > Loss: 2.274356\n",
            "Epoch 02 [=         ] [8600/60000] > Loss: 2.265986\n",
            "Epoch 02 [=         ] [8700/60000] > Loss: 2.264152\n",
            "Epoch 02 [=         ] [8800/60000] > Loss: 2.276040\n",
            "Epoch 02 [=         ] [8900/60000] > Loss: 2.266894\n",
            "Epoch 02 [=         ] [9000/60000] > Loss: 2.272355\n",
            "Epoch 02 [=         ] [9100/60000] > Loss: 2.272061\n",
            "Epoch 02 [=         ] [9200/60000] > Loss: 2.265040\n",
            "Epoch 02 [=         ] [9300/60000] > Loss: 2.259151\n",
            "Epoch 02 [=         ] [9400/60000] > Loss: 2.279861\n",
            "Epoch 02 [=         ] [9500/60000] > Loss: 2.272611\n",
            "Epoch 02 [=         ] [9600/60000] > Loss: 2.273707\n",
            "Epoch 02 [=         ] [9700/60000] > Loss: 2.272223\n",
            "Epoch 02 [=         ] [9800/60000] > Loss: 2.275503\n",
            "Epoch 02 [=         ] [9900/60000] > Loss: 2.266670\n",
            "Epoch 02 [=         ] [10000/60000] > Loss: 2.270078\n",
            "Epoch 02 [=         ] [10100/60000] > Loss: 2.272574\n",
            "Epoch 02 [=         ] [10200/60000] > Loss: 2.271700\n",
            "Epoch 02 [=         ] [10300/60000] > Loss: 2.280742\n",
            "Epoch 02 [=         ] [10400/60000] > Loss: 2.276337\n",
            "Epoch 02 [=         ] [10500/60000] > Loss: 2.269008\n",
            "Epoch 02 [=         ] [10600/60000] > Loss: 2.271459\n",
            "Epoch 02 [=         ] [10700/60000] > Loss: 2.275548\n",
            "Epoch 02 [=         ] [10800/60000] > Loss: 2.270163\n",
            "Epoch 02 [=         ] [10900/60000] > Loss: 2.278154\n",
            "Epoch 02 [=         ] [11000/60000] > Loss: 2.276059\n",
            "Epoch 02 [=         ] [11100/60000] > Loss: 2.269117\n",
            "Epoch 02 [=         ] [11200/60000] > Loss: 2.263496\n",
            "Epoch 02 [=         ] [11300/60000] > Loss: 2.274808\n",
            "Epoch 02 [=         ] [11400/60000] > Loss: 2.271034\n",
            "Epoch 02 [=         ] [11500/60000] > Loss: 2.276694\n",
            "Epoch 02 [=         ] [11600/60000] > Loss: 2.271996\n",
            "Epoch 02 [=         ] [11700/60000] > Loss: 2.270076\n",
            "Epoch 02 [=         ] [11800/60000] > Loss: 2.265171\n",
            "Epoch 02 [=         ] [11900/60000] > Loss: 2.264960\n",
            "Epoch 02 [==        ] [12000/60000] > Loss: 2.263488\n",
            "Epoch 02 [==        ] [12100/60000] > Loss: 2.266609\n",
            "Epoch 02 [==        ] [12200/60000] > Loss: 2.268490\n",
            "Epoch 02 [==        ] [12300/60000] > Loss: 2.269701\n",
            "Epoch 02 [==        ] [12400/60000] > Loss: 2.267150\n",
            "Epoch 02 [==        ] [12500/60000] > Loss: 2.275074\n",
            "Epoch 02 [==        ] [12600/60000] > Loss: 2.271171\n",
            "Epoch 02 [==        ] [12700/60000] > Loss: 2.263939\n",
            "Epoch 02 [==        ] [12800/60000] > Loss: 2.268349\n",
            "Epoch 02 [==        ] [12900/60000] > Loss: 2.270408\n",
            "Epoch 02 [==        ] [13000/60000] > Loss: 2.258109\n",
            "Epoch 02 [==        ] [13100/60000] > Loss: 2.271379\n",
            "Epoch 02 [==        ] [13200/60000] > Loss: 2.276398\n",
            "Epoch 02 [==        ] [13300/60000] > Loss: 2.268338\n",
            "Epoch 02 [==        ] [13400/60000] > Loss: 2.270757\n",
            "Epoch 02 [==        ] [13500/60000] > Loss: 2.259352\n",
            "Epoch 02 [==        ] [13600/60000] > Loss: 2.273342\n",
            "Epoch 02 [==        ] [13700/60000] > Loss: 2.275273\n",
            "Epoch 02 [==        ] [13800/60000] > Loss: 2.276129\n",
            "Epoch 02 [==        ] [13900/60000] > Loss: 2.263485\n",
            "Epoch 02 [==        ] [14000/60000] > Loss: 2.283796\n",
            "Epoch 02 [==        ] [14100/60000] > Loss: 2.272569\n",
            "Epoch 02 [==        ] [14200/60000] > Loss: 2.259035\n",
            "Epoch 02 [==        ] [14300/60000] > Loss: 2.252730\n",
            "Epoch 02 [==        ] [14400/60000] > Loss: 2.273345\n",
            "Epoch 02 [==        ] [14500/60000] > Loss: 2.282117\n",
            "Epoch 02 [==        ] [14600/60000] > Loss: 2.266907\n",
            "Epoch 02 [==        ] [14700/60000] > Loss: 2.273860\n",
            "Epoch 02 [==        ] [14800/60000] > Loss: 2.269721\n",
            "Epoch 02 [==        ] [14900/60000] > Loss: 2.265978\n",
            "Epoch 02 [==        ] [15000/60000] > Loss: 2.257238\n",
            "Epoch 02 [==        ] [15100/60000] > Loss: 2.253249\n",
            "Epoch 02 [==        ] [15200/60000] > Loss: 2.272206\n",
            "Epoch 02 [==        ] [15300/60000] > Loss: 2.260115\n",
            "Epoch 02 [==        ] [15400/60000] > Loss: 2.269677\n",
            "Epoch 02 [==        ] [15500/60000] > Loss: 2.263383\n",
            "Epoch 02 [==        ] [15600/60000] > Loss: 2.270732\n",
            "Epoch 02 [==        ] [15700/60000] > Loss: 2.266216\n",
            "Epoch 02 [==        ] [15800/60000] > Loss: 2.270320\n",
            "Epoch 02 [==        ] [15900/60000] > Loss: 2.269801\n",
            "Epoch 02 [==        ] [16000/60000] > Loss: 2.265244\n",
            "Epoch 02 [==        ] [16100/60000] > Loss: 2.263300\n",
            "Epoch 02 [==        ] [16200/60000] > Loss: 2.274545\n",
            "Epoch 02 [==        ] [16300/60000] > Loss: 2.256201\n",
            "Epoch 02 [==        ] [16400/60000] > Loss: 2.278013\n",
            "Epoch 02 [==        ] [16500/60000] > Loss: 2.260501\n",
            "Epoch 02 [==        ] [16600/60000] > Loss: 2.266970\n",
            "Epoch 02 [==        ] [16700/60000] > Loss: 2.270977\n",
            "Epoch 02 [==        ] [16800/60000] > Loss: 2.262428\n",
            "Epoch 02 [==        ] [16900/60000] > Loss: 2.282936\n",
            "Epoch 02 [==        ] [17000/60000] > Loss: 2.266070\n",
            "Epoch 02 [==        ] [17100/60000] > Loss: 2.271034\n",
            "Epoch 02 [==        ] [17200/60000] > Loss: 2.262021\n",
            "Epoch 02 [==        ] [17300/60000] > Loss: 2.269592\n",
            "Epoch 02 [==        ] [17400/60000] > Loss: 2.259510\n",
            "Epoch 02 [==        ] [17500/60000] > Loss: 2.259597\n",
            "Epoch 02 [==        ] [17600/60000] > Loss: 2.283593\n",
            "Epoch 02 [==        ] [17700/60000] > Loss: 2.265647\n",
            "Epoch 02 [==        ] [17800/60000] > Loss: 2.275739\n",
            "Epoch 02 [==        ] [17900/60000] > Loss: 2.268481\n",
            "Epoch 02 [===       ] [18000/60000] > Loss: 2.279413\n",
            "Epoch 02 [===       ] [18100/60000] > Loss: 2.261608\n",
            "Epoch 02 [===       ] [18200/60000] > Loss: 2.258156\n",
            "Epoch 02 [===       ] [18300/60000] > Loss: 2.261091\n",
            "Epoch 02 [===       ] [18400/60000] > Loss: 2.268907\n",
            "Epoch 02 [===       ] [18500/60000] > Loss: 2.263374\n",
            "Epoch 02 [===       ] [18600/60000] > Loss: 2.267891\n",
            "Epoch 02 [===       ] [18700/60000] > Loss: 2.269869\n",
            "Epoch 02 [===       ] [18800/60000] > Loss: 2.269988\n",
            "Epoch 02 [===       ] [18900/60000] > Loss: 2.277423\n",
            "Epoch 02 [===       ] [19000/60000] > Loss: 2.283908\n",
            "Epoch 02 [===       ] [19100/60000] > Loss: 2.262963\n",
            "Epoch 02 [===       ] [19200/60000] > Loss: 2.258396\n",
            "Epoch 02 [===       ] [19300/60000] > Loss: 2.273360\n",
            "Epoch 02 [===       ] [19400/60000] > Loss: 2.267633\n",
            "Epoch 02 [===       ] [19500/60000] > Loss: 2.273325\n",
            "Epoch 02 [===       ] [19600/60000] > Loss: 2.270330\n",
            "Epoch 02 [===       ] [19700/60000] > Loss: 2.274199\n",
            "Epoch 02 [===       ] [19800/60000] > Loss: 2.266521\n",
            "Epoch 02 [===       ] [19900/60000] > Loss: 2.252988\n",
            "Epoch 02 [===       ] [20000/60000] > Loss: 2.278265\n",
            "Epoch 02 [===       ] [20100/60000] > Loss: 2.257898\n",
            "Epoch 02 [===       ] [20200/60000] > Loss: 2.258154\n",
            "Epoch 02 [===       ] [20300/60000] > Loss: 2.267513\n",
            "Epoch 02 [===       ] [20400/60000] > Loss: 2.264746\n",
            "Epoch 02 [===       ] [20500/60000] > Loss: 2.269735\n",
            "Epoch 02 [===       ] [20600/60000] > Loss: 2.255299\n",
            "Epoch 02 [===       ] [20700/60000] > Loss: 2.273856\n",
            "Epoch 02 [===       ] [20800/60000] > Loss: 2.266297\n",
            "Epoch 02 [===       ] [20900/60000] > Loss: 2.273310\n",
            "Epoch 02 [===       ] [21000/60000] > Loss: 2.263821\n",
            "Epoch 02 [===       ] [21100/60000] > Loss: 2.254852\n",
            "Epoch 02 [===       ] [21200/60000] > Loss: 2.247048\n",
            "Epoch 02 [===       ] [21300/60000] > Loss: 2.275238\n",
            "Epoch 02 [===       ] [21400/60000] > Loss: 2.248252\n",
            "Epoch 02 [===       ] [21500/60000] > Loss: 2.261226\n",
            "Epoch 02 [===       ] [21600/60000] > Loss: 2.262712\n",
            "Epoch 02 [===       ] [21700/60000] > Loss: 2.276632\n",
            "Epoch 02 [===       ] [21800/60000] > Loss: 2.269518\n",
            "Epoch 02 [===       ] [21900/60000] > Loss: 2.259582\n",
            "Epoch 02 [===       ] [22000/60000] > Loss: 2.270907\n",
            "Epoch 02 [===       ] [22100/60000] > Loss: 2.265875\n",
            "Epoch 02 [===       ] [22200/60000] > Loss: 2.262814\n",
            "Epoch 02 [===       ] [22300/60000] > Loss: 2.263962\n",
            "Epoch 02 [===       ] [22400/60000] > Loss: 2.264036\n",
            "Epoch 02 [===       ] [22500/60000] > Loss: 2.269424\n",
            "Epoch 02 [===       ] [22600/60000] > Loss: 2.260227\n",
            "Epoch 02 [===       ] [22700/60000] > Loss: 2.274572\n",
            "Epoch 02 [===       ] [22800/60000] > Loss: 2.278434\n",
            "Epoch 02 [===       ] [22900/60000] > Loss: 2.252795\n",
            "Epoch 02 [===       ] [23000/60000] > Loss: 2.261615\n",
            "Epoch 02 [===       ] [23100/60000] > Loss: 2.266640\n",
            "Epoch 02 [===       ] [23200/60000] > Loss: 2.262975\n",
            "Epoch 02 [===       ] [23300/60000] > Loss: 2.248137\n",
            "Epoch 02 [===       ] [23400/60000] > Loss: 2.251846\n",
            "Epoch 02 [===       ] [23500/60000] > Loss: 2.258707\n",
            "Epoch 02 [===       ] [23600/60000] > Loss: 2.265600\n",
            "Epoch 02 [===       ] [23700/60000] > Loss: 2.263541\n",
            "Epoch 02 [===       ] [23800/60000] > Loss: 2.262243\n",
            "Epoch 02 [===       ] [23900/60000] > Loss: 2.272933\n",
            "Epoch 02 [====      ] [24000/60000] > Loss: 2.267757\n",
            "Epoch 02 [====      ] [24100/60000] > Loss: 2.265231\n",
            "Epoch 02 [====      ] [24200/60000] > Loss: 2.252869\n",
            "Epoch 02 [====      ] [24300/60000] > Loss: 2.260370\n",
            "Epoch 02 [====      ] [24400/60000] > Loss: 2.271974\n",
            "Epoch 02 [====      ] [24500/60000] > Loss: 2.277743\n",
            "Epoch 02 [====      ] [24600/60000] > Loss: 2.246067\n",
            "Epoch 02 [====      ] [24700/60000] > Loss: 2.255376\n",
            "Epoch 02 [====      ] [24800/60000] > Loss: 2.257216\n",
            "Epoch 02 [====      ] [24900/60000] > Loss: 2.254764\n",
            "Epoch 02 [====      ] [25000/60000] > Loss: 2.271595\n",
            "Epoch 02 [====      ] [25100/60000] > Loss: 2.261421\n",
            "Epoch 02 [====      ] [25200/60000] > Loss: 2.255534\n",
            "Epoch 02 [====      ] [25300/60000] > Loss: 2.282843\n",
            "Epoch 02 [====      ] [25400/60000] > Loss: 2.266381\n",
            "Epoch 02 [====      ] [25500/60000] > Loss: 2.261077\n",
            "Epoch 02 [====      ] [25600/60000] > Loss: 2.269289\n",
            "Epoch 02 [====      ] [25700/60000] > Loss: 2.273212\n",
            "Epoch 02 [====      ] [25800/60000] > Loss: 2.272424\n",
            "Epoch 02 [====      ] [25900/60000] > Loss: 2.266362\n",
            "Epoch 02 [====      ] [26000/60000] > Loss: 2.267287\n",
            "Epoch 02 [====      ] [26100/60000] > Loss: 2.279229\n",
            "Epoch 02 [====      ] [26200/60000] > Loss: 2.266516\n",
            "Epoch 02 [====      ] [26300/60000] > Loss: 2.271371\n",
            "Epoch 02 [====      ] [26400/60000] > Loss: 2.256172\n",
            "Epoch 02 [====      ] [26500/60000] > Loss: 2.264591\n",
            "Epoch 02 [====      ] [26600/60000] > Loss: 2.282547\n",
            "Epoch 02 [====      ] [26700/60000] > Loss: 2.268753\n",
            "Epoch 02 [====      ] [26800/60000] > Loss: 2.263337\n",
            "Epoch 02 [====      ] [26900/60000] > Loss: 2.262786\n",
            "Epoch 02 [====      ] [27000/60000] > Loss: 2.268531\n",
            "Epoch 02 [====      ] [27100/60000] > Loss: 2.255786\n",
            "Epoch 02 [====      ] [27200/60000] > Loss: 2.276899\n",
            "Epoch 02 [====      ] [27300/60000] > Loss: 2.256892\n",
            "Epoch 02 [====      ] [27400/60000] > Loss: 2.261262\n",
            "Epoch 02 [====      ] [27500/60000] > Loss: 2.264005\n",
            "Epoch 02 [====      ] [27600/60000] > Loss: 2.262385\n",
            "Epoch 02 [====      ] [27700/60000] > Loss: 2.267625\n",
            "Epoch 02 [====      ] [27800/60000] > Loss: 2.270929\n",
            "Epoch 02 [====      ] [27900/60000] > Loss: 2.273718\n",
            "Epoch 02 [====      ] [28000/60000] > Loss: 2.272242\n",
            "Epoch 02 [====      ] [28100/60000] > Loss: 2.258600\n",
            "Epoch 02 [====      ] [28200/60000] > Loss: 2.261867\n",
            "Epoch 02 [====      ] [28300/60000] > Loss: 2.258944\n",
            "Epoch 02 [====      ] [28400/60000] > Loss: 2.258323\n",
            "Epoch 02 [====      ] [28500/60000] > Loss: 2.260045\n",
            "Epoch 02 [====      ] [28600/60000] > Loss: 2.271852\n",
            "Epoch 02 [====      ] [28700/60000] > Loss: 2.268221\n",
            "Epoch 02 [====      ] [28800/60000] > Loss: 2.259977\n",
            "Epoch 02 [====      ] [28900/60000] > Loss: 2.250285\n",
            "Epoch 02 [====      ] [29000/60000] > Loss: 2.261723\n",
            "Epoch 02 [====      ] [29100/60000] > Loss: 2.262643\n",
            "Epoch 02 [====      ] [29200/60000] > Loss: 2.267940\n",
            "Epoch 02 [====      ] [29300/60000] > Loss: 2.275682\n",
            "Epoch 02 [====      ] [29400/60000] > Loss: 2.259551\n",
            "Epoch 02 [====      ] [29500/60000] > Loss: 2.247184\n",
            "Epoch 02 [====      ] [29600/60000] > Loss: 2.267217\n",
            "Epoch 02 [====      ] [29700/60000] > Loss: 2.266546\n",
            "Epoch 02 [====      ] [29800/60000] > Loss: 2.256996\n",
            "Epoch 02 [====      ] [29900/60000] > Loss: 2.266651\n",
            "Epoch 02 [=====     ] [30000/60000] > Loss: 2.261342\n",
            "Epoch 02 [=====     ] [30100/60000] > Loss: 2.258735\n",
            "Epoch 02 [=====     ] [30200/60000] > Loss: 2.264134\n",
            "Epoch 02 [=====     ] [30300/60000] > Loss: 2.263293\n",
            "Epoch 02 [=====     ] [30400/60000] > Loss: 2.252920\n",
            "Epoch 02 [=====     ] [30500/60000] > Loss: 2.254949\n",
            "Epoch 02 [=====     ] [30600/60000] > Loss: 2.256990\n",
            "Epoch 02 [=====     ] [30700/60000] > Loss: 2.248725\n",
            "Epoch 02 [=====     ] [30800/60000] > Loss: 2.260268\n",
            "Epoch 02 [=====     ] [30900/60000] > Loss: 2.266645\n",
            "Epoch 02 [=====     ] [31000/60000] > Loss: 2.267758\n",
            "Epoch 02 [=====     ] [31100/60000] > Loss: 2.262156\n",
            "Epoch 02 [=====     ] [31200/60000] > Loss: 2.251734\n",
            "Epoch 02 [=====     ] [31300/60000] > Loss: 2.255651\n",
            "Epoch 02 [=====     ] [31400/60000] > Loss: 2.256701\n",
            "Epoch 02 [=====     ] [31500/60000] > Loss: 2.261700\n",
            "Epoch 02 [=====     ] [31600/60000] > Loss: 2.252369\n",
            "Epoch 02 [=====     ] [31700/60000] > Loss: 2.247876\n",
            "Epoch 02 [=====     ] [31800/60000] > Loss: 2.258734\n",
            "Epoch 02 [=====     ] [31900/60000] > Loss: 2.263490\n",
            "Epoch 02 [=====     ] [32000/60000] > Loss: 2.255455\n",
            "Epoch 02 [=====     ] [32100/60000] > Loss: 2.260577\n",
            "Epoch 02 [=====     ] [32200/60000] > Loss: 2.268382\n",
            "Epoch 02 [=====     ] [32300/60000] > Loss: 2.253607\n",
            "Epoch 02 [=====     ] [32400/60000] > Loss: 2.263375\n",
            "Epoch 02 [=====     ] [32500/60000] > Loss: 2.261983\n",
            "Epoch 02 [=====     ] [32600/60000] > Loss: 2.256943\n",
            "Epoch 02 [=====     ] [32700/60000] > Loss: 2.263814\n",
            "Epoch 02 [=====     ] [32800/60000] > Loss: 2.262661\n",
            "Epoch 02 [=====     ] [32900/60000] > Loss: 2.266263\n",
            "Epoch 02 [=====     ] [33000/60000] > Loss: 2.266594\n",
            "Epoch 02 [=====     ] [33100/60000] > Loss: 2.266210\n",
            "Epoch 02 [=====     ] [33200/60000] > Loss: 2.255594\n",
            "Epoch 02 [=====     ] [33300/60000] > Loss: 2.272226\n",
            "Epoch 02 [=====     ] [33400/60000] > Loss: 2.251823\n",
            "Epoch 02 [=====     ] [33500/60000] > Loss: 2.247045\n",
            "Epoch 02 [=====     ] [33600/60000] > Loss: 2.260557\n",
            "Epoch 02 [=====     ] [33700/60000] > Loss: 2.257792\n",
            "Epoch 02 [=====     ] [33800/60000] > Loss: 2.247897\n",
            "Epoch 02 [=====     ] [33900/60000] > Loss: 2.259003\n",
            "Epoch 02 [=====     ] [34000/60000] > Loss: 2.254836\n",
            "Epoch 02 [=====     ] [34100/60000] > Loss: 2.270351\n",
            "Epoch 02 [=====     ] [34200/60000] > Loss: 2.261879\n",
            "Epoch 02 [=====     ] [34300/60000] > Loss: 2.259934\n",
            "Epoch 02 [=====     ] [34400/60000] > Loss: 2.265547\n",
            "Epoch 02 [=====     ] [34500/60000] > Loss: 2.253676\n",
            "Epoch 02 [=====     ] [34600/60000] > Loss: 2.273665\n",
            "Epoch 02 [=====     ] [34700/60000] > Loss: 2.249984\n",
            "Epoch 02 [=====     ] [34800/60000] > Loss: 2.274955\n",
            "Epoch 02 [=====     ] [34900/60000] > Loss: 2.276102\n",
            "Epoch 02 [=====     ] [35000/60000] > Loss: 2.265741\n",
            "Epoch 02 [=====     ] [35100/60000] > Loss: 2.266350\n",
            "Epoch 02 [=====     ] [35200/60000] > Loss: 2.262062\n",
            "Epoch 02 [=====     ] [35300/60000] > Loss: 2.272305\n",
            "Epoch 02 [=====     ] [35400/60000] > Loss: 2.256523\n",
            "Epoch 02 [=====     ] [35500/60000] > Loss: 2.265224\n",
            "Epoch 02 [=====     ] [35600/60000] > Loss: 2.252571\n",
            "Epoch 02 [=====     ] [35700/60000] > Loss: 2.271042\n",
            "Epoch 02 [=====     ] [35800/60000] > Loss: 2.260737\n",
            "Epoch 02 [=====     ] [35900/60000] > Loss: 2.259544\n",
            "Epoch 02 [======    ] [36000/60000] > Loss: 2.261677\n",
            "Epoch 02 [======    ] [36100/60000] > Loss: 2.271850\n",
            "Epoch 02 [======    ] [36200/60000] > Loss: 2.261795\n",
            "Epoch 02 [======    ] [36300/60000] > Loss: 2.256205\n",
            "Epoch 02 [======    ] [36400/60000] > Loss: 2.251105\n",
            "Epoch 02 [======    ] [36500/60000] > Loss: 2.267224\n",
            "Epoch 02 [======    ] [36600/60000] > Loss: 2.259872\n",
            "Epoch 02 [======    ] [36700/60000] > Loss: 2.245014\n",
            "Epoch 02 [======    ] [36800/60000] > Loss: 2.262006\n",
            "Epoch 02 [======    ] [36900/60000] > Loss: 2.261038\n",
            "Epoch 02 [======    ] [37000/60000] > Loss: 2.263371\n",
            "Epoch 02 [======    ] [37100/60000] > Loss: 2.257397\n",
            "Epoch 02 [======    ] [37200/60000] > Loss: 2.248601\n",
            "Epoch 02 [======    ] [37300/60000] > Loss: 2.262970\n",
            "Epoch 02 [======    ] [37400/60000] > Loss: 2.242084\n",
            "Epoch 02 [======    ] [37500/60000] > Loss: 2.257163\n",
            "Epoch 02 [======    ] [37600/60000] > Loss: 2.259877\n",
            "Epoch 02 [======    ] [37700/60000] > Loss: 2.258070\n",
            "Epoch 02 [======    ] [37800/60000] > Loss: 2.252301\n",
            "Epoch 02 [======    ] [37900/60000] > Loss: 2.264102\n",
            "Epoch 02 [======    ] [38000/60000] > Loss: 2.252729\n",
            "Epoch 02 [======    ] [38100/60000] > Loss: 2.258940\n",
            "Epoch 02 [======    ] [38200/60000] > Loss: 2.271101\n",
            "Epoch 02 [======    ] [38300/60000] > Loss: 2.263898\n",
            "Epoch 02 [======    ] [38400/60000] > Loss: 2.253899\n",
            "Epoch 02 [======    ] [38500/60000] > Loss: 2.257439\n",
            "Epoch 02 [======    ] [38600/60000] > Loss: 2.246897\n",
            "Epoch 02 [======    ] [38700/60000] > Loss: 2.244388\n",
            "Epoch 02 [======    ] [38800/60000] > Loss: 2.259163\n",
            "Epoch 02 [======    ] [38900/60000] > Loss: 2.257941\n",
            "Epoch 02 [======    ] [39000/60000] > Loss: 2.267193\n",
            "Epoch 02 [======    ] [39100/60000] > Loss: 2.260922\n",
            "Epoch 02 [======    ] [39200/60000] > Loss: 2.254711\n",
            "Epoch 02 [======    ] [39300/60000] > Loss: 2.263436\n",
            "Epoch 02 [======    ] [39400/60000] > Loss: 2.249966\n",
            "Epoch 02 [======    ] [39500/60000] > Loss: 2.256338\n",
            "Epoch 02 [======    ] [39600/60000] > Loss: 2.243467\n",
            "Epoch 02 [======    ] [39700/60000] > Loss: 2.258628\n",
            "Epoch 02 [======    ] [39800/60000] > Loss: 2.259070\n",
            "Epoch 02 [======    ] [39900/60000] > Loss: 2.255695\n",
            "Epoch 02 [======    ] [40000/60000] > Loss: 2.250536\n",
            "Epoch 02 [======    ] [40100/60000] > Loss: 2.268016\n",
            "Epoch 02 [======    ] [40200/60000] > Loss: 2.252873\n",
            "Epoch 02 [======    ] [40300/60000] > Loss: 2.250729\n",
            "Epoch 02 [======    ] [40400/60000] > Loss: 2.253444\n",
            "Epoch 02 [======    ] [40500/60000] > Loss: 2.266989\n",
            "Epoch 02 [======    ] [40600/60000] > Loss: 2.261467\n",
            "Epoch 02 [======    ] [40700/60000] > Loss: 2.248571\n",
            "Epoch 02 [======    ] [40800/60000] > Loss: 2.250146\n",
            "Epoch 02 [======    ] [40900/60000] > Loss: 2.255426\n",
            "Epoch 02 [======    ] [41000/60000] > Loss: 2.261547\n",
            "Epoch 02 [======    ] [41100/60000] > Loss: 2.267184\n",
            "Epoch 02 [======    ] [41200/60000] > Loss: 2.262378\n",
            "Epoch 02 [======    ] [41300/60000] > Loss: 2.245911\n",
            "Epoch 02 [======    ] [41400/60000] > Loss: 2.262016\n",
            "Epoch 02 [======    ] [41500/60000] > Loss: 2.261287\n",
            "Epoch 02 [======    ] [41600/60000] > Loss: 2.248829\n",
            "Epoch 02 [======    ] [41700/60000] > Loss: 2.259163\n",
            "Epoch 02 [======    ] [41800/60000] > Loss: 2.264816\n",
            "Epoch 02 [======    ] [41900/60000] > Loss: 2.250225\n",
            "Epoch 02 [=======   ] [42000/60000] > Loss: 2.249835\n",
            "Epoch 02 [=======   ] [42100/60000] > Loss: 2.253167\n",
            "Epoch 02 [=======   ] [42200/60000] > Loss: 2.271397\n",
            "Epoch 02 [=======   ] [42300/60000] > Loss: 2.253493\n",
            "Epoch 02 [=======   ] [42400/60000] > Loss: 2.250950\n",
            "Epoch 02 [=======   ] [42500/60000] > Loss: 2.249908\n",
            "Epoch 02 [=======   ] [42600/60000] > Loss: 2.258837\n",
            "Epoch 02 [=======   ] [42700/60000] > Loss: 2.250665\n",
            "Epoch 02 [=======   ] [42800/60000] > Loss: 2.259544\n",
            "Epoch 02 [=======   ] [42900/60000] > Loss: 2.253868\n",
            "Epoch 02 [=======   ] [43000/60000] > Loss: 2.269957\n",
            "Epoch 02 [=======   ] [43100/60000] > Loss: 2.258716\n",
            "Epoch 02 [=======   ] [43200/60000] > Loss: 2.262594\n",
            "Epoch 02 [=======   ] [43300/60000] > Loss: 2.249020\n",
            "Epoch 02 [=======   ] [43400/60000] > Loss: 2.249699\n",
            "Epoch 02 [=======   ] [43500/60000] > Loss: 2.260713\n",
            "Epoch 02 [=======   ] [43600/60000] > Loss: 2.246987\n",
            "Epoch 02 [=======   ] [43700/60000] > Loss: 2.252488\n",
            "Epoch 02 [=======   ] [43800/60000] > Loss: 2.256447\n",
            "Epoch 02 [=======   ] [43900/60000] > Loss: 2.258861\n",
            "Epoch 02 [=======   ] [44000/60000] > Loss: 2.260809\n",
            "Epoch 02 [=======   ] [44100/60000] > Loss: 2.252875\n",
            "Epoch 02 [=======   ] [44200/60000] > Loss: 2.265899\n",
            "Epoch 02 [=======   ] [44300/60000] > Loss: 2.253479\n",
            "Epoch 02 [=======   ] [44400/60000] > Loss: 2.266486\n",
            "Epoch 02 [=======   ] [44500/60000] > Loss: 2.252624\n",
            "Epoch 02 [=======   ] [44600/60000] > Loss: 2.259467\n",
            "Epoch 02 [=======   ] [44700/60000] > Loss: 2.238083\n",
            "Epoch 02 [=======   ] [44800/60000] > Loss: 2.240724\n",
            "Epoch 02 [=======   ] [44900/60000] > Loss: 2.251780\n",
            "Epoch 02 [=======   ] [45000/60000] > Loss: 2.252273\n",
            "Epoch 02 [=======   ] [45100/60000] > Loss: 2.253068\n",
            "Epoch 02 [=======   ] [45200/60000] > Loss: 2.255604\n",
            "Epoch 02 [=======   ] [45300/60000] > Loss: 2.255988\n",
            "Epoch 02 [=======   ] [45400/60000] > Loss: 2.247251\n",
            "Epoch 02 [=======   ] [45500/60000] > Loss: 2.250346\n",
            "Epoch 02 [=======   ] [45600/60000] > Loss: 2.248620\n",
            "Epoch 02 [=======   ] [45700/60000] > Loss: 2.263709\n",
            "Epoch 02 [=======   ] [45800/60000] > Loss: 2.264082\n",
            "Epoch 02 [=======   ] [45900/60000] > Loss: 2.253180\n",
            "Epoch 02 [=======   ] [46000/60000] > Loss: 2.266716\n",
            "Epoch 02 [=======   ] [46100/60000] > Loss: 2.256675\n",
            "Epoch 02 [=======   ] [46200/60000] > Loss: 2.258873\n",
            "Epoch 02 [=======   ] [46300/60000] > Loss: 2.244331\n",
            "Epoch 02 [=======   ] [46400/60000] > Loss: 2.240136\n",
            "Epoch 02 [=======   ] [46500/60000] > Loss: 2.250881\n",
            "Epoch 02 [=======   ] [46600/60000] > Loss: 2.251154\n",
            "Epoch 02 [=======   ] [46700/60000] > Loss: 2.236586\n",
            "Epoch 02 [=======   ] [46800/60000] > Loss: 2.252280\n",
            "Epoch 02 [=======   ] [46900/60000] > Loss: 2.247855\n",
            "Epoch 02 [=======   ] [47000/60000] > Loss: 2.252098\n",
            "Epoch 02 [=======   ] [47100/60000] > Loss: 2.257164\n",
            "Epoch 02 [=======   ] [47200/60000] > Loss: 2.248648\n",
            "Epoch 02 [=======   ] [47300/60000] > Loss: 2.260823\n",
            "Epoch 02 [=======   ] [47400/60000] > Loss: 2.246861\n",
            "Epoch 02 [=======   ] [47500/60000] > Loss: 2.255111\n",
            "Epoch 02 [=======   ] [47600/60000] > Loss: 2.250332\n",
            "Epoch 02 [=======   ] [47700/60000] > Loss: 2.261366\n",
            "Epoch 02 [=======   ] [47800/60000] > Loss: 2.263253\n",
            "Epoch 02 [=======   ] [47900/60000] > Loss: 2.266479\n",
            "Epoch 02 [========  ] [48000/60000] > Loss: 2.264492\n",
            "Epoch 02 [========  ] [48100/60000] > Loss: 2.261526\n",
            "Epoch 02 [========  ] [48200/60000] > Loss: 2.264401\n",
            "Epoch 02 [========  ] [48300/60000] > Loss: 2.262893\n",
            "Epoch 02 [========  ] [48400/60000] > Loss: 2.243274\n",
            "Epoch 02 [========  ] [48500/60000] > Loss: 2.253197\n",
            "Epoch 02 [========  ] [48600/60000] > Loss: 2.248746\n",
            "Epoch 02 [========  ] [48700/60000] > Loss: 2.247707\n",
            "Epoch 02 [========  ] [48800/60000] > Loss: 2.259439\n",
            "Epoch 02 [========  ] [48900/60000] > Loss: 2.259825\n",
            "Epoch 02 [========  ] [49000/60000] > Loss: 2.246381\n",
            "Epoch 02 [========  ] [49100/60000] > Loss: 2.263112\n",
            "Epoch 02 [========  ] [49200/60000] > Loss: 2.242954\n",
            "Epoch 02 [========  ] [49300/60000] > Loss: 2.244226\n",
            "Epoch 02 [========  ] [49400/60000] > Loss: 2.251544\n",
            "Epoch 02 [========  ] [49500/60000] > Loss: 2.250076\n",
            "Epoch 02 [========  ] [49600/60000] > Loss: 2.259640\n",
            "Epoch 02 [========  ] [49700/60000] > Loss: 2.263854\n",
            "Epoch 02 [========  ] [49800/60000] > Loss: 2.251839\n",
            "Epoch 02 [========  ] [49900/60000] > Loss: 2.257121\n",
            "Epoch 02 [========  ] [50000/60000] > Loss: 2.246796\n",
            "Epoch 02 [========  ] [50100/60000] > Loss: 2.246163\n",
            "Epoch 02 [========  ] [50200/60000] > Loss: 2.257237\n",
            "Epoch 02 [========  ] [50300/60000] > Loss: 2.256542\n",
            "Epoch 02 [========  ] [50400/60000] > Loss: 2.253548\n",
            "Epoch 02 [========  ] [50500/60000] > Loss: 2.258457\n",
            "Epoch 02 [========  ] [50600/60000] > Loss: 2.229317\n",
            "Epoch 02 [========  ] [50700/60000] > Loss: 2.259156\n",
            "Epoch 02 [========  ] [50800/60000] > Loss: 2.249493\n",
            "Epoch 02 [========  ] [50900/60000] > Loss: 2.253176\n",
            "Epoch 02 [========  ] [51000/60000] > Loss: 2.252113\n",
            "Epoch 02 [========  ] [51100/60000] > Loss: 2.255303\n",
            "Epoch 02 [========  ] [51200/60000] > Loss: 2.244067\n",
            "Epoch 02 [========  ] [51300/60000] > Loss: 2.258207\n",
            "Epoch 02 [========  ] [51400/60000] > Loss: 2.248301\n",
            "Epoch 02 [========  ] [51500/60000] > Loss: 2.252400\n",
            "Epoch 02 [========  ] [51600/60000] > Loss: 2.263036\n",
            "Epoch 02 [========  ] [51700/60000] > Loss: 2.257823\n",
            "Epoch 02 [========  ] [51800/60000] > Loss: 2.257257\n",
            "Epoch 02 [========  ] [51900/60000] > Loss: 2.255234\n",
            "Epoch 02 [========  ] [52000/60000] > Loss: 2.258426\n",
            "Epoch 02 [========  ] [52100/60000] > Loss: 2.241735\n",
            "Epoch 02 [========  ] [52200/60000] > Loss: 2.255123\n",
            "Epoch 02 [========  ] [52300/60000] > Loss: 2.254811\n",
            "Epoch 02 [========  ] [52400/60000] > Loss: 2.248581\n",
            "Epoch 02 [========  ] [52500/60000] > Loss: 2.263092\n",
            "Epoch 02 [========  ] [52600/60000] > Loss: 2.261412\n",
            "Epoch 02 [========  ] [52700/60000] > Loss: 2.249302\n",
            "Epoch 02 [========  ] [52800/60000] > Loss: 2.255136\n",
            "Epoch 02 [========  ] [52900/60000] > Loss: 2.254728\n",
            "Epoch 02 [========  ] [53000/60000] > Loss: 2.254141\n",
            "Epoch 02 [========  ] [53100/60000] > Loss: 2.248523\n",
            "Epoch 02 [========  ] [53200/60000] > Loss: 2.256943\n",
            "Epoch 02 [========  ] [53300/60000] > Loss: 2.259262\n",
            "Epoch 02 [========  ] [53400/60000] > Loss: 2.252532\n",
            "Epoch 02 [========  ] [53500/60000] > Loss: 2.258931\n",
            "Epoch 02 [========  ] [53600/60000] > Loss: 2.246390\n",
            "Epoch 02 [========  ] [53700/60000] > Loss: 2.252573\n",
            "Epoch 02 [========  ] [53800/60000] > Loss: 2.239683\n",
            "Epoch 02 [========  ] [53900/60000] > Loss: 2.234827\n",
            "Epoch 02 [========= ] [54000/60000] > Loss: 2.250202\n",
            "Epoch 02 [========= ] [54100/60000] > Loss: 2.244912\n",
            "Epoch 02 [========= ] [54200/60000] > Loss: 2.248258\n",
            "Epoch 02 [========= ] [54300/60000] > Loss: 2.259833\n",
            "Epoch 02 [========= ] [54400/60000] > Loss: 2.248420\n",
            "Epoch 02 [========= ] [54500/60000] > Loss: 2.261305\n",
            "Epoch 02 [========= ] [54600/60000] > Loss: 2.254159\n",
            "Epoch 02 [========= ] [54700/60000] > Loss: 2.241614\n",
            "Epoch 02 [========= ] [54800/60000] > Loss: 2.254567\n",
            "Epoch 02 [========= ] [54900/60000] > Loss: 2.257217\n",
            "Epoch 02 [========= ] [55000/60000] > Loss: 2.262624\n",
            "Epoch 02 [========= ] [55100/60000] > Loss: 2.247296\n",
            "Epoch 02 [========= ] [55200/60000] > Loss: 2.261154\n",
            "Epoch 02 [========= ] [55300/60000] > Loss: 2.255052\n",
            "Epoch 02 [========= ] [55400/60000] > Loss: 2.248416\n",
            "Epoch 02 [========= ] [55500/60000] > Loss: 2.238339\n",
            "Epoch 02 [========= ] [55600/60000] > Loss: 2.267768\n",
            "Epoch 02 [========= ] [55700/60000] > Loss: 2.240115\n",
            "Epoch 02 [========= ] [55800/60000] > Loss: 2.243766\n",
            "Epoch 02 [========= ] [55900/60000] > Loss: 2.254189\n",
            "Epoch 02 [========= ] [56000/60000] > Loss: 2.254688\n",
            "Epoch 02 [========= ] [56100/60000] > Loss: 2.248775\n",
            "Epoch 02 [========= ] [56200/60000] > Loss: 2.260451\n",
            "Epoch 02 [========= ] [56300/60000] > Loss: 2.251330\n",
            "Epoch 02 [========= ] [56400/60000] > Loss: 2.238792\n",
            "Epoch 02 [========= ] [56500/60000] > Loss: 2.252655\n",
            "Epoch 02 [========= ] [56600/60000] > Loss: 2.249929\n",
            "Epoch 02 [========= ] [56700/60000] > Loss: 2.265578\n",
            "Epoch 02 [========= ] [56800/60000] > Loss: 2.244091\n",
            "Epoch 02 [========= ] [56900/60000] > Loss: 2.260682\n",
            "Epoch 02 [========= ] [57000/60000] > Loss: 2.261701\n",
            "Epoch 02 [========= ] [57100/60000] > Loss: 2.237851\n",
            "Epoch 02 [========= ] [57200/60000] > Loss: 2.252412\n",
            "Epoch 02 [========= ] [57300/60000] > Loss: 2.239119\n",
            "Epoch 02 [========= ] [57400/60000] > Loss: 2.246879\n",
            "Epoch 02 [========= ] [57500/60000] > Loss: 2.247750\n",
            "Epoch 02 [========= ] [57600/60000] > Loss: 2.255438\n",
            "Epoch 02 [========= ] [57700/60000] > Loss: 2.249709\n",
            "Epoch 02 [========= ] [57800/60000] > Loss: 2.248360\n",
            "Epoch 02 [========= ] [57900/60000] > Loss: 2.260317\n",
            "Epoch 02 [========= ] [58000/60000] > Loss: 2.245253\n",
            "Epoch 02 [========= ] [58100/60000] > Loss: 2.248736\n",
            "Epoch 02 [========= ] [58200/60000] > Loss: 2.264103\n",
            "Epoch 02 [========= ] [58300/60000] > Loss: 2.237243\n",
            "Epoch 02 [========= ] [58400/60000] > Loss: 2.250664\n",
            "Epoch 02 [========= ] [58500/60000] > Loss: 2.255421\n",
            "Epoch 02 [========= ] [58600/60000] > Loss: 2.248597\n",
            "Epoch 02 [========= ] [58700/60000] > Loss: 2.252490\n",
            "Epoch 02 [========= ] [58800/60000] > Loss: 2.252376\n",
            "Epoch 02 [========= ] [58900/60000] > Loss: 2.237144\n",
            "Epoch 02 [========= ] [59000/60000] > Loss: 2.245489\n",
            "Epoch 02 [========= ] [59100/60000] > Loss: 2.253716\n",
            "Epoch 02 [========= ] [59200/60000] > Loss: 2.254017\n",
            "Epoch 02 [========= ] [59300/60000] > Loss: 2.248824\n",
            "Epoch 02 [========= ] [59400/60000] > Loss: 2.260579\n",
            "Epoch 02 [========= ] [59500/60000] > Loss: 2.270756\n",
            "Epoch 02 [========= ] [59600/60000] > Loss: 2.252012\n",
            "Epoch 02 [========= ] [59700/60000] > Loss: 2.256828\n",
            "Epoch 02 [========= ] [59800/60000] > Loss: 2.255960\n",
            "Epoch 02 [========= ] [59900/60000] > Loss: 2.258976\n",
            "Epoch 02 [==========] [60000/60000] > Loss: 2.242137\n",
            "Epoch 02 [==========] [10000/10000] Time 17:43:36.257660 > Acuracia Validacao: 31.29%\n",
            "Epoch 03 [          ] [100/60000] > Loss: 2.246268\n",
            "Epoch 03 [          ] [200/60000] > Loss: 2.244076\n",
            "Epoch 03 [          ] [300/60000] > Loss: 2.255871\n",
            "Epoch 03 [          ] [400/60000] > Loss: 2.247304\n",
            "Epoch 03 [          ] [500/60000] > Loss: 2.261416\n",
            "Epoch 03 [          ] [600/60000] > Loss: 2.240878\n",
            "Epoch 03 [          ] [700/60000] > Loss: 2.242708\n",
            "Epoch 03 [          ] [800/60000] > Loss: 2.252009\n",
            "Epoch 03 [          ] [900/60000] > Loss: 2.249918\n",
            "Epoch 03 [          ] [1000/60000] > Loss: 2.247869\n",
            "Epoch 03 [          ] [1100/60000] > Loss: 2.243559\n",
            "Epoch 03 [          ] [1200/60000] > Loss: 2.233558\n",
            "Epoch 03 [          ] [1300/60000] > Loss: 2.242459\n",
            "Epoch 03 [          ] [1400/60000] > Loss: 2.240038\n",
            "Epoch 03 [          ] [1500/60000] > Loss: 2.238598\n",
            "Epoch 03 [          ] [1600/60000] > Loss: 2.251525\n",
            "Epoch 03 [          ] [1700/60000] > Loss: 2.243474\n",
            "Epoch 03 [          ] [1800/60000] > Loss: 2.246930\n",
            "Epoch 03 [          ] [1900/60000] > Loss: 2.251568\n",
            "Epoch 03 [          ] [2000/60000] > Loss: 2.243761\n",
            "Epoch 03 [          ] [2100/60000] > Loss: 2.244423\n",
            "Epoch 03 [          ] [2200/60000] > Loss: 2.249318\n",
            "Epoch 03 [          ] [2300/60000] > Loss: 2.244280\n",
            "Epoch 03 [          ] [2400/60000] > Loss: 2.247265\n",
            "Epoch 03 [          ] [2500/60000] > Loss: 2.243329\n",
            "Epoch 03 [          ] [2600/60000] > Loss: 2.255273\n",
            "Epoch 03 [          ] [2700/60000] > Loss: 2.252961\n",
            "Epoch 03 [          ] [2800/60000] > Loss: 2.240023\n",
            "Epoch 03 [          ] [2900/60000] > Loss: 2.248240\n",
            "Epoch 03 [          ] [3000/60000] > Loss: 2.241745\n",
            "Epoch 03 [          ] [3100/60000] > Loss: 2.234085\n",
            "Epoch 03 [          ] [3200/60000] > Loss: 2.250579\n",
            "Epoch 03 [          ] [3300/60000] > Loss: 2.256897\n",
            "Epoch 03 [          ] [3400/60000] > Loss: 2.249128\n",
            "Epoch 03 [          ] [3500/60000] > Loss: 2.250982\n",
            "Epoch 03 [          ] [3600/60000] > Loss: 2.241828\n",
            "Epoch 03 [          ] [3700/60000] > Loss: 2.245758\n",
            "Epoch 03 [          ] [3800/60000] > Loss: 2.246563\n",
            "Epoch 03 [          ] [3900/60000] > Loss: 2.243665\n",
            "Epoch 03 [          ] [4000/60000] > Loss: 2.237415\n",
            "Epoch 03 [          ] [4100/60000] > Loss: 2.241933\n",
            "Epoch 03 [          ] [4200/60000] > Loss: 2.239222\n",
            "Epoch 03 [          ] [4300/60000] > Loss: 2.235397\n",
            "Epoch 03 [          ] [4400/60000] > Loss: 2.243611\n",
            "Epoch 03 [          ] [4500/60000] > Loss: 2.235486\n",
            "Epoch 03 [          ] [4600/60000] > Loss: 2.248682\n",
            "Epoch 03 [          ] [4700/60000] > Loss: 2.239017\n",
            "Epoch 03 [          ] [4800/60000] > Loss: 2.230600\n",
            "Epoch 03 [          ] [4900/60000] > Loss: 2.246925\n",
            "Epoch 03 [          ] [5000/60000] > Loss: 2.226678\n",
            "Epoch 03 [          ] [5100/60000] > Loss: 2.240212\n",
            "Epoch 03 [          ] [5200/60000] > Loss: 2.247063\n",
            "Epoch 03 [          ] [5300/60000] > Loss: 2.269009\n",
            "Epoch 03 [          ] [5400/60000] > Loss: 2.250218\n",
            "Epoch 03 [          ] [5500/60000] > Loss: 2.234338\n",
            "Epoch 03 [          ] [5600/60000] > Loss: 2.250321\n",
            "Epoch 03 [          ] [5700/60000] > Loss: 2.237947\n",
            "Epoch 03 [          ] [5800/60000] > Loss: 2.239297\n",
            "Epoch 03 [          ] [5900/60000] > Loss: 2.227341\n",
            "Epoch 03 [=         ] [6000/60000] > Loss: 2.260355\n",
            "Epoch 03 [=         ] [6100/60000] > Loss: 2.254619\n",
            "Epoch 03 [=         ] [6200/60000] > Loss: 2.253208\n",
            "Epoch 03 [=         ] [6300/60000] > Loss: 2.249245\n",
            "Epoch 03 [=         ] [6400/60000] > Loss: 2.259082\n",
            "Epoch 03 [=         ] [6500/60000] > Loss: 2.236935\n",
            "Epoch 03 [=         ] [6600/60000] > Loss: 2.239145\n",
            "Epoch 03 [=         ] [6700/60000] > Loss: 2.225297\n",
            "Epoch 03 [=         ] [6800/60000] > Loss: 2.244103\n",
            "Epoch 03 [=         ] [6900/60000] > Loss: 2.243081\n",
            "Epoch 03 [=         ] [7000/60000] > Loss: 2.247442\n",
            "Epoch 03 [=         ] [7100/60000] > Loss: 2.243641\n",
            "Epoch 03 [=         ] [7200/60000] > Loss: 2.247860\n",
            "Epoch 03 [=         ] [7300/60000] > Loss: 2.254575\n",
            "Epoch 03 [=         ] [7400/60000] > Loss: 2.239480\n",
            "Epoch 03 [=         ] [7500/60000] > Loss: 2.246091\n",
            "Epoch 03 [=         ] [7600/60000] > Loss: 2.248977\n",
            "Epoch 03 [=         ] [7700/60000] > Loss: 2.249239\n",
            "Epoch 03 [=         ] [7800/60000] > Loss: 2.256162\n",
            "Epoch 03 [=         ] [7900/60000] > Loss: 2.239193\n",
            "Epoch 03 [=         ] [8000/60000] > Loss: 2.236142\n",
            "Epoch 03 [=         ] [8100/60000] > Loss: 2.243969\n",
            "Epoch 03 [=         ] [8200/60000] > Loss: 2.240613\n",
            "Epoch 03 [=         ] [8300/60000] > Loss: 2.245151\n",
            "Epoch 03 [=         ] [8400/60000] > Loss: 2.238982\n",
            "Epoch 03 [=         ] [8500/60000] > Loss: 2.246040\n",
            "Epoch 03 [=         ] [8600/60000] > Loss: 2.244019\n",
            "Epoch 03 [=         ] [8700/60000] > Loss: 2.244395\n",
            "Epoch 03 [=         ] [8800/60000] > Loss: 2.229241\n",
            "Epoch 03 [=         ] [8900/60000] > Loss: 2.245289\n",
            "Epoch 03 [=         ] [9000/60000] > Loss: 2.234521\n",
            "Epoch 03 [=         ] [9100/60000] > Loss: 2.230871\n",
            "Epoch 03 [=         ] [9200/60000] > Loss: 2.263999\n",
            "Epoch 03 [=         ] [9300/60000] > Loss: 2.243431\n",
            "Epoch 03 [=         ] [9400/60000] > Loss: 2.250512\n",
            "Epoch 03 [=         ] [9500/60000] > Loss: 2.238564\n",
            "Epoch 03 [=         ] [9600/60000] > Loss: 2.243895\n",
            "Epoch 03 [=         ] [9700/60000] > Loss: 2.248463\n",
            "Epoch 03 [=         ] [9800/60000] > Loss: 2.254615\n",
            "Epoch 03 [=         ] [9900/60000] > Loss: 2.229638\n",
            "Epoch 03 [=         ] [10000/60000] > Loss: 2.243806\n",
            "Epoch 03 [=         ] [10100/60000] > Loss: 2.254358\n",
            "Epoch 03 [=         ] [10200/60000] > Loss: 2.246114\n",
            "Epoch 03 [=         ] [10300/60000] > Loss: 2.246514\n",
            "Epoch 03 [=         ] [10400/60000] > Loss: 2.245661\n",
            "Epoch 03 [=         ] [10500/60000] > Loss: 2.244915\n",
            "Epoch 03 [=         ] [10600/60000] > Loss: 2.241880\n",
            "Epoch 03 [=         ] [10700/60000] > Loss: 2.235695\n",
            "Epoch 03 [=         ] [10800/60000] > Loss: 2.243960\n",
            "Epoch 03 [=         ] [10900/60000] > Loss: 2.242903\n",
            "Epoch 03 [=         ] [11000/60000] > Loss: 2.250223\n",
            "Epoch 03 [=         ] [11100/60000] > Loss: 2.233959\n",
            "Epoch 03 [=         ] [11200/60000] > Loss: 2.250854\n",
            "Epoch 03 [=         ] [11300/60000] > Loss: 2.242660\n",
            "Epoch 03 [=         ] [11400/60000] > Loss: 2.237237\n",
            "Epoch 03 [=         ] [11500/60000] > Loss: 2.242958\n",
            "Epoch 03 [=         ] [11600/60000] > Loss: 2.252071\n",
            "Epoch 03 [=         ] [11700/60000] > Loss: 2.246276\n",
            "Epoch 03 [=         ] [11800/60000] > Loss: 2.240165\n",
            "Epoch 03 [=         ] [11900/60000] > Loss: 2.246452\n",
            "Epoch 03 [==        ] [12000/60000] > Loss: 2.234649\n",
            "Epoch 03 [==        ] [12100/60000] > Loss: 2.258846\n",
            "Epoch 03 [==        ] [12200/60000] > Loss: 2.248679\n",
            "Epoch 03 [==        ] [12300/60000] > Loss: 2.262941\n",
            "Epoch 03 [==        ] [12400/60000] > Loss: 2.241712\n",
            "Epoch 03 [==        ] [12500/60000] > Loss: 2.248406\n",
            "Epoch 03 [==        ] [12600/60000] > Loss: 2.252885\n",
            "Epoch 03 [==        ] [12700/60000] > Loss: 2.236551\n",
            "Epoch 03 [==        ] [12800/60000] > Loss: 2.247113\n",
            "Epoch 03 [==        ] [12900/60000] > Loss: 2.246746\n",
            "Epoch 03 [==        ] [13000/60000] > Loss: 2.232052\n",
            "Epoch 03 [==        ] [13100/60000] > Loss: 2.227760\n",
            "Epoch 03 [==        ] [13200/60000] > Loss: 2.239825\n",
            "Epoch 03 [==        ] [13300/60000] > Loss: 2.220018\n",
            "Epoch 03 [==        ] [13400/60000] > Loss: 2.246883\n",
            "Epoch 03 [==        ] [13500/60000] > Loss: 2.242403\n",
            "Epoch 03 [==        ] [13600/60000] > Loss: 2.238482\n",
            "Epoch 03 [==        ] [13700/60000] > Loss: 2.250117\n",
            "Epoch 03 [==        ] [13800/60000] > Loss: 2.234347\n",
            "Epoch 03 [==        ] [13900/60000] > Loss: 2.240561\n",
            "Epoch 03 [==        ] [14000/60000] > Loss: 2.245978\n",
            "Epoch 03 [==        ] [14100/60000] > Loss: 2.228975\n",
            "Epoch 03 [==        ] [14200/60000] > Loss: 2.247048\n",
            "Epoch 03 [==        ] [14300/60000] > Loss: 2.252522\n",
            "Epoch 03 [==        ] [14400/60000] > Loss: 2.231265\n",
            "Epoch 03 [==        ] [14500/60000] > Loss: 2.252062\n",
            "Epoch 03 [==        ] [14600/60000] > Loss: 2.226947\n",
            "Epoch 03 [==        ] [14700/60000] > Loss: 2.249375\n",
            "Epoch 03 [==        ] [14800/60000] > Loss: 2.237800\n",
            "Epoch 03 [==        ] [14900/60000] > Loss: 2.241993\n",
            "Epoch 03 [==        ] [15000/60000] > Loss: 2.238728\n",
            "Epoch 03 [==        ] [15100/60000] > Loss: 2.247838\n",
            "Epoch 03 [==        ] [15200/60000] > Loss: 2.233233\n",
            "Epoch 03 [==        ] [15300/60000] > Loss: 2.231004\n",
            "Epoch 03 [==        ] [15400/60000] > Loss: 2.234838\n",
            "Epoch 03 [==        ] [15500/60000] > Loss: 2.248253\n",
            "Epoch 03 [==        ] [15600/60000] > Loss: 2.240498\n",
            "Epoch 03 [==        ] [15700/60000] > Loss: 2.246498\n",
            "Epoch 03 [==        ] [15800/60000] > Loss: 2.235200\n",
            "Epoch 03 [==        ] [15900/60000] > Loss: 2.245186\n",
            "Epoch 03 [==        ] [16000/60000] > Loss: 2.247016\n",
            "Epoch 03 [==        ] [16100/60000] > Loss: 2.248129\n",
            "Epoch 03 [==        ] [16200/60000] > Loss: 2.252656\n",
            "Epoch 03 [==        ] [16300/60000] > Loss: 2.226243\n",
            "Epoch 03 [==        ] [16400/60000] > Loss: 2.244030\n",
            "Epoch 03 [==        ] [16500/60000] > Loss: 2.225436\n",
            "Epoch 03 [==        ] [16600/60000] > Loss: 2.248296\n",
            "Epoch 03 [==        ] [16700/60000] > Loss: 2.252589\n",
            "Epoch 03 [==        ] [16800/60000] > Loss: 2.232824\n",
            "Epoch 03 [==        ] [16900/60000] > Loss: 2.233387\n",
            "Epoch 03 [==        ] [17000/60000] > Loss: 2.241406\n",
            "Epoch 03 [==        ] [17100/60000] > Loss: 2.230703\n",
            "Epoch 03 [==        ] [17200/60000] > Loss: 2.226076\n",
            "Epoch 03 [==        ] [17300/60000] > Loss: 2.235406\n",
            "Epoch 03 [==        ] [17400/60000] > Loss: 2.237056\n",
            "Epoch 03 [==        ] [17500/60000] > Loss: 2.248709\n",
            "Epoch 03 [==        ] [17600/60000] > Loss: 2.237396\n",
            "Epoch 03 [==        ] [17700/60000] > Loss: 2.234458\n",
            "Epoch 03 [==        ] [17800/60000] > Loss: 2.237061\n",
            "Epoch 03 [==        ] [17900/60000] > Loss: 2.241365\n",
            "Epoch 03 [===       ] [18000/60000] > Loss: 2.236200\n",
            "Epoch 03 [===       ] [18100/60000] > Loss: 2.253528\n",
            "Epoch 03 [===       ] [18200/60000] > Loss: 2.233371\n",
            "Epoch 03 [===       ] [18300/60000] > Loss: 2.237916\n",
            "Epoch 03 [===       ] [18400/60000] > Loss: 2.240440\n",
            "Epoch 03 [===       ] [18500/60000] > Loss: 2.242372\n",
            "Epoch 03 [===       ] [18600/60000] > Loss: 2.232528\n",
            "Epoch 03 [===       ] [18700/60000] > Loss: 2.243238\n",
            "Epoch 03 [===       ] [18800/60000] > Loss: 2.250487\n",
            "Epoch 03 [===       ] [18900/60000] > Loss: 2.246682\n",
            "Epoch 03 [===       ] [19000/60000] > Loss: 2.252488\n",
            "Epoch 03 [===       ] [19100/60000] > Loss: 2.236305\n",
            "Epoch 03 [===       ] [19200/60000] > Loss: 2.226326\n",
            "Epoch 03 [===       ] [19300/60000] > Loss: 2.227809\n",
            "Epoch 03 [===       ] [19400/60000] > Loss: 2.239484\n",
            "Epoch 03 [===       ] [19500/60000] > Loss: 2.236385\n",
            "Epoch 03 [===       ] [19600/60000] > Loss: 2.238409\n",
            "Epoch 03 [===       ] [19700/60000] > Loss: 2.245984\n",
            "Epoch 03 [===       ] [19800/60000] > Loss: 2.246352\n",
            "Epoch 03 [===       ] [19900/60000] > Loss: 2.244871\n",
            "Epoch 03 [===       ] [20000/60000] > Loss: 2.235521\n",
            "Epoch 03 [===       ] [20100/60000] > Loss: 2.246841\n",
            "Epoch 03 [===       ] [20200/60000] > Loss: 2.237733\n",
            "Epoch 03 [===       ] [20300/60000] > Loss: 2.240678\n",
            "Epoch 03 [===       ] [20400/60000] > Loss: 2.235692\n",
            "Epoch 03 [===       ] [20500/60000] > Loss: 2.226643\n",
            "Epoch 03 [===       ] [20600/60000] > Loss: 2.226456\n",
            "Epoch 03 [===       ] [20700/60000] > Loss: 2.233601\n",
            "Epoch 03 [===       ] [20800/60000] > Loss: 2.228049\n",
            "Epoch 03 [===       ] [20900/60000] > Loss: 2.232303\n",
            "Epoch 03 [===       ] [21000/60000] > Loss: 2.251462\n",
            "Epoch 03 [===       ] [21100/60000] > Loss: 2.252861\n",
            "Epoch 03 [===       ] [21200/60000] > Loss: 2.232565\n",
            "Epoch 03 [===       ] [21300/60000] > Loss: 2.247496\n",
            "Epoch 03 [===       ] [21400/60000] > Loss: 2.228472\n",
            "Epoch 03 [===       ] [21500/60000] > Loss: 2.245502\n",
            "Epoch 03 [===       ] [21600/60000] > Loss: 2.237995\n",
            "Epoch 03 [===       ] [21700/60000] > Loss: 2.238129\n",
            "Epoch 03 [===       ] [21800/60000] > Loss: 2.244037\n",
            "Epoch 03 [===       ] [21900/60000] > Loss: 2.246159\n",
            "Epoch 03 [===       ] [22000/60000] > Loss: 2.256740\n",
            "Epoch 03 [===       ] [22100/60000] > Loss: 2.238223\n",
            "Epoch 03 [===       ] [22200/60000] > Loss: 2.231999\n",
            "Epoch 03 [===       ] [22300/60000] > Loss: 2.238566\n",
            "Epoch 03 [===       ] [22400/60000] > Loss: 2.245445\n",
            "Epoch 03 [===       ] [22500/60000] > Loss: 2.235605\n",
            "Epoch 03 [===       ] [22600/60000] > Loss: 2.236823\n",
            "Epoch 03 [===       ] [22700/60000] > Loss: 2.247748\n",
            "Epoch 03 [===       ] [22800/60000] > Loss: 2.245681\n",
            "Epoch 03 [===       ] [22900/60000] > Loss: 2.242048\n",
            "Epoch 03 [===       ] [23000/60000] > Loss: 2.247504\n",
            "Epoch 03 [===       ] [23100/60000] > Loss: 2.239836\n",
            "Epoch 03 [===       ] [23200/60000] > Loss: 2.232025\n",
            "Epoch 03 [===       ] [23300/60000] > Loss: 2.236660\n",
            "Epoch 03 [===       ] [23400/60000] > Loss: 2.240506\n",
            "Epoch 03 [===       ] [23500/60000] > Loss: 2.236081\n",
            "Epoch 03 [===       ] [23600/60000] > Loss: 2.248450\n",
            "Epoch 03 [===       ] [23700/60000] > Loss: 2.241181\n",
            "Epoch 03 [===       ] [23800/60000] > Loss: 2.230823\n",
            "Epoch 03 [===       ] [23900/60000] > Loss: 2.230121\n",
            "Epoch 03 [====      ] [24000/60000] > Loss: 2.232609\n",
            "Epoch 03 [====      ] [24100/60000] > Loss: 2.232198\n",
            "Epoch 03 [====      ] [24200/60000] > Loss: 2.229422\n",
            "Epoch 03 [====      ] [24300/60000] > Loss: 2.239159\n",
            "Epoch 03 [====      ] [24400/60000] > Loss: 2.249402\n",
            "Epoch 03 [====      ] [24500/60000] > Loss: 2.239196\n",
            "Epoch 03 [====      ] [24600/60000] > Loss: 2.242115\n",
            "Epoch 03 [====      ] [24700/60000] > Loss: 2.243882\n",
            "Epoch 03 [====      ] [24800/60000] > Loss: 2.222126\n",
            "Epoch 03 [====      ] [24900/60000] > Loss: 2.237732\n",
            "Epoch 03 [====      ] [25000/60000] > Loss: 2.240821\n",
            "Epoch 03 [====      ] [25100/60000] > Loss: 2.229635\n",
            "Epoch 03 [====      ] [25200/60000] > Loss: 2.254479\n",
            "Epoch 03 [====      ] [25300/60000] > Loss: 2.234869\n",
            "Epoch 03 [====      ] [25400/60000] > Loss: 2.232221\n",
            "Epoch 03 [====      ] [25500/60000] > Loss: 2.228158\n",
            "Epoch 03 [====      ] [25600/60000] > Loss: 2.241805\n",
            "Epoch 03 [====      ] [25700/60000] > Loss: 2.232242\n",
            "Epoch 03 [====      ] [25800/60000] > Loss: 2.244873\n",
            "Epoch 03 [====      ] [25900/60000] > Loss: 2.233573\n",
            "Epoch 03 [====      ] [26000/60000] > Loss: 2.223598\n",
            "Epoch 03 [====      ] [26100/60000] > Loss: 2.225820\n",
            "Epoch 03 [====      ] [26200/60000] > Loss: 2.245630\n",
            "Epoch 03 [====      ] [26300/60000] > Loss: 2.232684\n",
            "Epoch 03 [====      ] [26400/60000] > Loss: 2.227604\n",
            "Epoch 03 [====      ] [26500/60000] > Loss: 2.224372\n",
            "Epoch 03 [====      ] [26600/60000] > Loss: 2.233522\n",
            "Epoch 03 [====      ] [26700/60000] > Loss: 2.245051\n",
            "Epoch 03 [====      ] [26800/60000] > Loss: 2.244142\n",
            "Epoch 03 [====      ] [26900/60000] > Loss: 2.236323\n",
            "Epoch 03 [====      ] [27000/60000] > Loss: 2.227948\n",
            "Epoch 03 [====      ] [27100/60000] > Loss: 2.231144\n",
            "Epoch 03 [====      ] [27200/60000] > Loss: 2.235431\n",
            "Epoch 03 [====      ] [27300/60000] > Loss: 2.245672\n",
            "Epoch 03 [====      ] [27400/60000] > Loss: 2.235817\n",
            "Epoch 03 [====      ] [27500/60000] > Loss: 2.236744\n",
            "Epoch 03 [====      ] [27600/60000] > Loss: 2.237201\n",
            "Epoch 03 [====      ] [27700/60000] > Loss: 2.239109\n",
            "Epoch 03 [====      ] [27800/60000] > Loss: 2.227665\n",
            "Epoch 03 [====      ] [27900/60000] > Loss: 2.229708\n",
            "Epoch 03 [====      ] [28000/60000] > Loss: 2.245366\n",
            "Epoch 03 [====      ] [28100/60000] > Loss: 2.244964\n",
            "Epoch 03 [====      ] [28200/60000] > Loss: 2.236409\n",
            "Epoch 03 [====      ] [28300/60000] > Loss: 2.228509\n",
            "Epoch 03 [====      ] [28400/60000] > Loss: 2.241242\n",
            "Epoch 03 [====      ] [28500/60000] > Loss: 2.237478\n",
            "Epoch 03 [====      ] [28600/60000] > Loss: 2.240780\n",
            "Epoch 03 [====      ] [28700/60000] > Loss: 2.239894\n",
            "Epoch 03 [====      ] [28800/60000] > Loss: 2.231761\n",
            "Epoch 03 [====      ] [28900/60000] > Loss: 2.217079\n",
            "Epoch 03 [====      ] [29000/60000] > Loss: 2.234347\n",
            "Epoch 03 [====      ] [29100/60000] > Loss: 2.237458\n",
            "Epoch 03 [====      ] [29200/60000] > Loss: 2.230087\n",
            "Epoch 03 [====      ] [29300/60000] > Loss: 2.235155\n",
            "Epoch 03 [====      ] [29400/60000] > Loss: 2.236615\n",
            "Epoch 03 [====      ] [29500/60000] > Loss: 2.223672\n",
            "Epoch 03 [====      ] [29600/60000] > Loss: 2.234684\n",
            "Epoch 03 [====      ] [29700/60000] > Loss: 2.228282\n",
            "Epoch 03 [====      ] [29800/60000] > Loss: 2.218317\n",
            "Epoch 03 [====      ] [29900/60000] > Loss: 2.232711\n",
            "Epoch 03 [=====     ] [30000/60000] > Loss: 2.229973\n",
            "Epoch 03 [=====     ] [30100/60000] > Loss: 2.229927\n",
            "Epoch 03 [=====     ] [30200/60000] > Loss: 2.216368\n",
            "Epoch 03 [=====     ] [30300/60000] > Loss: 2.226239\n",
            "Epoch 03 [=====     ] [30400/60000] > Loss: 2.245649\n",
            "Epoch 03 [=====     ] [30500/60000] > Loss: 2.230662\n",
            "Epoch 03 [=====     ] [30600/60000] > Loss: 2.242345\n",
            "Epoch 03 [=====     ] [30700/60000] > Loss: 2.225213\n",
            "Epoch 03 [=====     ] [30800/60000] > Loss: 2.260936\n",
            "Epoch 03 [=====     ] [30900/60000] > Loss: 2.235663\n",
            "Epoch 03 [=====     ] [31000/60000] > Loss: 2.230120\n",
            "Epoch 03 [=====     ] [31100/60000] > Loss: 2.226824\n",
            "Epoch 03 [=====     ] [31200/60000] > Loss: 2.236079\n",
            "Epoch 03 [=====     ] [31300/60000] > Loss: 2.225649\n",
            "Epoch 03 [=====     ] [31400/60000] > Loss: 2.245813\n",
            "Epoch 03 [=====     ] [31500/60000] > Loss: 2.220123\n",
            "Epoch 03 [=====     ] [31600/60000] > Loss: 2.228352\n",
            "Epoch 03 [=====     ] [31700/60000] > Loss: 2.247159\n",
            "Epoch 03 [=====     ] [31800/60000] > Loss: 2.235791\n",
            "Epoch 03 [=====     ] [31900/60000] > Loss: 2.228200\n",
            "Epoch 03 [=====     ] [32000/60000] > Loss: 2.239303\n",
            "Epoch 03 [=====     ] [32100/60000] > Loss: 2.235226\n",
            "Epoch 03 [=====     ] [32200/60000] > Loss: 2.240372\n",
            "Epoch 03 [=====     ] [32300/60000] > Loss: 2.227280\n",
            "Epoch 03 [=====     ] [32400/60000] > Loss: 2.240588\n",
            "Epoch 03 [=====     ] [32500/60000] > Loss: 2.228147\n",
            "Epoch 03 [=====     ] [32600/60000] > Loss: 2.232953\n",
            "Epoch 03 [=====     ] [32700/60000] > Loss: 2.224888\n",
            "Epoch 03 [=====     ] [32800/60000] > Loss: 2.235415\n",
            "Epoch 03 [=====     ] [32900/60000] > Loss: 2.232254\n",
            "Epoch 03 [=====     ] [33000/60000] > Loss: 2.239489\n",
            "Epoch 03 [=====     ] [33100/60000] > Loss: 2.224941\n",
            "Epoch 03 [=====     ] [33200/60000] > Loss: 2.228700\n",
            "Epoch 03 [=====     ] [33300/60000] > Loss: 2.222323\n",
            "Epoch 03 [=====     ] [33400/60000] > Loss: 2.239287\n",
            "Epoch 03 [=====     ] [33500/60000] > Loss: 2.224755\n",
            "Epoch 03 [=====     ] [33600/60000] > Loss: 2.231613\n",
            "Epoch 03 [=====     ] [33700/60000] > Loss: 2.229825\n",
            "Epoch 03 [=====     ] [33800/60000] > Loss: 2.236753\n",
            "Epoch 03 [=====     ] [33900/60000] > Loss: 2.222361\n",
            "Epoch 03 [=====     ] [34000/60000] > Loss: 2.244712\n",
            "Epoch 03 [=====     ] [34100/60000] > Loss: 2.235384\n",
            "Epoch 03 [=====     ] [34200/60000] > Loss: 2.233131\n",
            "Epoch 03 [=====     ] [34300/60000] > Loss: 2.224932\n",
            "Epoch 03 [=====     ] [34400/60000] > Loss: 2.239661\n",
            "Epoch 03 [=====     ] [34500/60000] > Loss: 2.254138\n",
            "Epoch 03 [=====     ] [34600/60000] > Loss: 2.228830\n",
            "Epoch 03 [=====     ] [34700/60000] > Loss: 2.235129\n",
            "Epoch 03 [=====     ] [34800/60000] > Loss: 2.229200\n",
            "Epoch 03 [=====     ] [34900/60000] > Loss: 2.220857\n",
            "Epoch 03 [=====     ] [35000/60000] > Loss: 2.232887\n",
            "Epoch 03 [=====     ] [35100/60000] > Loss: 2.240531\n",
            "Epoch 03 [=====     ] [35200/60000] > Loss: 2.230688\n",
            "Epoch 03 [=====     ] [35300/60000] > Loss: 2.238432\n",
            "Epoch 03 [=====     ] [35400/60000] > Loss: 2.236421\n",
            "Epoch 03 [=====     ] [35500/60000] > Loss: 2.225681\n",
            "Epoch 03 [=====     ] [35600/60000] > Loss: 2.230304\n",
            "Epoch 03 [=====     ] [35700/60000] > Loss: 2.224253\n",
            "Epoch 03 [=====     ] [35800/60000] > Loss: 2.233102\n",
            "Epoch 03 [=====     ] [35900/60000] > Loss: 2.230499\n",
            "Epoch 03 [======    ] [36000/60000] > Loss: 2.225143\n",
            "Epoch 03 [======    ] [36100/60000] > Loss: 2.224834\n",
            "Epoch 03 [======    ] [36200/60000] > Loss: 2.229624\n",
            "Epoch 03 [======    ] [36300/60000] > Loss: 2.226606\n",
            "Epoch 03 [======    ] [36400/60000] > Loss: 2.224935\n",
            "Epoch 03 [======    ] [36500/60000] > Loss: 2.232281\n",
            "Epoch 03 [======    ] [36600/60000] > Loss: 2.232592\n",
            "Epoch 03 [======    ] [36700/60000] > Loss: 2.219003\n",
            "Epoch 03 [======    ] [36800/60000] > Loss: 2.214899\n",
            "Epoch 03 [======    ] [36900/60000] > Loss: 2.216228\n",
            "Epoch 03 [======    ] [37000/60000] > Loss: 2.238880\n",
            "Epoch 03 [======    ] [37100/60000] > Loss: 2.236758\n",
            "Epoch 03 [======    ] [37200/60000] > Loss: 2.225448\n",
            "Epoch 03 [======    ] [37300/60000] > Loss: 2.234094\n",
            "Epoch 03 [======    ] [37400/60000] > Loss: 2.227456\n",
            "Epoch 03 [======    ] [37500/60000] > Loss: 2.230892\n",
            "Epoch 03 [======    ] [37600/60000] > Loss: 2.226222\n",
            "Epoch 03 [======    ] [37700/60000] > Loss: 2.218814\n",
            "Epoch 03 [======    ] [37800/60000] > Loss: 2.213150\n",
            "Epoch 03 [======    ] [37900/60000] > Loss: 2.219165\n",
            "Epoch 03 [======    ] [38000/60000] > Loss: 2.237312\n",
            "Epoch 03 [======    ] [38100/60000] > Loss: 2.233140\n",
            "Epoch 03 [======    ] [38200/60000] > Loss: 2.230919\n",
            "Epoch 03 [======    ] [38300/60000] > Loss: 2.227171\n",
            "Epoch 03 [======    ] [38400/60000] > Loss: 2.234961\n",
            "Epoch 03 [======    ] [38500/60000] > Loss: 2.224089\n",
            "Epoch 03 [======    ] [38600/60000] > Loss: 2.227328\n",
            "Epoch 03 [======    ] [38700/60000] > Loss: 2.222507\n",
            "Epoch 03 [======    ] [38800/60000] > Loss: 2.225795\n",
            "Epoch 03 [======    ] [38900/60000] > Loss: 2.215509\n",
            "Epoch 03 [======    ] [39000/60000] > Loss: 2.230464\n",
            "Epoch 03 [======    ] [39100/60000] > Loss: 2.212779\n",
            "Epoch 03 [======    ] [39200/60000] > Loss: 2.236946\n",
            "Epoch 03 [======    ] [39300/60000] > Loss: 2.223246\n",
            "Epoch 03 [======    ] [39400/60000] > Loss: 2.218006\n",
            "Epoch 03 [======    ] [39500/60000] > Loss: 2.225129\n",
            "Epoch 03 [======    ] [39600/60000] > Loss: 2.223635\n",
            "Epoch 03 [======    ] [39700/60000] > Loss: 2.232342\n",
            "Epoch 03 [======    ] [39800/60000] > Loss: 2.234289\n",
            "Epoch 03 [======    ] [39900/60000] > Loss: 2.231970\n",
            "Epoch 03 [======    ] [40000/60000] > Loss: 2.230502\n",
            "Epoch 03 [======    ] [40100/60000] > Loss: 2.213520\n",
            "Epoch 03 [======    ] [40200/60000] > Loss: 2.223084\n",
            "Epoch 03 [======    ] [40300/60000] > Loss: 2.220240\n",
            "Epoch 03 [======    ] [40400/60000] > Loss: 2.232504\n",
            "Epoch 03 [======    ] [40500/60000] > Loss: 2.237763\n",
            "Epoch 03 [======    ] [40600/60000] > Loss: 2.214762\n",
            "Epoch 03 [======    ] [40700/60000] > Loss: 2.224039\n",
            "Epoch 03 [======    ] [40800/60000] > Loss: 2.228139\n",
            "Epoch 03 [======    ] [40900/60000] > Loss: 2.232181\n",
            "Epoch 03 [======    ] [41000/60000] > Loss: 2.241723\n",
            "Epoch 03 [======    ] [41100/60000] > Loss: 2.244220\n",
            "Epoch 03 [======    ] [41200/60000] > Loss: 2.229566\n",
            "Epoch 03 [======    ] [41300/60000] > Loss: 2.228771\n",
            "Epoch 03 [======    ] [41400/60000] > Loss: 2.222352\n",
            "Epoch 03 [======    ] [41500/60000] > Loss: 2.220798\n",
            "Epoch 03 [======    ] [41600/60000] > Loss: 2.239022\n",
            "Epoch 03 [======    ] [41700/60000] > Loss: 2.199704\n",
            "Epoch 03 [======    ] [41800/60000] > Loss: 2.218302\n",
            "Epoch 03 [======    ] [41900/60000] > Loss: 2.221840\n",
            "Epoch 03 [=======   ] [42000/60000] > Loss: 2.234546\n",
            "Epoch 03 [=======   ] [42100/60000] > Loss: 2.224552\n",
            "Epoch 03 [=======   ] [42200/60000] > Loss: 2.222689\n",
            "Epoch 03 [=======   ] [42300/60000] > Loss: 2.228030\n",
            "Epoch 03 [=======   ] [42400/60000] > Loss: 2.211708\n",
            "Epoch 03 [=======   ] [42500/60000] > Loss: 2.219517\n",
            "Epoch 03 [=======   ] [42600/60000] > Loss: 2.235601\n",
            "Epoch 03 [=======   ] [42700/60000] > Loss: 2.232630\n",
            "Epoch 03 [=======   ] [42800/60000] > Loss: 2.227247\n",
            "Epoch 03 [=======   ] [42900/60000] > Loss: 2.233163\n",
            "Epoch 03 [=======   ] [43000/60000] > Loss: 2.221409\n",
            "Epoch 03 [=======   ] [43100/60000] > Loss: 2.225050\n",
            "Epoch 03 [=======   ] [43200/60000] > Loss: 2.220199\n",
            "Epoch 03 [=======   ] [43300/60000] > Loss: 2.212709\n",
            "Epoch 03 [=======   ] [43400/60000] > Loss: 2.226364\n",
            "Epoch 03 [=======   ] [43500/60000] > Loss: 2.225422\n",
            "Epoch 03 [=======   ] [43600/60000] > Loss: 2.221642\n",
            "Epoch 03 [=======   ] [43700/60000] > Loss: 2.216170\n",
            "Epoch 03 [=======   ] [43800/60000] > Loss: 2.223815\n",
            "Epoch 03 [=======   ] [43900/60000] > Loss: 2.234856\n",
            "Epoch 03 [=======   ] [44000/60000] > Loss: 2.240954\n",
            "Epoch 03 [=======   ] [44100/60000] > Loss: 2.222740\n",
            "Epoch 03 [=======   ] [44200/60000] > Loss: 2.231060\n",
            "Epoch 03 [=======   ] [44300/60000] > Loss: 2.198759\n",
            "Epoch 03 [=======   ] [44400/60000] > Loss: 2.222400\n",
            "Epoch 03 [=======   ] [44500/60000] > Loss: 2.235034\n",
            "Epoch 03 [=======   ] [44600/60000] > Loss: 2.230490\n",
            "Epoch 03 [=======   ] [44700/60000] > Loss: 2.220308\n",
            "Epoch 03 [=======   ] [44800/60000] > Loss: 2.219365\n",
            "Epoch 03 [=======   ] [44900/60000] > Loss: 2.234311\n",
            "Epoch 03 [=======   ] [45000/60000] > Loss: 2.219923\n",
            "Epoch 03 [=======   ] [45100/60000] > Loss: 2.220488\n",
            "Epoch 03 [=======   ] [45200/60000] > Loss: 2.206220\n",
            "Epoch 03 [=======   ] [45300/60000] > Loss: 2.234804\n",
            "Epoch 03 [=======   ] [45400/60000] > Loss: 2.216226\n",
            "Epoch 03 [=======   ] [45500/60000] > Loss: 2.241576\n",
            "Epoch 03 [=======   ] [45600/60000] > Loss: 2.232250\n",
            "Epoch 03 [=======   ] [45700/60000] > Loss: 2.230866\n",
            "Epoch 03 [=======   ] [45800/60000] > Loss: 2.235863\n",
            "Epoch 03 [=======   ] [45900/60000] > Loss: 2.228022\n",
            "Epoch 03 [=======   ] [46000/60000] > Loss: 2.220422\n",
            "Epoch 03 [=======   ] [46100/60000] > Loss: 2.225566\n",
            "Epoch 03 [=======   ] [46200/60000] > Loss: 2.225947\n",
            "Epoch 03 [=======   ] [46300/60000] > Loss: 2.254835\n",
            "Epoch 03 [=======   ] [46400/60000] > Loss: 2.209139\n",
            "Epoch 03 [=======   ] [46500/60000] > Loss: 2.231130\n",
            "Epoch 03 [=======   ] [46600/60000] > Loss: 2.215738\n",
            "Epoch 03 [=======   ] [46700/60000] > Loss: 2.238317\n",
            "Epoch 03 [=======   ] [46800/60000] > Loss: 2.201801\n",
            "Epoch 03 [=======   ] [46900/60000] > Loss: 2.231743\n",
            "Epoch 03 [=======   ] [47000/60000] > Loss: 2.233560\n",
            "Epoch 03 [=======   ] [47100/60000] > Loss: 2.221916\n",
            "Epoch 03 [=======   ] [47200/60000] > Loss: 2.226927\n",
            "Epoch 03 [=======   ] [47300/60000] > Loss: 2.213214\n",
            "Epoch 03 [=======   ] [47400/60000] > Loss: 2.212380\n",
            "Epoch 03 [=======   ] [47500/60000] > Loss: 2.223641\n",
            "Epoch 03 [=======   ] [47600/60000] > Loss: 2.219499\n",
            "Epoch 03 [=======   ] [47700/60000] > Loss: 2.225096\n",
            "Epoch 03 [=======   ] [47800/60000] > Loss: 2.205892\n",
            "Epoch 03 [=======   ] [47900/60000] > Loss: 2.223681\n",
            "Epoch 03 [========  ] [48000/60000] > Loss: 2.203668\n",
            "Epoch 03 [========  ] [48100/60000] > Loss: 2.221359\n",
            "Epoch 03 [========  ] [48200/60000] > Loss: 2.225212\n",
            "Epoch 03 [========  ] [48300/60000] > Loss: 2.219145\n",
            "Epoch 03 [========  ] [48400/60000] > Loss: 2.225918\n",
            "Epoch 03 [========  ] [48500/60000] > Loss: 2.236401\n",
            "Epoch 03 [========  ] [48600/60000] > Loss: 2.223457\n",
            "Epoch 03 [========  ] [48700/60000] > Loss: 2.221186\n",
            "Epoch 03 [========  ] [48800/60000] > Loss: 2.206257\n",
            "Epoch 03 [========  ] [48900/60000] > Loss: 2.219794\n",
            "Epoch 03 [========  ] [49000/60000] > Loss: 2.223219\n",
            "Epoch 03 [========  ] [49100/60000] > Loss: 2.211872\n",
            "Epoch 03 [========  ] [49200/60000] > Loss: 2.223949\n",
            "Epoch 03 [========  ] [49300/60000] > Loss: 2.230776\n",
            "Epoch 03 [========  ] [49400/60000] > Loss: 2.223752\n",
            "Epoch 03 [========  ] [49500/60000] > Loss: 2.217322\n",
            "Epoch 03 [========  ] [49600/60000] > Loss: 2.214666\n",
            "Epoch 03 [========  ] [49700/60000] > Loss: 2.229213\n",
            "Epoch 03 [========  ] [49800/60000] > Loss: 2.230576\n",
            "Epoch 03 [========  ] [49900/60000] > Loss: 2.212882\n",
            "Epoch 03 [========  ] [50000/60000] > Loss: 2.210734\n",
            "Epoch 03 [========  ] [50100/60000] > Loss: 2.225688\n",
            "Epoch 03 [========  ] [50200/60000] > Loss: 2.236068\n",
            "Epoch 03 [========  ] [50300/60000] > Loss: 2.212130\n",
            "Epoch 03 [========  ] [50400/60000] > Loss: 2.218176\n",
            "Epoch 03 [========  ] [50500/60000] > Loss: 2.233085\n",
            "Epoch 03 [========  ] [50600/60000] > Loss: 2.234933\n",
            "Epoch 03 [========  ] [50700/60000] > Loss: 2.219336\n",
            "Epoch 03 [========  ] [50800/60000] > Loss: 2.220975\n",
            "Epoch 03 [========  ] [50900/60000] > Loss: 2.212974\n",
            "Epoch 03 [========  ] [51000/60000] > Loss: 2.235083\n",
            "Epoch 03 [========  ] [51100/60000] > Loss: 2.241262\n",
            "Epoch 03 [========  ] [51200/60000] > Loss: 2.217023\n",
            "Epoch 03 [========  ] [51300/60000] > Loss: 2.248861\n",
            "Epoch 03 [========  ] [51400/60000] > Loss: 2.213053\n",
            "Epoch 03 [========  ] [51500/60000] > Loss: 2.217882\n",
            "Epoch 03 [========  ] [51600/60000] > Loss: 2.238733\n",
            "Epoch 03 [========  ] [51700/60000] > Loss: 2.203862\n",
            "Epoch 03 [========  ] [51800/60000] > Loss: 2.237970\n",
            "Epoch 03 [========  ] [51900/60000] > Loss: 2.208730\n",
            "Epoch 03 [========  ] [52000/60000] > Loss: 2.213638\n",
            "Epoch 03 [========  ] [52100/60000] > Loss: 2.215300\n",
            "Epoch 03 [========  ] [52200/60000] > Loss: 2.222650\n",
            "Epoch 03 [========  ] [52300/60000] > Loss: 2.234015\n",
            "Epoch 03 [========  ] [52400/60000] > Loss: 2.224630\n",
            "Epoch 03 [========  ] [52500/60000] > Loss: 2.216767\n",
            "Epoch 03 [========  ] [52600/60000] > Loss: 2.218194\n",
            "Epoch 03 [========  ] [52700/60000] > Loss: 2.217218\n",
            "Epoch 03 [========  ] [52800/60000] > Loss: 2.231294\n",
            "Epoch 03 [========  ] [52900/60000] > Loss: 2.211108\n",
            "Epoch 03 [========  ] [53000/60000] > Loss: 2.232276\n",
            "Epoch 03 [========  ] [53100/60000] > Loss: 2.217302\n",
            "Epoch 03 [========  ] [53200/60000] > Loss: 2.226100\n",
            "Epoch 03 [========  ] [53300/60000] > Loss: 2.212628\n",
            "Epoch 03 [========  ] [53400/60000] > Loss: 2.210179\n",
            "Epoch 03 [========  ] [53500/60000] > Loss: 2.233906\n",
            "Epoch 03 [========  ] [53600/60000] > Loss: 2.208040\n",
            "Epoch 03 [========  ] [53700/60000] > Loss: 2.228777\n",
            "Epoch 03 [========  ] [53800/60000] > Loss: 2.231937\n",
            "Epoch 03 [========  ] [53900/60000] > Loss: 2.213088\n",
            "Epoch 03 [========= ] [54000/60000] > Loss: 2.225792\n",
            "Epoch 03 [========= ] [54100/60000] > Loss: 2.229277\n",
            "Epoch 03 [========= ] [54200/60000] > Loss: 2.235838\n",
            "Epoch 03 [========= ] [54300/60000] > Loss: 2.224811\n",
            "Epoch 03 [========= ] [54400/60000] > Loss: 2.231657\n",
            "Epoch 03 [========= ] [54500/60000] > Loss: 2.232929\n",
            "Epoch 03 [========= ] [54600/60000] > Loss: 2.233125\n",
            "Epoch 03 [========= ] [54700/60000] > Loss: 2.225935\n",
            "Epoch 03 [========= ] [54800/60000] > Loss: 2.204254\n",
            "Epoch 03 [========= ] [54900/60000] > Loss: 2.210646\n",
            "Epoch 03 [========= ] [55000/60000] > Loss: 2.204833\n",
            "Epoch 03 [========= ] [55100/60000] > Loss: 2.199452\n",
            "Epoch 03 [========= ] [55200/60000] > Loss: 2.246405\n",
            "Epoch 03 [========= ] [55300/60000] > Loss: 2.227988\n",
            "Epoch 03 [========= ] [55400/60000] > Loss: 2.217223\n",
            "Epoch 03 [========= ] [55500/60000] > Loss: 2.223197\n",
            "Epoch 03 [========= ] [55600/60000] > Loss: 2.210846\n",
            "Epoch 03 [========= ] [55700/60000] > Loss: 2.221379\n",
            "Epoch 03 [========= ] [55800/60000] > Loss: 2.223803\n",
            "Epoch 03 [========= ] [55900/60000] > Loss: 2.213691\n",
            "Epoch 03 [========= ] [56000/60000] > Loss: 2.207805\n",
            "Epoch 03 [========= ] [56100/60000] > Loss: 2.221503\n",
            "Epoch 03 [========= ] [56200/60000] > Loss: 2.223526\n",
            "Epoch 03 [========= ] [56300/60000] > Loss: 2.229284\n",
            "Epoch 03 [========= ] [56400/60000] > Loss: 2.214337\n",
            "Epoch 03 [========= ] [56500/60000] > Loss: 2.214415\n",
            "Epoch 03 [========= ] [56600/60000] > Loss: 2.222775\n",
            "Epoch 03 [========= ] [56700/60000] > Loss: 2.221308\n",
            "Epoch 03 [========= ] [56800/60000] > Loss: 2.238469\n",
            "Epoch 03 [========= ] [56900/60000] > Loss: 2.224499\n",
            "Epoch 03 [========= ] [57000/60000] > Loss: 2.226951\n",
            "Epoch 03 [========= ] [57100/60000] > Loss: 2.218279\n",
            "Epoch 03 [========= ] [57200/60000] > Loss: 2.226118\n",
            "Epoch 03 [========= ] [57300/60000] > Loss: 2.219332\n",
            "Epoch 03 [========= ] [57400/60000] > Loss: 2.222937\n",
            "Epoch 03 [========= ] [57500/60000] > Loss: 2.214061\n",
            "Epoch 03 [========= ] [57600/60000] > Loss: 2.219113\n",
            "Epoch 03 [========= ] [57700/60000] > Loss: 2.224348\n",
            "Epoch 03 [========= ] [57800/60000] > Loss: 2.243464\n",
            "Epoch 03 [========= ] [57900/60000] > Loss: 2.212151\n",
            "Epoch 03 [========= ] [58000/60000] > Loss: 2.218355\n",
            "Epoch 03 [========= ] [58100/60000] > Loss: 2.211906\n",
            "Epoch 03 [========= ] [58200/60000] > Loss: 2.235037\n",
            "Epoch 03 [========= ] [58300/60000] > Loss: 2.225067\n",
            "Epoch 03 [========= ] [58400/60000] > Loss: 2.212764\n",
            "Epoch 03 [========= ] [58500/60000] > Loss: 2.225019\n",
            "Epoch 03 [========= ] [58600/60000] > Loss: 2.214007\n",
            "Epoch 03 [========= ] [58700/60000] > Loss: 2.220824\n",
            "Epoch 03 [========= ] [58800/60000] > Loss: 2.208789\n",
            "Epoch 03 [========= ] [58900/60000] > Loss: 2.223302\n",
            "Epoch 03 [========= ] [59000/60000] > Loss: 2.217536\n",
            "Epoch 03 [========= ] [59100/60000] > Loss: 2.213283\n",
            "Epoch 03 [========= ] [59200/60000] > Loss: 2.214355\n",
            "Epoch 03 [========= ] [59300/60000] > Loss: 2.217197\n",
            "Epoch 03 [========= ] [59400/60000] > Loss: 2.224353\n",
            "Epoch 03 [========= ] [59500/60000] > Loss: 2.216631\n",
            "Epoch 03 [========= ] [59600/60000] > Loss: 2.196976\n",
            "Epoch 03 [========= ] [59700/60000] > Loss: 2.215092\n",
            "Epoch 03 [========= ] [59800/60000] > Loss: 2.211724\n",
            "Epoch 03 [========= ] [59900/60000] > Loss: 2.216605\n",
            "Epoch 03 [==========] [60000/60000] > Loss: 2.220390\n",
            "Epoch 03 [==========] [10000/10000] Time 17:43:41.285778 > Acuracia Validacao: 45.76%\n",
            "Epoch 04 [          ] [100/60000] > Loss: 2.225772\n",
            "Epoch 04 [          ] [200/60000] > Loss: 2.213431\n",
            "Epoch 04 [          ] [300/60000] > Loss: 2.227532\n",
            "Epoch 04 [          ] [400/60000] > Loss: 2.210985\n",
            "Epoch 04 [          ] [500/60000] > Loss: 2.211161\n",
            "Epoch 04 [          ] [600/60000] > Loss: 2.221748\n",
            "Epoch 04 [          ] [700/60000] > Loss: 2.207286\n",
            "Epoch 04 [          ] [800/60000] > Loss: 2.210879\n",
            "Epoch 04 [          ] [900/60000] > Loss: 2.205664\n",
            "Epoch 04 [          ] [1000/60000] > Loss: 2.221073\n",
            "Epoch 04 [          ] [1100/60000] > Loss: 2.220778\n",
            "Epoch 04 [          ] [1200/60000] > Loss: 2.220182\n",
            "Epoch 04 [          ] [1300/60000] > Loss: 2.215069\n",
            "Epoch 04 [          ] [1400/60000] > Loss: 2.222673\n",
            "Epoch 04 [          ] [1500/60000] > Loss: 2.212725\n",
            "Epoch 04 [          ] [1600/60000] > Loss: 2.226552\n",
            "Epoch 04 [          ] [1700/60000] > Loss: 2.226078\n",
            "Epoch 04 [          ] [1800/60000] > Loss: 2.215428\n",
            "Epoch 04 [          ] [1900/60000] > Loss: 2.224434\n",
            "Epoch 04 [          ] [2000/60000] > Loss: 2.226617\n",
            "Epoch 04 [          ] [2100/60000] > Loss: 2.212035\n",
            "Epoch 04 [          ] [2200/60000] > Loss: 2.208318\n",
            "Epoch 04 [          ] [2300/60000] > Loss: 2.224808\n",
            "Epoch 04 [          ] [2400/60000] > Loss: 2.227580\n",
            "Epoch 04 [          ] [2500/60000] > Loss: 2.207975\n",
            "Epoch 04 [          ] [2600/60000] > Loss: 2.226564\n",
            "Epoch 04 [          ] [2700/60000] > Loss: 2.217704\n",
            "Epoch 04 [          ] [2800/60000] > Loss: 2.205498\n",
            "Epoch 04 [          ] [2900/60000] > Loss: 2.203172\n",
            "Epoch 04 [          ] [3000/60000] > Loss: 2.230599\n",
            "Epoch 04 [          ] [3100/60000] > Loss: 2.219294\n",
            "Epoch 04 [          ] [3200/60000] > Loss: 2.215380\n",
            "Epoch 04 [          ] [3300/60000] > Loss: 2.220028\n",
            "Epoch 04 [          ] [3400/60000] > Loss: 2.226180\n",
            "Epoch 04 [          ] [3500/60000] > Loss: 2.200591\n",
            "Epoch 04 [          ] [3600/60000] > Loss: 2.204918\n",
            "Epoch 04 [          ] [3700/60000] > Loss: 2.221538\n",
            "Epoch 04 [          ] [3800/60000] > Loss: 2.218734\n",
            "Epoch 04 [          ] [3900/60000] > Loss: 2.202107\n",
            "Epoch 04 [          ] [4000/60000] > Loss: 2.201099\n",
            "Epoch 04 [          ] [4100/60000] > Loss: 2.214681\n",
            "Epoch 04 [          ] [4200/60000] > Loss: 2.205083\n",
            "Epoch 04 [          ] [4300/60000] > Loss: 2.219055\n",
            "Epoch 04 [          ] [4400/60000] > Loss: 2.200954\n",
            "Epoch 04 [          ] [4500/60000] > Loss: 2.219902\n",
            "Epoch 04 [          ] [4600/60000] > Loss: 2.218277\n",
            "Epoch 04 [          ] [4700/60000] > Loss: 2.198648\n",
            "Epoch 04 [          ] [4800/60000] > Loss: 2.207686\n",
            "Epoch 04 [          ] [4900/60000] > Loss: 2.199110\n",
            "Epoch 04 [          ] [5000/60000] > Loss: 2.221083\n",
            "Epoch 04 [          ] [5100/60000] > Loss: 2.214635\n",
            "Epoch 04 [          ] [5200/60000] > Loss: 2.220250\n",
            "Epoch 04 [          ] [5300/60000] > Loss: 2.195010\n",
            "Epoch 04 [          ] [5400/60000] > Loss: 2.209672\n",
            "Epoch 04 [          ] [5500/60000] > Loss: 2.222862\n",
            "Epoch 04 [          ] [5600/60000] > Loss: 2.230320\n",
            "Epoch 04 [          ] [5700/60000] > Loss: 2.213565\n",
            "Epoch 04 [          ] [5800/60000] > Loss: 2.220510\n",
            "Epoch 04 [          ] [5900/60000] > Loss: 2.216196\n",
            "Epoch 04 [=         ] [6000/60000] > Loss: 2.211968\n",
            "Epoch 04 [=         ] [6100/60000] > Loss: 2.214641\n",
            "Epoch 04 [=         ] [6200/60000] > Loss: 2.212711\n",
            "Epoch 04 [=         ] [6300/60000] > Loss: 2.203435\n",
            "Epoch 04 [=         ] [6400/60000] > Loss: 2.219733\n",
            "Epoch 04 [=         ] [6500/60000] > Loss: 2.205701\n",
            "Epoch 04 [=         ] [6600/60000] > Loss: 2.206460\n",
            "Epoch 04 [=         ] [6700/60000] > Loss: 2.205313\n",
            "Epoch 04 [=         ] [6800/60000] > Loss: 2.196834\n",
            "Epoch 04 [=         ] [6900/60000] > Loss: 2.226296\n",
            "Epoch 04 [=         ] [7000/60000] > Loss: 2.201681\n",
            "Epoch 04 [=         ] [7100/60000] > Loss: 2.218952\n",
            "Epoch 04 [=         ] [7200/60000] > Loss: 2.207178\n",
            "Epoch 04 [=         ] [7300/60000] > Loss: 2.217488\n",
            "Epoch 04 [=         ] [7400/60000] > Loss: 2.231814\n",
            "Epoch 04 [=         ] [7500/60000] > Loss: 2.222996\n",
            "Epoch 04 [=         ] [7600/60000] > Loss: 2.225173\n",
            "Epoch 04 [=         ] [7700/60000] > Loss: 2.208431\n",
            "Epoch 04 [=         ] [7800/60000] > Loss: 2.218511\n",
            "Epoch 04 [=         ] [7900/60000] > Loss: 2.205666\n",
            "Epoch 04 [=         ] [8000/60000] > Loss: 2.195073\n",
            "Epoch 04 [=         ] [8100/60000] > Loss: 2.215491\n",
            "Epoch 04 [=         ] [8200/60000] > Loss: 2.217987\n",
            "Epoch 04 [=         ] [8300/60000] > Loss: 2.209439\n",
            "Epoch 04 [=         ] [8400/60000] > Loss: 2.207378\n",
            "Epoch 04 [=         ] [8500/60000] > Loss: 2.221424\n",
            "Epoch 04 [=         ] [8600/60000] > Loss: 2.196267\n",
            "Epoch 04 [=         ] [8700/60000] > Loss: 2.198710\n",
            "Epoch 04 [=         ] [8800/60000] > Loss: 2.193485\n",
            "Epoch 04 [=         ] [8900/60000] > Loss: 2.206826\n",
            "Epoch 04 [=         ] [9000/60000] > Loss: 2.213913\n",
            "Epoch 04 [=         ] [9100/60000] > Loss: 2.229526\n",
            "Epoch 04 [=         ] [9200/60000] > Loss: 2.211851\n",
            "Epoch 04 [=         ] [9300/60000] > Loss: 2.230088\n",
            "Epoch 04 [=         ] [9400/60000] > Loss: 2.193305\n",
            "Epoch 04 [=         ] [9500/60000] > Loss: 2.207604\n",
            "Epoch 04 [=         ] [9600/60000] > Loss: 2.219506\n",
            "Epoch 04 [=         ] [9700/60000] > Loss: 2.218473\n",
            "Epoch 04 [=         ] [9800/60000] > Loss: 2.214473\n",
            "Epoch 04 [=         ] [9900/60000] > Loss: 2.214554\n",
            "Epoch 04 [=         ] [10000/60000] > Loss: 2.218321\n",
            "Epoch 04 [=         ] [10100/60000] > Loss: 2.206836\n",
            "Epoch 04 [=         ] [10200/60000] > Loss: 2.203420\n",
            "Epoch 04 [=         ] [10300/60000] > Loss: 2.205244\n",
            "Epoch 04 [=         ] [10400/60000] > Loss: 2.214267\n",
            "Epoch 04 [=         ] [10500/60000] > Loss: 2.210995\n",
            "Epoch 04 [=         ] [10600/60000] > Loss: 2.194052\n",
            "Epoch 04 [=         ] [10700/60000] > Loss: 2.194001\n",
            "Epoch 04 [=         ] [10800/60000] > Loss: 2.231026\n",
            "Epoch 04 [=         ] [10900/60000] > Loss: 2.214966\n",
            "Epoch 04 [=         ] [11000/60000] > Loss: 2.205709\n",
            "Epoch 04 [=         ] [11100/60000] > Loss: 2.217025\n",
            "Epoch 04 [=         ] [11200/60000] > Loss: 2.210960\n",
            "Epoch 04 [=         ] [11300/60000] > Loss: 2.201640\n",
            "Epoch 04 [=         ] [11400/60000] > Loss: 2.208979\n",
            "Epoch 04 [=         ] [11500/60000] > Loss: 2.227051\n",
            "Epoch 04 [=         ] [11600/60000] > Loss: 2.218021\n",
            "Epoch 04 [=         ] [11700/60000] > Loss: 2.209027\n",
            "Epoch 04 [=         ] [11800/60000] > Loss: 2.230264\n",
            "Epoch 04 [=         ] [11900/60000] > Loss: 2.197950\n",
            "Epoch 04 [==        ] [12000/60000] > Loss: 2.210265\n",
            "Epoch 04 [==        ] [12100/60000] > Loss: 2.203188\n",
            "Epoch 04 [==        ] [12200/60000] > Loss: 2.217705\n",
            "Epoch 04 [==        ] [12300/60000] > Loss: 2.212616\n",
            "Epoch 04 [==        ] [12400/60000] > Loss: 2.203304\n",
            "Epoch 04 [==        ] [12500/60000] > Loss: 2.216323\n",
            "Epoch 04 [==        ] [12600/60000] > Loss: 2.231820\n",
            "Epoch 04 [==        ] [12700/60000] > Loss: 2.206913\n",
            "Epoch 04 [==        ] [12800/60000] > Loss: 2.194737\n",
            "Epoch 04 [==        ] [12900/60000] > Loss: 2.213270\n",
            "Epoch 04 [==        ] [13000/60000] > Loss: 2.214471\n",
            "Epoch 04 [==        ] [13100/60000] > Loss: 2.208695\n",
            "Epoch 04 [==        ] [13200/60000] > Loss: 2.202407\n",
            "Epoch 04 [==        ] [13300/60000] > Loss: 2.195565\n",
            "Epoch 04 [==        ] [13400/60000] > Loss: 2.202056\n",
            "Epoch 04 [==        ] [13500/60000] > Loss: 2.218713\n",
            "Epoch 04 [==        ] [13600/60000] > Loss: 2.214269\n",
            "Epoch 04 [==        ] [13700/60000] > Loss: 2.199698\n",
            "Epoch 04 [==        ] [13800/60000] > Loss: 2.199881\n",
            "Epoch 04 [==        ] [13900/60000] > Loss: 2.211842\n",
            "Epoch 04 [==        ] [14000/60000] > Loss: 2.209529\n",
            "Epoch 04 [==        ] [14100/60000] > Loss: 2.222744\n",
            "Epoch 04 [==        ] [14200/60000] > Loss: 2.211826\n",
            "Epoch 04 [==        ] [14300/60000] > Loss: 2.202833\n",
            "Epoch 04 [==        ] [14400/60000] > Loss: 2.205908\n",
            "Epoch 04 [==        ] [14500/60000] > Loss: 2.217495\n",
            "Epoch 04 [==        ] [14600/60000] > Loss: 2.221557\n",
            "Epoch 04 [==        ] [14700/60000] > Loss: 2.190620\n",
            "Epoch 04 [==        ] [14800/60000] > Loss: 2.216743\n",
            "Epoch 04 [==        ] [14900/60000] > Loss: 2.194652\n",
            "Epoch 04 [==        ] [15000/60000] > Loss: 2.240010\n",
            "Epoch 04 [==        ] [15100/60000] > Loss: 2.196005\n",
            "Epoch 04 [==        ] [15200/60000] > Loss: 2.216783\n",
            "Epoch 04 [==        ] [15300/60000] > Loss: 2.213754\n",
            "Epoch 04 [==        ] [15400/60000] > Loss: 2.208850\n",
            "Epoch 04 [==        ] [15500/60000] > Loss: 2.202059\n",
            "Epoch 04 [==        ] [15600/60000] > Loss: 2.207517\n",
            "Epoch 04 [==        ] [15700/60000] > Loss: 2.202205\n",
            "Epoch 04 [==        ] [15800/60000] > Loss: 2.206517\n",
            "Epoch 04 [==        ] [15900/60000] > Loss: 2.201518\n",
            "Epoch 04 [==        ] [16000/60000] > Loss: 2.217342\n",
            "Epoch 04 [==        ] [16100/60000] > Loss: 2.211532\n",
            "Epoch 04 [==        ] [16200/60000] > Loss: 2.208851\n",
            "Epoch 04 [==        ] [16300/60000] > Loss: 2.206941\n",
            "Epoch 04 [==        ] [16400/60000] > Loss: 2.203920\n",
            "Epoch 04 [==        ] [16500/60000] > Loss: 2.220498\n",
            "Epoch 04 [==        ] [16600/60000] > Loss: 2.199708\n",
            "Epoch 04 [==        ] [16700/60000] > Loss: 2.202549\n",
            "Epoch 04 [==        ] [16800/60000] > Loss: 2.198868\n",
            "Epoch 04 [==        ] [16900/60000] > Loss: 2.197130\n",
            "Epoch 04 [==        ] [17000/60000] > Loss: 2.213539\n",
            "Epoch 04 [==        ] [17100/60000] > Loss: 2.202135\n",
            "Epoch 04 [==        ] [17200/60000] > Loss: 2.184068\n",
            "Epoch 04 [==        ] [17300/60000] > Loss: 2.222454\n",
            "Epoch 04 [==        ] [17400/60000] > Loss: 2.205205\n",
            "Epoch 04 [==        ] [17500/60000] > Loss: 2.217396\n",
            "Epoch 04 [==        ] [17600/60000] > Loss: 2.194438\n",
            "Epoch 04 [==        ] [17700/60000] > Loss: 2.194692\n",
            "Epoch 04 [==        ] [17800/60000] > Loss: 2.218370\n",
            "Epoch 04 [==        ] [17900/60000] > Loss: 2.193357\n",
            "Epoch 04 [===       ] [18000/60000] > Loss: 2.212887\n",
            "Epoch 04 [===       ] [18100/60000] > Loss: 2.212421\n",
            "Epoch 04 [===       ] [18200/60000] > Loss: 2.193595\n",
            "Epoch 04 [===       ] [18300/60000] > Loss: 2.231389\n",
            "Epoch 04 [===       ] [18400/60000] > Loss: 2.200842\n",
            "Epoch 04 [===       ] [18500/60000] > Loss: 2.197236\n",
            "Epoch 04 [===       ] [18600/60000] > Loss: 2.206124\n",
            "Epoch 04 [===       ] [18700/60000] > Loss: 2.218258\n",
            "Epoch 04 [===       ] [18800/60000] > Loss: 2.198038\n",
            "Epoch 04 [===       ] [18900/60000] > Loss: 2.207292\n",
            "Epoch 04 [===       ] [19000/60000] > Loss: 2.206240\n",
            "Epoch 04 [===       ] [19100/60000] > Loss: 2.196637\n",
            "Epoch 04 [===       ] [19200/60000] > Loss: 2.201605\n",
            "Epoch 04 [===       ] [19300/60000] > Loss: 2.213625\n",
            "Epoch 04 [===       ] [19400/60000] > Loss: 2.217218\n",
            "Epoch 04 [===       ] [19500/60000] > Loss: 2.200219\n",
            "Epoch 04 [===       ] [19600/60000] > Loss: 2.217092\n",
            "Epoch 04 [===       ] [19700/60000] > Loss: 2.197421\n",
            "Epoch 04 [===       ] [19800/60000] > Loss: 2.221103\n",
            "Epoch 04 [===       ] [19900/60000] > Loss: 2.202870\n",
            "Epoch 04 [===       ] [20000/60000] > Loss: 2.221261\n",
            "Epoch 04 [===       ] [20100/60000] > Loss: 2.203158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YwYTrcevsnxK"
      },
      "source": [
        "## Exercícios\n",
        "\n",
        "1. Altere a quatidade de neurônios das camadas. Isso afeta os resultados?\n",
        "2. Tente adicionar uma nova camada oculta. Isso afeta os resultados obtidos? E o que dizer sobre o tempo de treinamento?\n",
        "3. A mudança na taxa de aprendizado (*learning rate*) altera o resultado?\n",
        "4. Qual é o melhor resultado que você pode obter ao otimizar todos os parâmetros (taxa de aprendizado, iterações, número de camadas ocultas, número de unidades ocultas por camada)?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNi0ht2OsnxM",
        "colab": {}
      },
      "source": [
        "# as alterações serão feitas no proprio código acima\n",
        "# acc sem alteração:  Acuracia Validacao: 88.73%\n",
        "\n",
        "# acc com uma nova camada escondida (100 neuronios) - > acc = Acuracia Validacao: 79.29%\n",
        "\n",
        "# acc com a mesma camada extra, porem com um lr de 0.05 ->\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}